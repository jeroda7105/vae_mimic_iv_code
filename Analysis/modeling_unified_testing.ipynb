{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mimic_iv_omop_modeling_unified_testing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0DsFARgE0MOh"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Time Series Data\n",
        "\n",
        "# Data by the hour\n",
        "first_48_data = pd.read_csv('/content/drive/MyDrive/revised_first_48_by_hr.csv')\n",
        "first_48_data = first_48_data.dropna(axis=1, how='all')\n",
        "\n",
        "first_48_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "4jqZLo8J1VcH",
        "outputId": "ec9c23bb-8df4-4ad2-c872-6da25a819ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           time_since_start measurement_datetime  \\\n",
              "0           0  0 days 00:00:00.000000000  2174-05-26 04:20:00   \n",
              "1           1  0 days 01:00:00.000000000  2174-05-26 05:20:00   \n",
              "2           2  0 days 02:00:00.000000000  2174-05-26 06:20:00   \n",
              "3           3  0 days 03:00:00.000000000  2174-05-26 07:20:00   \n",
              "4           4  0 days 04:00:00.000000000  2174-05-26 08:20:00   \n",
              "\n",
              "             person_id  visit_occurrence_id visit_start_datetime  \\\n",
              "0 -8090189584974691216 -9133360720296560252  2174-05-26 04:20:00   \n",
              "1 -8090189584974691216 -9133360720296560252  2174-05-26 04:20:00   \n",
              "2 -8090189584974691216 -9133360720296560252  2174-05-26 04:20:00   \n",
              "3 -8090189584974691216 -9133360720296560252  2174-05-26 04:20:00   \n",
              "4 -8090189584974691216 -9133360720296560252  2174-05-26 04:20:00   \n",
              "\n",
              "    visit_end_datetime  ART BP Diastolic  Arterial Blood Pressure diastolic  \\\n",
              "0  2174-05-31 14:15:00               NaN                                NaN   \n",
              "1  2174-05-31 14:15:00               NaN                                NaN   \n",
              "2  2174-05-31 14:15:00               NaN                                NaN   \n",
              "3  2174-05-31 14:15:00               NaN                                NaN   \n",
              "4  2174-05-31 14:15:00               NaN                                NaN   \n",
              "\n",
              "   Non Invasive Blood Pressure diastolic  ...  Admission Weight  \\\n",
              "0                                    NaN  ...               NaN   \n",
              "1                                    NaN  ...               NaN   \n",
              "2                                    NaN  ...               NaN   \n",
              "3                                    NaN  ...               NaN   \n",
              "4                                    NaN  ...               NaN   \n",
              "\n",
              "   pH|Blood|Blood Gas  PH (Arterial)  readmission_freq  readmission_id  \\\n",
              "0                 NaN            NaN               0.0             NaN   \n",
              "1                 NaN            NaN               0.0             NaN   \n",
              "2                 NaN            NaN               0.0             NaN   \n",
              "3                 NaN            NaN               0.0             NaN   \n",
              "4                 NaN            NaN               0.0             NaN   \n",
              "\n",
              "   readmission_time  time_between_readmission  readmission_label  death_label  \\\n",
              "0               NaN                       NaN                0.0          0.0   \n",
              "1               NaN                       NaN                0.0          0.0   \n",
              "2               NaN                       NaN                0.0          0.0   \n",
              "3               NaN                       NaN                0.0          0.0   \n",
              "4               NaN                       NaN                0.0          0.0   \n",
              "\n",
              "   length_of_stay  \n",
              "0      129.916667  \n",
              "1      129.916667  \n",
              "2      129.916667  \n",
              "3      129.916667  \n",
              "4      129.916667  \n",
              "\n",
              "[5 rows x 49 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcfde207-17cf-4cd1-83cb-bfabca0f62c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>time_since_start</th>\n",
              "      <th>measurement_datetime</th>\n",
              "      <th>person_id</th>\n",
              "      <th>visit_occurrence_id</th>\n",
              "      <th>visit_start_datetime</th>\n",
              "      <th>visit_end_datetime</th>\n",
              "      <th>ART BP Diastolic</th>\n",
              "      <th>Arterial Blood Pressure diastolic</th>\n",
              "      <th>Non Invasive Blood Pressure diastolic</th>\n",
              "      <th>...</th>\n",
              "      <th>Admission Weight</th>\n",
              "      <th>pH|Blood|Blood Gas</th>\n",
              "      <th>PH (Arterial)</th>\n",
              "      <th>readmission_freq</th>\n",
              "      <th>readmission_id</th>\n",
              "      <th>readmission_time</th>\n",
              "      <th>time_between_readmission</th>\n",
              "      <th>readmission_label</th>\n",
              "      <th>death_label</th>\n",
              "      <th>length_of_stay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0 days 00:00:00.000000000</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>-8090189584974691216</td>\n",
              "      <td>-9133360720296560252</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>2174-05-31 14:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0 days 01:00:00.000000000</td>\n",
              "      <td>2174-05-26 05:20:00</td>\n",
              "      <td>-8090189584974691216</td>\n",
              "      <td>-9133360720296560252</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>2174-05-31 14:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0 days 02:00:00.000000000</td>\n",
              "      <td>2174-05-26 06:20:00</td>\n",
              "      <td>-8090189584974691216</td>\n",
              "      <td>-9133360720296560252</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>2174-05-31 14:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0 days 03:00:00.000000000</td>\n",
              "      <td>2174-05-26 07:20:00</td>\n",
              "      <td>-8090189584974691216</td>\n",
              "      <td>-9133360720296560252</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>2174-05-31 14:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0 days 04:00:00.000000000</td>\n",
              "      <td>2174-05-26 08:20:00</td>\n",
              "      <td>-8090189584974691216</td>\n",
              "      <td>-9133360720296560252</td>\n",
              "      <td>2174-05-26 04:20:00</td>\n",
              "      <td>2174-05-31 14:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.916667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 49 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcfde207-17cf-4cd1-83cb-bfabca0f62c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcfde207-17cf-4cd1-83cb-bfabca0f62c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcfde207-17cf-4cd1-83cb-bfabca0f62c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting timedelta string to float \n",
        "\n",
        "time_deltas = first_48_data['time_since_start'].apply(lambda x : pd.to_timedelta(x))\n",
        "\n",
        "time_delta_floats = time_deltas.apply(lambda x : x / np.timedelta64(1, 'm'))\n",
        "\n",
        "first_48_data['time_since_start'] = time_delta_floats\n",
        "\n",
        "print(first_48_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsQqcLKH1bJN",
        "outputId": "daf66fb9-552b-47d7-dd53-6a13f04de830"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  time_since_start measurement_datetime            person_id  \\\n",
            "0           0               0.0  2174-05-26 04:20:00 -8090189584974691216   \n",
            "1           1              60.0  2174-05-26 05:20:00 -8090189584974691216   \n",
            "2           2             120.0  2174-05-26 06:20:00 -8090189584974691216   \n",
            "3           3             180.0  2174-05-26 07:20:00 -8090189584974691216   \n",
            "4           4             240.0  2174-05-26 08:20:00 -8090189584974691216   \n",
            "\n",
            "   visit_occurrence_id visit_start_datetime   visit_end_datetime  \\\n",
            "0 -9133360720296560252  2174-05-26 04:20:00  2174-05-31 14:15:00   \n",
            "1 -9133360720296560252  2174-05-26 04:20:00  2174-05-31 14:15:00   \n",
            "2 -9133360720296560252  2174-05-26 04:20:00  2174-05-31 14:15:00   \n",
            "3 -9133360720296560252  2174-05-26 04:20:00  2174-05-31 14:15:00   \n",
            "4 -9133360720296560252  2174-05-26 04:20:00  2174-05-31 14:15:00   \n",
            "\n",
            "   ART BP Diastolic  Arterial Blood Pressure diastolic  \\\n",
            "0               NaN                                NaN   \n",
            "1               NaN                                NaN   \n",
            "2               NaN                                NaN   \n",
            "3               NaN                                NaN   \n",
            "4               NaN                                NaN   \n",
            "\n",
            "   Non Invasive Blood Pressure diastolic  ...  Admission Weight  \\\n",
            "0                                    NaN  ...               NaN   \n",
            "1                                    NaN  ...               NaN   \n",
            "2                                    NaN  ...               NaN   \n",
            "3                                    NaN  ...               NaN   \n",
            "4                                    NaN  ...               NaN   \n",
            "\n",
            "   pH|Blood|Blood Gas  PH (Arterial)  readmission_freq  readmission_id  \\\n",
            "0                 NaN            NaN               0.0             NaN   \n",
            "1                 NaN            NaN               0.0             NaN   \n",
            "2                 NaN            NaN               0.0             NaN   \n",
            "3                 NaN            NaN               0.0             NaN   \n",
            "4                 NaN            NaN               0.0             NaN   \n",
            "\n",
            "   readmission_time  time_between_readmission  readmission_label  death_label  \\\n",
            "0               NaN                       NaN                0.0          0.0   \n",
            "1               NaN                       NaN                0.0          0.0   \n",
            "2               NaN                       NaN                0.0          0.0   \n",
            "3               NaN                       NaN                0.0          0.0   \n",
            "4               NaN                       NaN                0.0          0.0   \n",
            "\n",
            "   length_of_stay  \n",
            "0      129.916667  \n",
            "1      129.916667  \n",
            "2      129.916667  \n",
            "3      129.916667  \n",
            "4      129.916667  \n",
            "\n",
            "[5 rows x 49 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardizing the features\n",
        "\n",
        "feature_data = first_48_data[first_48_data.columns[7:-7]]\n",
        "print(feature_data.head())\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "std_scaler.fit(feature_data)\n",
        "\n",
        "scaled_X = std_scaler.transform(feature_data)\n",
        "\n",
        "scaled_X_df = pd.DataFrame(scaled_X, columns=first_48_data.columns[7:-7])\n",
        "\n",
        "first_48_data[first_48_data.columns[7:-7]] = scaled_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShNbUHNw1l7H",
        "outputId": "09b79c9b-69be-4069-b57b-8a7a37cbb707"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ART BP Diastolic  Arterial Blood Pressure diastolic  \\\n",
            "0               NaN                                NaN   \n",
            "1               NaN                                NaN   \n",
            "2               NaN                                NaN   \n",
            "3               NaN                                NaN   \n",
            "4               NaN                                NaN   \n",
            "\n",
            "   Non Invasive Blood Pressure diastolic  \\\n",
            "0                                    NaN   \n",
            "1                                    NaN   \n",
            "2                                    NaN   \n",
            "3                                    NaN   \n",
            "4                                    NaN   \n",
            "\n",
            "   Manual Blood Pressure Diastolic Left  \\\n",
            "0                                   NaN   \n",
            "1                                   NaN   \n",
            "2                                   NaN   \n",
            "3                                   NaN   \n",
            "4                                   NaN   \n",
            "\n",
            "   Manual Blood Pressure Diastolic Right  Inspired O2 Fraction  \\\n",
            "0                                    NaN                   NaN   \n",
            "1                                    NaN                   NaN   \n",
            "2                                    NaN                   NaN   \n",
            "3                                    NaN                   NaN   \n",
            "4                                    NaN                   NaN   \n",
            "\n",
            "   GCS - Eye Opening  GCS - Motor Response  GCS - Verbal Response  \\\n",
            "0                NaN                   NaN                    NaN   \n",
            "1                NaN                   NaN                    NaN   \n",
            "2                NaN                   NaN                    NaN   \n",
            "3                NaN                   NaN                    NaN   \n",
            "4                NaN                   NaN                    NaN   \n",
            "\n",
            "   Glascow coma scale total  ...  Manual Blood Pressure Systolic Left  \\\n",
            "0                       NaN  ...                                  NaN   \n",
            "1                       NaN  ...                                  NaN   \n",
            "2                       NaN  ...                                  NaN   \n",
            "3                       NaN  ...                                  NaN   \n",
            "4                       NaN  ...                                  NaN   \n",
            "\n",
            "   Manual Blood Pressure Systolic Right  Non Invasive Blood Pressure systolic  \\\n",
            "0                                   NaN                                   NaN   \n",
            "1                                   NaN                                   NaN   \n",
            "2                                   NaN                                   NaN   \n",
            "3                                   NaN                                   NaN   \n",
            "4                                   NaN                                   NaN   \n",
            "\n",
            "   Temperature|Blood|Blood Gas  Temperature Celsius  Temperature  \\\n",
            "0                          NaN                  NaN          NaN   \n",
            "1                          NaN                  NaN          NaN   \n",
            "2                          NaN                  NaN          NaN   \n",
            "3                          NaN                  NaN          NaN   \n",
            "4                          NaN                  NaN          NaN   \n",
            "\n",
            "   Admission Weight (Kg)  Admission Weight  pH|Blood|Blood Gas  PH (Arterial)  \n",
            "0                    NaN               NaN                 NaN            NaN  \n",
            "1                    NaN               NaN                 NaN            NaN  \n",
            "2                    NaN               NaN                 NaN            NaN  \n",
            "3                    NaN               NaN                 NaN            NaN  \n",
            "4                   78.0               NaN                 NaN            NaN  \n",
            "\n",
            "[5 rows x 35 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by admission\n",
        "\n",
        "data = first_48_data.groupby('visit_occurrence_id')\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7GR50X1onC",
        "outputId": "104330ff-5a03-41b5-b7a4-88accb8a5ee7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the feature and label data\n",
        "y_readmission = []\n",
        "y_mortality = []\n",
        "y_los = []\n",
        "\n",
        "i = 0\n",
        "\n",
        "for group_idx, group_rows in data:\n",
        "\n",
        "  j = 0\n",
        "\n",
        "  y_readmission.append(group_rows['readmission_label'].values[0])\n",
        "  y_mortality.append(group_rows['death_label'].values[0])\n",
        "  y_los.append(group_rows['length_of_stay'].values[0])\n",
        "\n",
        "  for idx, row in group_rows.iterrows():\n",
        "    \n",
        "    # entry of the matrix\n",
        "    cur_time_entry = []\n",
        "\n",
        "    # Creating the row with the necessary feature values\n",
        "    #cur_time_entry.append(row['time_since_start'])\n",
        "    \n",
        "    for feature_name in first_48_data.columns[7:-7]:\n",
        "      cur_time_entry.append(row[feature_name])\n",
        "\n",
        "    cur_time_entry = np.array([cur_time_entry])\n",
        "\n",
        "    \n",
        "    # To ensure that this works to insert the first row\n",
        "    if j == 0:\n",
        "\n",
        "      # matrix of the time series\n",
        "      X_element = np.array(cur_time_entry)\n",
        "      \n",
        "    else:\n",
        "      X_element = np.concatenate((X_element, np.array(cur_time_entry)))\n",
        "    \n",
        "    j += 1\n",
        "\n",
        "    \n",
        "  \n",
        "  # To ensure that this works to insert the first matrix\n",
        "  if i == 0:\n",
        "\n",
        "    # Holds all of the multivariate time series\n",
        "    X = [X_element]\n",
        "    \n",
        "  else:\n",
        "    X = np.concatenate((X, [X_element]))\n",
        "  \n",
        "  i += 1\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "X_columns = []\n",
        "#X_columns.append(first_48_data.columns[1])\n",
        "\n",
        "for feature_name in first_48_data.columns[7:-7]:\n",
        "  X_columns.append(feature_name)\n",
        "\n",
        "y_readmission = pd.Series(y_readmission, name='readmission_label')\n",
        "y_mortality = pd.Series(y_mortality, name='death_label')\n",
        "y_los = pd.Series(y_los, name='length_of_stay')\n",
        "\n",
        "y = { 'readmission_label': y_readmission,\n",
        "       'death_label': y_mortality,\n",
        "       'length_of_stay': y_los \n",
        "}\n",
        "\n",
        "y = pd.DataFrame(y)\n",
        "\n",
        "print(len(X))\n",
        "print(len(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3F1Pepf1rLB",
        "outputId": "372bf643-923d-4c12-c16c-ccc0f37249b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124\n",
            "124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preparing the train and test sets\n",
        "def balanced_train_test_split(X, y):\n",
        "  while(1):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    mortality_y_train = y_train['death_label']\n",
        "    mortality_y_test = y_test['death_label']\n",
        "    \n",
        "    prop_positive = len(np.where(mortality_y_test == 1)) / len(np.where(y['death_label'] == 1)) \n",
        "     \n",
        "    if prop_positive >= 0.2:\n",
        "      print(np.where(mortality_y_test == 1))\n",
        "      break\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "T2z9KMmI1tVF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X_train, X_test, y_train, y_test = balanced_train_test_split(X, y)"
      ],
      "metadata": {
        "id": "ZaQwfzOwPYYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa5cf68-f128-4485-e1fb-945431dd8370"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 2,  6,  7, 20]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "train_feature_means = []\n",
        "\n",
        "# Reshaping to 2-dimensional data for imputation\n",
        "X_train_2d = np.reshape(X_train, (99*48, 35))\n",
        "\n",
        "\n",
        "train_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "train_mean_imputer.fit(X_train_2d)\n",
        "X_train_2d = train_mean_imputer.transform(X_train_2d)\n",
        "\n",
        "\n",
        "for i in range(X_train_2d.shape[1]):\n",
        "  train_feature_means.append(np.mean(X_train_2d[:][i]))\n",
        "\n",
        "\n",
        "\n",
        "print(train_feature_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwJDX3Ai2GnQ",
        "outputId": "3dfb62cb-6328-470e-9d3f-2609db86d48f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124, 48, 35)\n",
            "[0.0373490292322291, 0.0373490292322291, 0.0373490292322291, 0.0373490292322291, 0.03597609258640947, 0.039717549418736994, -0.07057858583747331, 0.007299376307830534, -0.061395411232063525, -0.024982003870954932, -0.001486424529856481, 0.14101326822251994, 0.01190366691248264, 0.03132000182428588, -0.005515852441152342, -0.0001931601062763621, -0.07342391323754627, 0.028247227984927344, 0.03554779464180281, 0.08590065426268852, 0.04273291315007864, -0.0010475361487406714, 0.10179098983591817, 0.1017814865462288, 0.03445443860480352, 0.00022757435658054984, 0.03370061832596056, 0.1320225891612314, 0.0807371430480259, 0.07555240616723223, 0.11727925594020025, 0.15112083210455993, -0.030324929527357294, -0.0140139563831042, 0.0373490292322291]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "test_feature_means = []\n",
        "\n",
        "# Reshaping to 2-dimensional data for imputation\n",
        "X_test_2d = np.reshape(X_test, (25*48, 35))\n",
        "\n",
        "\n",
        "test_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "test_mean_imputer.fit(X_test_2d)\n",
        "X_test_2d = test_mean_imputer.transform(X_test_2d)\n",
        "\n",
        "\n",
        "for i in range(X_test_2d.shape[1]):\n",
        "  test_feature_means.append(np.mean(X_test_2d[:][i]))\n",
        "\n",
        "\n",
        "\n",
        "print(test_feature_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q12dIA8z2hsx",
        "outputId": "02544436-9d4b-467e-8e31-e0a922277cff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124, 48, 35)\n",
            "[-0.19695384038407346, -0.19695384038407346, -0.19695384038407346, -0.19695384038407346, -0.19695384038407346, -0.19695384038407346, -0.6514260242427226, -0.2977983017385706, -0.02683252194705933, -0.2327509695477523, -0.27737466886176354, -0.24338871426238895, -0.06303971484771395, -0.28243787535460546, -0.13480021290647815, -0.30315692513436926, -0.29801075719866965, -0.31344516760923063, -0.10287072252894008, -0.3022773909180368, -0.2943700114485993, -0.37266161895017064, -0.29691125638344923, -0.1076520246359438, -0.2621288240807947, -0.21090938203162768, -0.04277639096519147, -0.3246635659971022, -0.28983949243917495]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a random mask for evaluation of imputation \n",
        "\n",
        "def mean_imputation_eval(X, train_feature_means, test_feature_means=None):\n",
        "  iter = 2000\n",
        "  mse_list = []\n",
        "  mae_list = []\n",
        "\n",
        "  n_samples = X.shape[0]\n",
        "\n",
        "  rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "  mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "  rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "\n",
        "  for j in range(iter):\n",
        "\n",
        "    for i in range(rand_X_imputed.shape[0]):\n",
        "      rand_mask[i] = np.random.randint(2, size=(48, 35))\n",
        "\n",
        "    mse = 0\n",
        "    mae = 0\n",
        "\n",
        "    # Actual mask of observations for comparison\n",
        "    mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
        "    mask_X = np.where(np.isnan(X), 0, 1)\n",
        "    # Random mask for evaluation\n",
        "    rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
        "    #print(rand_X_test_imputed[i])\n",
        "\n",
        "    #print(mask_X_test_imputed[i].shape)\n",
        "\n",
        "    # imputing on the random mask data\n",
        "    rand_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
        "    \n",
        "    #print(rand_X_test_imputed)\n",
        "\n",
        "\n",
        "    rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
        "      \n",
        "    for i in range(rand_X_imputed.shape[0]):\n",
        "      # mse += np.mean(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
        "      # mae += np.mean(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
        "      mse += np.sum(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(mask_X[i])\n",
        "      mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(mask_X[i])\n",
        "\n",
        "    mse_list.append(mse / n_samples)\n",
        "    mae_list.append(mae / n_samples)\n",
        "\n",
        "\n",
        "  print(\"mse:\")\n",
        "  print(np.mean(mse_list))\n",
        "  print(np.var(mse_list), \"\\n\")\n",
        "\n",
        "\n",
        "  print(\"mae:\")\n",
        "  print(np.mean(mae_list))\n",
        "  print(np.var(mae_list), \"\\n\")"
      ],
      "metadata": {
        "id": "6Q53xXLP2lnd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_imputation_eval(X, train_feature_means)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4SbKzJc21E7",
        "outputId": "b0d17ec3-2331-49b8-9426-1fce90386016"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse:\n",
            "0.581032312781591\n",
            "0.014821267460382719 \n",
            "\n",
            "mae:\n",
            "0.3993161111881436\n",
            "0.000630250892139529 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mean_imputed_data(X_train, X_test, train_feature_means, test_feature_means=None):\n",
        "  impute_value = 0.\n",
        "\n",
        "  X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "  train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        if np.isnan(X_train[i,j,k]):\n",
        "          X_train_imputed[i,j,k] = train_feature_means[k]\n",
        "          train_mask[i,j,k] = 0\n",
        "        else:\n",
        "          X_train_imputed[i,j,k] = X_train[i,j,k]\n",
        "          train_mask[i,j,k] = 1\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        if np.isnan(X_test[i,j,k]):\n",
        "          X_test_imputed[i,j,k] = train_feature_means[k]\n",
        "          test_mask[i,j,k] = 0\n",
        "        else:\n",
        "          X_test_imputed[i,j,k] = X_test[i,j,k]\n",
        "          test_mask[i,j,k] = 1\n",
        "\n",
        "  return X_train_imputed, X_test_imputed\n",
        "    "
      ],
      "metadata": {
        "id": "8qPYEc7B3GNQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean_imputed, X_test_mean_imputed = create_mean_imputed_data(X_train, X_test, train_feature_means)"
      ],
      "metadata": {
        "id": "iComzTNR4cbF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_preprocessing(X_train, X_test):\n",
        "  impute_value = 0.\n",
        "\n",
        "  X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "  train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        if np.isnan(X_train[i,j,k]):\n",
        "          X_train_imputed[i,j,k] = impute_value\n",
        "          train_mask[i,j,k] = 0\n",
        "        else:\n",
        "          X_train_imputed[i,j,k] = X_train[i,j,k]\n",
        "          train_mask[i,j,k] = 1\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        if np.isnan(X_test[i,j,k]):\n",
        "          X_test_imputed[i,j,k] = impute_value\n",
        "          test_mask[i,j,k] = 0\n",
        "        else:\n",
        "          X_test_imputed[i,j,k] = X_test[i,j,k]\n",
        "          test_mask[i,j,k] = 1\n",
        "  return X_train_imputed, X_test_imputed, train_mask, test_mask"
      ],
      "metadata": {
        "id": "d9GnUNeC40Em"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_X_train, processed_X_test, train_mask, test_mask = vae_preprocessing(X_train, X_test)"
      ],
      "metadata": {
        "id": "HPBch8O_5uFF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class vae_model(ABC):\n",
        "  def __init__(self):\n",
        "    self.latent_dim = 2\n",
        "    self.sequence_length = 48\n",
        "\n",
        "  def set_seed(self, seed):\n",
        "    \n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "  def sampling(self, args):\n",
        "      \n",
        "    latent_dim = 2\n",
        "    z_mean, z_log_sigma = args\n",
        "    batch_size = tf.shape(z_mean)[0]\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1)\n",
        "    \n",
        "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
        "\n",
        "\n",
        "  def vae_loss(self, inp, mask, out, z_log_sigma, z_mean):\n",
        "    masked_input = tf.math.multiply(inp, mask)\n",
        "    masked_output = tf.math.multiply(out, mask)\n",
        "\n",
        "    #mse = np.sum(np.square(np.subtract(masked_output, masked_input))) / np.sum(mask)\n",
        "    mse = K.sum(K.square(masked_output - masked_input)) / K.sum(mask)\n",
        "\n",
        "    reconstruction = mse * self.sequence_length\n",
        "    kl = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
        "\n",
        "    return reconstruction + kl\n",
        "\n",
        "  @abstractmethod\n",
        "  def get_model(self):\n",
        "    pass\n",
        "   \n"
      ],
      "metadata": {
        "id": "Co301rq5CDqP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_vae(vae_model):\n",
        "\n",
        "  def get_model(self):\n",
        "  \n",
        "\n",
        "    self.set_seed(33)\n",
        "\n",
        "    # encoder\n",
        "    \n",
        "    inp = Input(shape=(self.sequence_length, 35))\n",
        "    mask = Input(shape=(self.sequence_length, 35))\n",
        "    \n",
        "    concat = Concatenate()([inp])\n",
        "  \n",
        "    #enc = LSTM(192, input_shape=(48, 36))(concat)\n",
        "\n",
        "    conv = tf.keras.layers.Conv1D(filters = 16, kernel_size = 3, activation='relu')(concat)\n",
        "    print(conv.shape)\n",
        "\n",
        "    max_pool = tf.keras.layers.MaxPool1D(pool_size = 2)(conv) \n",
        "\n",
        "    conv = tf.keras.layers.Conv1D(filters = 8, kernel_size = 3, activation='relu')(max_pool)\n",
        "    print(conv.shape)\n",
        "    \n",
        "    enc = tf.keras.layers.Flatten()(conv)\n",
        "\n",
        "    enc = Dense(21*8, activation=\"relu\")(enc)\n",
        "\n",
        "    enc = Dense(21*4, activation=\"relu\")(enc)\n",
        "\n",
        "    z = Dense(21*2, activation=\"relu\")(enc)\n",
        "      \n",
        "    z_mean = Dense(self.latent_dim)(z)\n",
        "    z_log_sigma = Dense(self.latent_dim)(z)\n",
        "\n",
        "    encoder = Model([inp], [z_mean, z_log_sigma])\n",
        "    \n",
        "    # decoder\n",
        "    \n",
        "    inp_z = Input(shape=(self.latent_dim,))\n",
        "\n",
        "    dec = Dense(21*2)(inp_z)\n",
        "\n",
        "    dec = Dense(21*4)(dec)\n",
        "\n",
        "    dec = Dense(21*8)(dec)\n",
        "\n",
        "    dec = Concatenate()([dec])\n",
        "    dec = Reshape((21, 8))(dec)\n",
        "\n",
        "    deconv = tf.keras.layers.Conv1DTranspose(filters=16, kernel_size=3)(dec)\n",
        "    print(deconv.shape)\n",
        "\n",
        "    upsample = tf.keras.layers.UpSampling1D(2)(deconv)\n",
        "\n",
        "    deconv = tf.keras.layers.Conv1DTranspose(filters=35, kernel_size=3)(upsample)\n",
        "    print(deconv.shape)\n",
        "\n",
        "    \n",
        "    out = deconv\n",
        "    \n",
        "\n",
        "    decoder = Model([inp_z], out) \n",
        "    \n",
        "    # encoder and decoder \n",
        "\n",
        "    z_mean, z_log_sigma = encoder([inp])\n",
        "    z = Lambda(self.sampling)([z_mean, z_log_sigma])\n",
        "    pred = decoder([z])\n",
        "\n",
        "    vae = Model([inp,  mask], pred)\n",
        "    vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
        "    vae.compile(loss=None, optimizer=Adam(learning_rate=1e-4))\n",
        "    \n",
        "    return vae"
      ],
      "metadata": {
        "id": "ev9NJEg-58HO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class lstm_vae(vae_model):\n",
        "\n",
        "\n",
        "  def get_model(self):\n",
        "      \n",
        "    self.set_seed(33)\n",
        "\n",
        "\n",
        "    \n",
        "    # encoder \n",
        "    \n",
        "    inp = Input(shape=(self.sequence_length, 35))\n",
        "    mask = Input(shape=(self.sequence_length, 35))\n",
        "    \n",
        "    concat = Concatenate()([inp])\n",
        "  \n",
        "    enc = LSTM(192, input_shape=(48, 35))(concat)\n",
        "    \n",
        "    z = Dense(96, activation=\"relu\")(enc)\n",
        "        \n",
        "    z_mean = Dense(self.latent_dim)(z)\n",
        "    z_log_sigma = Dense(self.latent_dim)(z)\n",
        "\n",
        "    encoder = Model([inp], [z_mean, z_log_sigma])\n",
        "    \n",
        "    # decoder\n",
        "    \n",
        "    inp_z = Input(shape=(self.latent_dim,))\n",
        "\n",
        "    dec = RepeatVector(self.sequence_length)(inp_z)\n",
        "    \n",
        "    dec = Concatenate()([dec])\n",
        "    dec = LSTM(192, input_shape=(48, 35), return_sequences=True)(dec)\n",
        "    \n",
        "    out = TimeDistributed(Dense(35))(dec)\n",
        "    \n",
        "\n",
        "    decoder = Model([inp_z], out) \n",
        "    \n",
        "    # encoder and decoder \n",
        "\n",
        "    z_mean, z_log_sigma = encoder([inp])\n",
        "    z = Lambda(self.sampling)([z_mean, z_log_sigma])\n",
        "    pred = decoder([z])\n",
        "\n",
        "    vae = Model([inp,  mask], pred)\n",
        "    vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
        "    vae.compile(loss=None, optimizer=Adam(learning_rate=1e-3))\n",
        "    \n",
        "    return vae"
      ],
      "metadata": {
        "id": "VoghIhwW61Js"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cnn_lstm_vae(vae_model):\n",
        "\n",
        "  def get_model(self):\n",
        "      \n",
        "    self.set_seed(33)\n",
        "\n",
        "    \n",
        "    # encoder \n",
        "    \n",
        "    inp = Input(shape=(self.sequence_length, 35))\n",
        "    mask = Input(shape=(self.sequence_length, 35))\n",
        "    \n",
        "    concat = Concatenate()([inp])\n",
        "  \n",
        "    #enc = LSTM(192, input_shape=(48, 36))(concat)\n",
        "\n",
        "    conv = tf.keras.layers.Conv1D(filters = 16, kernel_size = 3, activation='relu')(concat)\n",
        "    print(conv.shape)\n",
        "\n",
        "    max_pool = tf.keras.layers.MaxPool1D(pool_size = 2)(conv) \n",
        "\n",
        "    conv = tf.keras.layers.Conv1D(filters = 8, kernel_size = 3, activation='relu')(max_pool)\n",
        "    print(conv.shape)\n",
        "    \n",
        "    enc = tf.keras.layers.Flatten()(conv)\n",
        "\n",
        "    enc = Dense(21*8, activation=\"relu\")(enc)\n",
        "\n",
        "    enc = Dense(21*4, activation=\"relu\")(enc)\n",
        "\n",
        "    enc = Dense(21*2, activation=\"relu\")(enc)\n",
        "    \n",
        "    enc = Reshape((21, 2))(enc)\n",
        "\n",
        "    enc = LSTM(192, input_shape=(21, 2))(enc)\n",
        "\n",
        "    z = Dense(64, activation=\"relu\")(enc)\n",
        "      \n",
        "    z_mean = Dense(self.latent_dim)(z)\n",
        "    z_log_sigma = Dense(self.latent_dim)(z)\n",
        "\n",
        "    encoder = Model([inp], [z_mean, z_log_sigma])\n",
        "    \n",
        "    # decoder\n",
        "    \n",
        "    inp_z = Input(shape=(self.latent_dim,))\n",
        "\n",
        "    dec = RepeatVector(self.sequence_length)(inp_z)\n",
        "    \n",
        "    dec = Concatenate()([dec])\n",
        "    dec = LSTM(192, input_shape=(48, 35), return_sequences=True)(dec)\n",
        "    \n",
        "    \n",
        "    out = TimeDistributed(Dense(35))(dec)\n",
        "\n",
        "    '''\n",
        "    deconv = tf.keras.layers.Conv1DTranspose(filters=16, kernel_size=3)(dec)\n",
        "    print(deconv.shape)\n",
        "\n",
        "    upsample = tf.keras.layers.UpSampling1D(2)(deconv)\n",
        "\n",
        "    deconv = tf.keras.layers.Conv1DTranspose(filters=35, kernel_size=3)(upsample)\n",
        "    print(deconv.shape)\n",
        "    '''\n",
        "    \n",
        "    #out = deconv\n",
        "    decoder = Model([inp_z], out) \n",
        "    \n",
        "    # encoder and decoder \n",
        "\n",
        "    z_mean, z_log_sigma = encoder([inp])\n",
        "    z = Lambda(self.sampling)([z_mean, z_log_sigma])\n",
        "    pred = decoder([z])\n",
        "\n",
        "    vae = Model([inp,  mask], pred)\n",
        "    vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
        "    vae.compile(loss=None, optimizer=Adam(learning_rate=1e-4))\n",
        "    \n",
        "    return vae"
      ],
      "metadata": {
        "id": "BbCt7eAh67-T"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_vae_instance = cnn_vae()\n",
        "lstm_vae_instance = lstm_vae()\n",
        "cnn_lstm_vae_instance = cnn_lstm_vae()\n",
        "\n",
        "cnn_vae_model = cnn_vae_instance.get_model()\n",
        "lstm_vae_model = lstm_vae_instance.get_model()\n",
        "cnn_lstm_vae_model = cnn_lstm_vae_instance.get_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttCWr6Ff7Iq4",
        "outputId": "c36d6ab3-035c-41ea-f20d-8f1efd7803ac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 46, 16)\n",
            "(None, 21, 8)\n",
            "(None, 23, 16)\n",
            "(None, 48, 35)\n",
            "(None, 46, 16)\n",
            "(None, 21, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_vae_model(model, processed_X_train, processed_X_test, train_mask, test_mask):\n",
        "  \n",
        "  es = EarlyStopping(patience=15, verbose=1, min_delta=0.001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "  model.fit([processed_X_train, train_mask], batch_size=1, epochs=1000, shuffle=False, callbacks=[es])\n",
        "\n",
        "  \n",
        "  vae = Model(model.input, model.output)\n",
        "\n",
        "  reconstruc_train = vae.predict([processed_X_train,  train_mask])\n",
        "  reconstruc_test = vae.predict([processed_X_test, test_mask])\n",
        "\n",
        "  mse = 0\n",
        "  mae = 0\n",
        "\n",
        "  #print(mask_X_test_imputed[1])\n",
        "  masked_reconstruction = tf.math.multiply(reconstruc_test, test_mask)\n",
        "\n",
        "  for i in range(processed_X_test.shape[0]):\n",
        "    mse += np.sum(np.square(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
        "    mae += np.sum(np.absolute(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
        "\n",
        "\n",
        "  print(\"test mse: \", mse / processed_X_test.shape[0])\n",
        "  print(\"test mae: \", mae / processed_X_test.shape[0], \"\\n\")\n",
        "\n",
        "  return model, reconstruc_train, reconstruc_test\n"
      ],
      "metadata": {
        "id": "pwKhQRmD8sWn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_masked_eval(X, vae):\n",
        "  # Creating a random mask for evaluation of imputation \n",
        "\n",
        "  iter = 50\n",
        "  mse_list = []\n",
        "  mae_list = []\n",
        "\n",
        "  n_samples = X.shape[0]\n",
        "\n",
        "  rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "  mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "  rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
        "\n",
        "  for j in range(iter):\n",
        "\n",
        "    for i in range(rand_X_imputed.shape[0]):\n",
        "      rand_mask[i] = np.random.randint(2, size=(48, 35))\n",
        "\n",
        "    mse = 0\n",
        "    mae = 0\n",
        "\n",
        "    # Actual mask of observations for comparison\n",
        "    mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
        "    mask_X = np.where(np.isnan(X), 0, 1)\n",
        "    # Random mask for evaluation\n",
        "    rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
        "    #print(rand_X_test_imputed[i])\n",
        "\n",
        "    #print(mask_X_test_imputed[i].shape)\n",
        "\n",
        "    # imputing on the random mask data\n",
        "    imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=1)\n",
        "    rand_X_imputed = imputated_data\n",
        "    \n",
        "    #print(rand_X_test_imputed)\n",
        "\n",
        "\n",
        "    rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
        "      \n",
        "    for i in range(rand_X_imputed.shape[0]):\n",
        "      # mse += np.mean(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
        "      # mae += np.mean(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
        "      mse += np.sum(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(mask_X[i])\n",
        "      mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(mask_X[i])\n",
        "\n",
        "    mse_list.append(mse / n_samples)\n",
        "    mae_list.append(mae / n_samples)\n",
        "\n",
        "\n",
        "  print(\"mse:\")\n",
        "  print(np.mean(mse_list))\n",
        "  print(np.var(mse_list), \"\\n\")\n",
        "\n",
        "\n",
        "  print(\"mae:\")\n",
        "  print(np.mean(mae_list))\n",
        "  print(np.var(mae_list), \"\\n\")"
      ],
      "metadata": {
        "id": "TxadxrVYByDt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cnn-vae: \")\n",
        "trained_cnn_vae_model, cnn_reconstruc_train, cnn_reconstruc_test = train_eval_vae_model(cnn_vae_model, \n",
        "                                                processed_X_train, processed_X_test, train_mask, test_mask)\n",
        "vae_masked_eval(X, trained_cnn_vae_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8AlPXRZ-Uuh",
        "outputId": "aab1c819-900d-4ed6-ba44-30948a246388"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn-vae: \n",
            "Epoch 1/1000\n",
            "99/99 [==============================] - 1s 3ms/step - loss: 43.3551\n",
            "Epoch 2/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 43.2452\n",
            "Epoch 3/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 42.8901\n",
            "Epoch 4/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 42.7188\n",
            "Epoch 5/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 42.7022\n",
            "Epoch 6/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 42.3797\n",
            "Epoch 7/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 41.6282\n",
            "Epoch 8/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 40.6596\n",
            "Epoch 9/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 40.1491\n",
            "Epoch 10/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 39.3315\n",
            "Epoch 11/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 39.1230\n",
            "Epoch 12/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 38.1963\n",
            "Epoch 13/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 37.9234\n",
            "Epoch 14/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 37.7753\n",
            "Epoch 15/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 37.5844\n",
            "Epoch 16/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 37.0348\n",
            "Epoch 17/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 36.5986\n",
            "Epoch 18/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 36.2145\n",
            "Epoch 19/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 36.2383\n",
            "Epoch 20/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 35.8852\n",
            "Epoch 21/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 35.5410\n",
            "Epoch 22/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 34.6742\n",
            "Epoch 23/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 34.7234\n",
            "Epoch 24/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 33.8317\n",
            "Epoch 25/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 33.6504\n",
            "Epoch 26/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 33.7743\n",
            "Epoch 27/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 33.0745\n",
            "Epoch 28/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 33.0402\n",
            "Epoch 29/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.8992\n",
            "Epoch 30/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.7339\n",
            "Epoch 31/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.4373\n",
            "Epoch 32/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 32.2683\n",
            "Epoch 33/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.0968\n",
            "Epoch 34/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.2848\n",
            "Epoch 35/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 32.2050\n",
            "Epoch 36/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.9003\n",
            "Epoch 37/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.8261\n",
            "Epoch 38/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.7250\n",
            "Epoch 39/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.7839\n",
            "Epoch 40/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.5893\n",
            "Epoch 41/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.4090\n",
            "Epoch 42/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.4341\n",
            "Epoch 43/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.3526\n",
            "Epoch 44/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.5169\n",
            "Epoch 45/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.1262\n",
            "Epoch 46/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.3514\n",
            "Epoch 47/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.1868\n",
            "Epoch 48/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.2532\n",
            "Epoch 49/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.4538\n",
            "Epoch 50/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 31.1311\n",
            "Epoch 51/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.1999\n",
            "Epoch 52/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.9286\n",
            "Epoch 53/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.9114\n",
            "Epoch 54/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.9654\n",
            "Epoch 55/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 31.0018\n",
            "Epoch 56/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.6545\n",
            "Epoch 57/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.8527\n",
            "Epoch 58/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.7327\n",
            "Epoch 59/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.8583\n",
            "Epoch 60/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.7153\n",
            "Epoch 61/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.5168\n",
            "Epoch 62/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.8587\n",
            "Epoch 63/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.5871\n",
            "Epoch 64/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.6718\n",
            "Epoch 65/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.4139\n",
            "Epoch 66/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.7134\n",
            "Epoch 67/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.4713\n",
            "Epoch 68/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.6297\n",
            "Epoch 69/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.3697\n",
            "Epoch 70/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.3010\n",
            "Epoch 71/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.4741\n",
            "Epoch 72/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.2885\n",
            "Epoch 73/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.3572\n",
            "Epoch 74/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.3217\n",
            "Epoch 75/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 30.3597\n",
            "Epoch 76/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.1561\n",
            "Epoch 77/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.0942\n",
            "Epoch 78/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.9262\n",
            "Epoch 79/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.2394\n",
            "Epoch 80/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.8245\n",
            "Epoch 81/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.8948\n",
            "Epoch 82/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.9413\n",
            "Epoch 83/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 30.0551\n",
            "Epoch 84/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.9537\n",
            "Epoch 85/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.7631\n",
            "Epoch 86/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.8302\n",
            "Epoch 87/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.7023\n",
            "Epoch 88/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.7294\n",
            "Epoch 89/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.9551\n",
            "Epoch 90/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.5842\n",
            "Epoch 91/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.4529\n",
            "Epoch 92/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.5410\n",
            "Epoch 93/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.4780\n",
            "Epoch 94/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.2181\n",
            "Epoch 95/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.3809\n",
            "Epoch 96/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.5771\n",
            "Epoch 97/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.3041\n",
            "Epoch 98/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.0681\n",
            "Epoch 99/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.1539\n",
            "Epoch 100/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.2488\n",
            "Epoch 101/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.8506\n",
            "Epoch 102/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.1648\n",
            "Epoch 103/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 29.0116\n",
            "Epoch 104/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 29.1263\n",
            "Epoch 105/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.8109\n",
            "Epoch 106/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.9754\n",
            "Epoch 107/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.9225\n",
            "Epoch 108/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.9235\n",
            "Epoch 109/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.7878\n",
            "Epoch 110/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.6204\n",
            "Epoch 111/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.9817\n",
            "Epoch 112/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.7575\n",
            "Epoch 113/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.4078\n",
            "Epoch 114/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.6190\n",
            "Epoch 115/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.8137\n",
            "Epoch 116/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.8912\n",
            "Epoch 117/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.6308\n",
            "Epoch 118/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.4719\n",
            "Epoch 119/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.3955\n",
            "Epoch 120/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.4585\n",
            "Epoch 121/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.5972\n",
            "Epoch 122/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.3288\n",
            "Epoch 123/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.3774\n",
            "Epoch 124/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.4823\n",
            "Epoch 125/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.1981\n",
            "Epoch 126/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.3901\n",
            "Epoch 127/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.2629\n",
            "Epoch 128/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.1935\n",
            "Epoch 129/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.1478\n",
            "Epoch 130/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.3820\n",
            "Epoch 131/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.3104\n",
            "Epoch 132/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.0572\n",
            "Epoch 133/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.0848\n",
            "Epoch 134/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.1043\n",
            "Epoch 135/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.0791\n",
            "Epoch 136/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.0614\n",
            "Epoch 137/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.3924\n",
            "Epoch 138/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.2304\n",
            "Epoch 139/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.0393\n",
            "Epoch 140/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.9294\n",
            "Epoch 141/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.0556\n",
            "Epoch 142/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 28.0062\n",
            "Epoch 143/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.9964\n",
            "Epoch 144/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.9049\n",
            "Epoch 145/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.9216\n",
            "Epoch 146/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.8321\n",
            "Epoch 147/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.9723\n",
            "Epoch 148/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.9178\n",
            "Epoch 149/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 28.1169\n",
            "Epoch 150/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.8826\n",
            "Epoch 151/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.9458\n",
            "Epoch 152/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.8377\n",
            "Epoch 153/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.7148\n",
            "Epoch 154/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.8902\n",
            "Epoch 155/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6479\n",
            "Epoch 156/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.6662\n",
            "Epoch 157/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6240\n",
            "Epoch 158/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.9079\n",
            "Epoch 159/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.7485\n",
            "Epoch 160/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.8912\n",
            "Epoch 161/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.8179\n",
            "Epoch 162/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6399\n",
            "Epoch 163/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6353\n",
            "Epoch 164/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6467\n",
            "Epoch 165/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.5778\n",
            "Epoch 166/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.8065\n",
            "Epoch 167/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6367\n",
            "Epoch 168/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.8442\n",
            "Epoch 169/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.5146\n",
            "Epoch 170/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.5661\n",
            "Epoch 171/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.5045\n",
            "Epoch 172/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6074\n",
            "Epoch 173/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4796\n",
            "Epoch 174/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.6708\n",
            "Epoch 175/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6485\n",
            "Epoch 176/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4909\n",
            "Epoch 177/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4522\n",
            "Epoch 178/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6344\n",
            "Epoch 179/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.6162\n",
            "Epoch 180/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3983\n",
            "Epoch 181/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4570\n",
            "Epoch 182/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.7095\n",
            "Epoch 183/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3723\n",
            "Epoch 184/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4378\n",
            "Epoch 185/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.4467\n",
            "Epoch 186/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.4099\n",
            "Epoch 187/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.6376\n",
            "Epoch 188/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3775\n",
            "Epoch 189/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.3632\n",
            "Epoch 190/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.6394\n",
            "Epoch 191/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3088\n",
            "Epoch 192/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3652\n",
            "Epoch 193/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.4401\n",
            "Epoch 194/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4691\n",
            "Epoch 195/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3059\n",
            "Epoch 196/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4546\n",
            "Epoch 197/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.4054\n",
            "Epoch 198/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2510\n",
            "Epoch 199/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2125\n",
            "Epoch 200/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2429\n",
            "Epoch 201/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3576\n",
            "Epoch 202/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3417\n",
            "Epoch 203/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.4466\n",
            "Epoch 204/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2572\n",
            "Epoch 205/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2691\n",
            "Epoch 206/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3538\n",
            "Epoch 207/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3844\n",
            "Epoch 208/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3050\n",
            "Epoch 209/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2758\n",
            "Epoch 210/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1945\n",
            "Epoch 211/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3108\n",
            "Epoch 212/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.5596\n",
            "Epoch 213/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1693\n",
            "Epoch 214/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.3465\n",
            "Epoch 215/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1917\n",
            "Epoch 216/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2338\n",
            "Epoch 217/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.1894\n",
            "Epoch 218/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2014\n",
            "Epoch 219/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2015\n",
            "Epoch 220/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1018\n",
            "Epoch 221/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.2119\n",
            "Epoch 222/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.4378\n",
            "Epoch 223/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.1303\n",
            "Epoch 224/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1872\n",
            "Epoch 225/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.1182\n",
            "Epoch 226/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2108\n",
            "Epoch 227/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1251\n",
            "Epoch 228/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0037\n",
            "Epoch 229/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.1123\n",
            "Epoch 230/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1243\n",
            "Epoch 231/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0978\n",
            "Epoch 232/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 26.9810\n",
            "Epoch 233/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2625\n",
            "Epoch 234/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0129\n",
            "Epoch 235/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2887\n",
            "Epoch 236/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0620\n",
            "Epoch 237/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0371\n",
            "Epoch 238/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0606\n",
            "Epoch 239/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0120\n",
            "Epoch 240/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0677\n",
            "Epoch 241/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 26.9694\n",
            "Epoch 242/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1937\n",
            "Epoch 243/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2662\n",
            "Epoch 244/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 26.9988\n",
            "Epoch 245/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0634\n",
            "Epoch 246/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 26.9746\n",
            "Epoch 247/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0425\n",
            "Epoch 248/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1692\n",
            "Epoch 249/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1396\n",
            "Epoch 250/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0547\n",
            "Epoch 251/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0257\n",
            "Epoch 252/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 26.9741\n",
            "Epoch 253/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.2156\n",
            "Epoch 254/1000\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.1677\n",
            "Epoch 255/1000\n",
            "99/99 [==============================] - 0s 2ms/step - loss: 27.0906\n",
            "Epoch 256/1000\n",
            "97/99 [============================>.] - ETA: 0s - loss: 26.7272Restoring model weights from the end of the best epoch: 241.\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 27.0112\n",
            "Epoch 256: early stopping\n",
            "test mse:  1.9291052010242824\n",
            "test mae:  0.8889287581620461 \n",
            "\n",
            "mse:\n",
            "0.9101994067087218\n",
            "0.00023765296109603534 \n",
            "\n",
            "mae:\n",
            "0.6507138300306362\n",
            "8.268224413844063e-05 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lstm-vae: \")\n",
        "trained_lstm_vae_model, lstm_reconstruc_train, lstm_reconstruc_test = train_eval_vae_model(lstm_vae_model, \n",
        "                                                processed_X_train, processed_X_test, train_mask, test_mask)\n",
        "vae_masked_eval(X, trained_lstm_vae_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF-rWxjfChjA",
        "outputId": "de04f152-1b16-44e8-c28b-05a64f24f34a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm-vae: \n",
            "Epoch 1/1000\n",
            "99/99 [==============================] - 7s 35ms/step - loss: 42.9428\n",
            "Epoch 2/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 42.0328\n",
            "Epoch 3/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 40.4639\n",
            "Epoch 4/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 40.1325\n",
            "Epoch 5/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 39.5105\n",
            "Epoch 6/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 39.3465\n",
            "Epoch 7/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 40.3941\n",
            "Epoch 8/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 38.5145\n",
            "Epoch 9/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 37.3661\n",
            "Epoch 10/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 37.7065\n",
            "Epoch 11/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 37.5213\n",
            "Epoch 12/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 37.4884\n",
            "Epoch 13/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 36.4912\n",
            "Epoch 14/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 35.2227\n",
            "Epoch 15/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 35.0149\n",
            "Epoch 16/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 34.9725\n",
            "Epoch 17/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 34.5052\n",
            "Epoch 18/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 33.5973\n",
            "Epoch 19/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 33.8857\n",
            "Epoch 20/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 34.0291\n",
            "Epoch 21/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 34.4471\n",
            "Epoch 22/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 33.4400\n",
            "Epoch 23/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 32.4782\n",
            "Epoch 24/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 32.6292\n",
            "Epoch 25/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 32.6530\n",
            "Epoch 26/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 32.5467\n",
            "Epoch 27/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 32.1136\n",
            "Epoch 28/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 32.1986\n",
            "Epoch 29/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 32.0534\n",
            "Epoch 30/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 31.9622\n",
            "Epoch 31/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 31.6392\n",
            "Epoch 32/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 31.1187\n",
            "Epoch 33/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 31.2759\n",
            "Epoch 34/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 30.7263\n",
            "Epoch 35/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 29.9007\n",
            "Epoch 36/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 29.9679\n",
            "Epoch 37/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 30.1815\n",
            "Epoch 38/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 30.4556\n",
            "Epoch 39/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 29.7359\n",
            "Epoch 40/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 29.5811\n",
            "Epoch 41/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 29.1308\n",
            "Epoch 42/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 29.1530\n",
            "Epoch 43/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.4298\n",
            "Epoch 44/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 29.4241\n",
            "Epoch 45/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.7716\n",
            "Epoch 46/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 27.8858\n",
            "Epoch 47/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 28.0387\n",
            "Epoch 48/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.9628\n",
            "Epoch 49/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.6665\n",
            "Epoch 50/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.0069\n",
            "Epoch 51/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 29.3410\n",
            "Epoch 52/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 27.5754\n",
            "Epoch 53/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 27.4290\n",
            "Epoch 54/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 27.2036\n",
            "Epoch 55/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.6350\n",
            "Epoch 56/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.3696\n",
            "Epoch 57/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 27.4824\n",
            "Epoch 58/1000\n",
            "99/99 [==============================] - 3s 32ms/step - loss: 31.8337\n",
            "Epoch 59/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 32.8676\n",
            "Epoch 60/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 31.0393\n",
            "Epoch 61/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.3948\n",
            "Epoch 62/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 28.2455\n",
            "Epoch 63/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 27.1312\n",
            "Epoch 64/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 26.9752\n",
            "Epoch 65/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.4701\n",
            "Epoch 66/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 26.3992\n",
            "Epoch 67/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.9964\n",
            "Epoch 68/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.4636\n",
            "Epoch 69/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.8778\n",
            "Epoch 70/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.8380\n",
            "Epoch 71/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 25.3720\n",
            "Epoch 72/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 26.2674\n",
            "Epoch 73/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 26.7678\n",
            "Epoch 74/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.4881\n",
            "Epoch 75/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.5200\n",
            "Epoch 76/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.9873\n",
            "Epoch 77/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.8803\n",
            "Epoch 78/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.6955\n",
            "Epoch 79/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.8148\n",
            "Epoch 80/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.6327\n",
            "Epoch 81/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.0912\n",
            "Epoch 82/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 27.9173\n",
            "Epoch 83/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.0081\n",
            "Epoch 84/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.7170\n",
            "Epoch 85/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.0633\n",
            "Epoch 86/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 25.1103\n",
            "Epoch 87/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.1154\n",
            "Epoch 88/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 23.1800\n",
            "Epoch 89/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.5943\n",
            "Epoch 90/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 23.2690\n",
            "Epoch 91/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 23.1836\n",
            "Epoch 92/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 23.6256\n",
            "Epoch 93/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.4484\n",
            "Epoch 94/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.9368\n",
            "Epoch 95/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.8089\n",
            "Epoch 96/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.3397\n",
            "Epoch 97/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 22.6445\n",
            "Epoch 98/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 23.9293\n",
            "Epoch 99/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.7332\n",
            "Epoch 100/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 22.9860\n",
            "Epoch 101/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 22.7028\n",
            "Epoch 102/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.2324\n",
            "Epoch 103/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.9357\n",
            "Epoch 104/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.2211\n",
            "Epoch 105/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.0331\n",
            "Epoch 106/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.7738\n",
            "Epoch 107/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.9262\n",
            "Epoch 108/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.6715\n",
            "Epoch 109/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.9526\n",
            "Epoch 110/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.3597\n",
            "Epoch 111/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.0274\n",
            "Epoch 112/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.7535\n",
            "Epoch 113/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.5835\n",
            "Epoch 114/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.4775\n",
            "Epoch 115/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.7738\n",
            "Epoch 116/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.0796\n",
            "Epoch 117/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.9121\n",
            "Epoch 118/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.7242\n",
            "Epoch 119/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.3095\n",
            "Epoch 120/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.1343\n",
            "Epoch 121/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.7807\n",
            "Epoch 122/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.7042\n",
            "Epoch 123/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.2834\n",
            "Epoch 124/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.0443\n",
            "Epoch 125/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.3997\n",
            "Epoch 126/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.5387\n",
            "Epoch 127/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.4324\n",
            "Epoch 128/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.0395\n",
            "Epoch 129/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 26.8605\n",
            "Epoch 130/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 23.8591\n",
            "Epoch 131/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.4010\n",
            "Epoch 132/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.4915\n",
            "Epoch 133/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.9313\n",
            "Epoch 134/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.7952\n",
            "Epoch 135/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.9483\n",
            "Epoch 136/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.6848\n",
            "Epoch 137/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.7944\n",
            "Epoch 138/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.6441\n",
            "Epoch 139/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.5059\n",
            "Epoch 140/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.2424\n",
            "Epoch 141/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 23.5551\n",
            "Epoch 142/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.9279\n",
            "Epoch 143/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.6083\n",
            "Epoch 144/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.3059\n",
            "Epoch 145/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 19.9190\n",
            "Epoch 146/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 19.4610\n",
            "Epoch 147/1000\n",
            "99/99 [==============================] - 3s 35ms/step - loss: 20.0117\n",
            "Epoch 148/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.2291\n",
            "Epoch 149/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.6897\n",
            "Epoch 150/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.9223\n",
            "Epoch 151/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.6620\n",
            "Epoch 152/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.6261\n",
            "Epoch 153/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.4884\n",
            "Epoch 154/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.2450\n",
            "Epoch 155/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 18.9885\n",
            "Epoch 156/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.8009\n",
            "Epoch 157/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 19.6876\n",
            "Epoch 158/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.8792\n",
            "Epoch 159/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.8193\n",
            "Epoch 160/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.3895\n",
            "Epoch 161/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 19.1080\n",
            "Epoch 162/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.7327\n",
            "Epoch 163/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 18.6674\n",
            "Epoch 164/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.9882\n",
            "Epoch 165/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.4499\n",
            "Epoch 166/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.3235\n",
            "Epoch 167/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.9138\n",
            "Epoch 168/1000\n",
            "99/99 [==============================] - 3s 35ms/step - loss: 18.8647\n",
            "Epoch 169/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.2070\n",
            "Epoch 170/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 18.2264\n",
            "Epoch 171/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 19.2342\n",
            "Epoch 172/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.0944\n",
            "Epoch 173/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.2780\n",
            "Epoch 174/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.0512\n",
            "Epoch 175/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.5900\n",
            "Epoch 176/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 21.2058\n",
            "Epoch 177/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 20.4516\n",
            "Epoch 178/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 20.1782\n",
            "Epoch 179/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 19.7116\n",
            "Epoch 180/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 21.2503\n",
            "Epoch 181/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 22.7142\n",
            "Epoch 182/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 25.1950\n",
            "Epoch 183/1000\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 23.2885\n",
            "Epoch 184/1000\n",
            "99/99 [==============================] - 3s 34ms/step - loss: 25.1854\n",
            "Epoch 185/1000\n",
            "99/99 [==============================] - ETA: 0s - loss: 24.3323Restoring model weights from the end of the best epoch: 170.\n",
            "99/99 [==============================] - 3s 33ms/step - loss: 24.3323\n",
            "Epoch 185: early stopping\n",
            "test mse:  1.9465106612092982\n",
            "test mae:  0.8466588934306891 \n",
            "\n",
            "mse:\n",
            "0.7941060344907345\n",
            "0.0004563792457514932 \n",
            "\n",
            "mae:\n",
            "0.5601755740480691\n",
            "0.00013973330953785887 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cnn-lstm-vae: \")\n",
        "trained_cnn_lstm_vae_model, cnn_lstm_reconstruc_train, cnn_lstm_reconstruc_test = train_eval_vae_model(cnn_lstm_vae_model, \n",
        "                                                processed_X_train, processed_X_test, train_mask, test_mask)\n",
        "vae_masked_eval(X, trained_cnn_lstm_vae_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWWUJ7IQCj9t",
        "outputId": "25cac071-1f74-4b97-e040-db4f35d418e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn-lstm-vae: \n",
            "Epoch 1/1000\n",
            "99/99 [==============================] - 5s 25ms/step - loss: 43.1267\n",
            "Epoch 2/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 42.7210\n",
            "Epoch 3/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 42.5470\n",
            "Epoch 4/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 41.6271\n",
            "Epoch 5/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 41.3181\n",
            "Epoch 6/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 40.2183\n",
            "Epoch 7/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 39.2659\n",
            "Epoch 8/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 38.5638\n",
            "Epoch 9/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 38.3794\n",
            "Epoch 10/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 38.0855\n",
            "Epoch 11/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 38.2819\n",
            "Epoch 12/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 37.6980\n",
            "Epoch 13/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 37.4664\n",
            "Epoch 14/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 37.7626\n",
            "Epoch 15/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.8464\n",
            "Epoch 16/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 37.0517\n",
            "Epoch 17/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.9712\n",
            "Epoch 18/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 36.6604\n",
            "Epoch 19/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.8967\n",
            "Epoch 20/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.6056\n",
            "Epoch 21/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 36.1292\n",
            "Epoch 22/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.1108\n",
            "Epoch 23/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.2993\n",
            "Epoch 24/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 36.2406\n",
            "Epoch 25/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 35.8608\n",
            "Epoch 26/1000\n",
            "99/99 [==============================] - 2s 23ms/step - loss: 35.7508\n",
            "Epoch 27/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 35.8922\n",
            "Epoch 28/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 35.5729\n",
            "Epoch 29/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 35.6563\n",
            "Epoch 30/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 35.3744\n",
            "Epoch 31/1000\n",
            "99/99 [==============================] - 2s 24ms/step - loss: 35.0831\n",
            "Epoch 32/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 35.1361\n",
            "Epoch 33/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.9511\n",
            "Epoch 34/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.8198\n",
            "Epoch 35/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.8731\n",
            "Epoch 36/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 34.9430\n",
            "Epoch 37/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 34.8358\n",
            "Epoch 38/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.6098\n",
            "Epoch 39/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.5412\n",
            "Epoch 40/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.3125\n",
            "Epoch 41/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.1939\n",
            "Epoch 42/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 33.9264\n",
            "Epoch 43/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 34.4312\n",
            "Epoch 44/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 34.0190\n",
            "Epoch 45/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 33.7821\n",
            "Epoch 46/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 33.3923\n",
            "Epoch 47/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 33.4595\n",
            "Epoch 48/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 33.3041\n",
            "Epoch 49/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 33.2136\n",
            "Epoch 50/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.9931\n",
            "Epoch 51/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 33.1468\n",
            "Epoch 52/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 33.1804\n",
            "Epoch 53/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.8089\n",
            "Epoch 54/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.7421\n",
            "Epoch 55/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.9201\n",
            "Epoch 56/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.7307\n",
            "Epoch 57/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.4427\n",
            "Epoch 58/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.7262\n",
            "Epoch 59/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.6993\n",
            "Epoch 60/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 32.3111\n",
            "Epoch 61/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.2730\n",
            "Epoch 62/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.2615\n",
            "Epoch 63/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.8375\n",
            "Epoch 64/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 31.9425\n",
            "Epoch 65/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.7767\n",
            "Epoch 66/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.9617\n",
            "Epoch 67/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.9537\n",
            "Epoch 68/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.9887\n",
            "Epoch 69/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.3447\n",
            "Epoch 70/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.4065\n",
            "Epoch 71/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.5483\n",
            "Epoch 72/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.5718\n",
            "Epoch 73/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.5179\n",
            "Epoch 74/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.0340\n",
            "Epoch 75/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 32.1793\n",
            "Epoch 76/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.8414\n",
            "Epoch 77/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.4426\n",
            "Epoch 78/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.0538\n",
            "Epoch 79/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.2168\n",
            "Epoch 80/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.8349\n",
            "Epoch 81/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.9003\n",
            "Epoch 82/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.0604\n",
            "Epoch 83/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.7644\n",
            "Epoch 84/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 30.2595\n",
            "Epoch 85/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 30.7746\n",
            "Epoch 86/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 31.1157\n",
            "Epoch 87/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 31.7828\n",
            "Epoch 88/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 32.8153\n",
            "Epoch 89/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 31.3079\n",
            "Epoch 90/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 30.9367\n",
            "Epoch 91/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.5287\n",
            "Epoch 92/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.4559\n",
            "Epoch 93/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9781\n",
            "Epoch 94/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9062\n",
            "Epoch 95/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9704\n",
            "Epoch 96/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9283\n",
            "Epoch 97/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 30.3486\n",
            "Epoch 98/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.3616\n",
            "Epoch 99/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9560\n",
            "Epoch 100/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.8757\n",
            "Epoch 101/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.7783\n",
            "Epoch 102/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.1375\n",
            "Epoch 103/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.4272\n",
            "Epoch 104/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.3006\n",
            "Epoch 105/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.2439\n",
            "Epoch 106/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.6316\n",
            "Epoch 107/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 29.8428\n",
            "Epoch 108/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.8261\n",
            "Epoch 109/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.5775\n",
            "Epoch 110/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.3630\n",
            "Epoch 111/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 29.5397\n",
            "Epoch 112/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.7518\n",
            "Epoch 113/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.9300\n",
            "Epoch 114/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.9662\n",
            "Epoch 115/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 29.6293\n",
            "Epoch 116/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.3484\n",
            "Epoch 117/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.5391\n",
            "Epoch 118/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.8314\n",
            "Epoch 119/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.7479\n",
            "Epoch 120/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.2368\n",
            "Epoch 121/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.8343\n",
            "Epoch 122/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.6904\n",
            "Epoch 123/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.5344\n",
            "Epoch 124/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.5770\n",
            "Epoch 125/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.0496\n",
            "Epoch 126/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.7871\n",
            "Epoch 127/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.0017\n",
            "Epoch 128/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.1411\n",
            "Epoch 129/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.0305\n",
            "Epoch 130/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.2869\n",
            "Epoch 131/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.9702\n",
            "Epoch 132/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.1771\n",
            "Epoch 133/1000\n",
            "99/99 [==============================] - 3s 28ms/step - loss: 29.1194\n",
            "Epoch 134/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.3571\n",
            "Epoch 135/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.2320\n",
            "Epoch 136/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.0587\n",
            "Epoch 137/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.4744\n",
            "Epoch 138/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.7222\n",
            "Epoch 139/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.8464\n",
            "Epoch 140/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.9008\n",
            "Epoch 141/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.7720\n",
            "Epoch 142/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.4290\n",
            "Epoch 143/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.5207\n",
            "Epoch 144/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 30.4566\n",
            "Epoch 145/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.6152\n",
            "Epoch 146/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.3533\n",
            "Epoch 147/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 29.1671\n",
            "Epoch 148/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.6753\n",
            "Epoch 149/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.9748\n",
            "Epoch 150/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.9420\n",
            "Epoch 151/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.4347\n",
            "Epoch 152/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.5876\n",
            "Epoch 153/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.2407\n",
            "Epoch 154/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.2421\n",
            "Epoch 155/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.5905\n",
            "Epoch 156/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.3451\n",
            "Epoch 157/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.3225\n",
            "Epoch 158/1000\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 28.4084\n",
            "Epoch 159/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.6336\n",
            "Epoch 160/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.8835\n",
            "Epoch 161/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 28.4262\n",
            "Epoch 162/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.3028\n",
            "Epoch 163/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.9845\n",
            "Epoch 164/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 28.8832\n",
            "Epoch 165/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.0448\n",
            "Epoch 166/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.9684\n",
            "Epoch 167/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.8353\n",
            "Epoch 168/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.5681\n",
            "Epoch 169/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.7709\n",
            "Epoch 170/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.6334\n",
            "Epoch 171/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.6399\n",
            "Epoch 172/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.9804\n",
            "Epoch 173/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 28.7678\n",
            "Epoch 174/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.2366\n",
            "Epoch 175/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.3299\n",
            "Epoch 176/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 29.2500\n",
            "Epoch 177/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.3546\n",
            "Epoch 178/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.9110\n",
            "Epoch 179/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.1996\n",
            "Epoch 180/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.4525\n",
            "Epoch 181/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.5319\n",
            "Epoch 182/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.4706\n",
            "Epoch 183/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.7475\n",
            "Epoch 184/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 28.8134\n",
            "Epoch 185/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.7413\n",
            "Epoch 186/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 29.9332\n",
            "Epoch 187/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.9044\n",
            "Epoch 188/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.5773\n",
            "Epoch 189/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.9897\n",
            "Epoch 190/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.4337\n",
            "Epoch 191/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.5172\n",
            "Epoch 192/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.2937\n",
            "Epoch 193/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.4005\n",
            "Epoch 194/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.2223\n",
            "Epoch 195/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.0170\n",
            "Epoch 196/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.3488\n",
            "Epoch 197/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 26.9008\n",
            "Epoch 198/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.6487\n",
            "Epoch 199/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.3327\n",
            "Epoch 200/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.0249\n",
            "Epoch 201/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 26.7683\n",
            "Epoch 202/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.1203\n",
            "Epoch 203/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 26.9830\n",
            "Epoch 204/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.9745\n",
            "Epoch 205/1000\n",
            "99/99 [==============================] - 2s 25ms/step - loss: 27.4440\n",
            "Epoch 206/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.2709\n",
            "Epoch 207/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.5068\n",
            "Epoch 208/1000\n",
            "99/99 [==============================] - 3s 25ms/step - loss: 27.8913\n",
            "Epoch 209/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.3169\n",
            "Epoch 210/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.0887\n",
            "Epoch 211/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.1331\n",
            "Epoch 212/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.6398\n",
            "Epoch 213/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.0796\n",
            "Epoch 214/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.8039\n",
            "Epoch 215/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.3874\n",
            "Epoch 216/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.4569\n",
            "Epoch 217/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.7506\n",
            "Epoch 218/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 28.0216\n",
            "Epoch 219/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.2383\n",
            "Epoch 220/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.5510\n",
            "Epoch 221/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.4318\n",
            "Epoch 222/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.5448\n",
            "Epoch 223/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.1212\n",
            "Epoch 224/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.5975\n",
            "Epoch 225/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.6861\n",
            "Epoch 226/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.7295\n",
            "Epoch 227/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.6865\n",
            "Epoch 228/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.7942\n",
            "Epoch 229/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.5123\n",
            "Epoch 230/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.2929\n",
            "Epoch 231/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.7074\n",
            "Epoch 232/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.9673\n",
            "Epoch 233/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.9125\n",
            "Epoch 234/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.4158\n",
            "Epoch 235/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.4263\n",
            "Epoch 236/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 27.8074\n",
            "Epoch 237/1000\n",
            "99/99 [==============================] - 3s 26ms/step - loss: 26.4871\n",
            "Epoch 238/1000\n",
            "98/99 [============================>.] - ETA: 0s - loss: 26.4353Restoring model weights from the end of the best epoch: 223.\n",
            "99/99 [==============================] - 3s 27ms/step - loss: 26.3365\n",
            "Epoch 238: early stopping\n",
            "test mse:  1.9710764642617853\n",
            "test mae:  0.9261620226559182 \n",
            "\n",
            "mse:\n",
            "0.9922033546105129\n",
            "0.00046105999641555775 \n",
            "\n",
            "mae:\n",
            "0.683867407468815\n",
            "0.00014411660879017226 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 19\n",
        "b = 12\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(cnn_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
        "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "ZZ7l1FCGkn69",
        "outputId": "9baf3100-6d87-4545-f7ad-673cf2a5bc74"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4cabb5e50>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(lstm_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
        "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "TCGufV0mk3kO",
        "outputId": "75068835-f335-423c-cf75-3610f8def729"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4cab95110>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(cnn_lstm_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
        "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "na86HbAuk3t9",
        "outputId": "630d52d2-f46d-4211-fb5c-22a7ccb56557"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4cab0e7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def imputed_vae_data(X_train, X_test, reconstruc_train, reconstruc_test):\n",
        "  \n",
        "  X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "\n",
        "  # Impute original with reconstruction\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        if np.isnan(X_train[i,j,k]):\n",
        "          X_train_imputed[i,j,k] = reconstruc_train[i,j,k]\n",
        "        else:\n",
        "          X_train_imputed[i,j,k] = X_train[i,j,k]\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        if np.isnan(X_test[i,j,k]):\n",
        "          X_test_imputed[i,j,k] = reconstruc_test[i,j,k]\n",
        "        else:\n",
        "          X_test_imputed[i,j,k] = X_test[i,j,k]\n",
        "\n",
        "  return X_train_imputed, X_test_imputed"
      ],
      "metadata": {
        "id": "-dvIbnsBCkG6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_X_train_imputed, cnn_X_test_imputed = imputed_vae_data(X_train, X_test, cnn_reconstruc_train, cnn_reconstruc_test)\n",
        "lstm_X_train_imputed, lstm_X_test_imputed = imputed_vae_data(X_train, X_test, lstm_reconstruc_train, lstm_reconstruc_test)\n",
        "cnn_lstm_X_train_imputed, cnn_lstm_X_test_imputed = imputed_vae_data(X_train, X_test, cnn_lstm_reconstruc_train, cnn_lstm_reconstruc_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "aDMMIX0bE0gH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readm_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
        "  readm_X_train = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  readm_X_test = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        readm_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        readm_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
        "\n",
        "\n",
        "\n",
        "  readm_y_train = y_train['readmission_label']\n",
        "  readm_y_test = y_test['readmission_label']\n",
        "\n",
        "\n",
        "  rm_idx_train = []\n",
        "  rm_idx_test = []\n",
        "\n",
        "\n",
        "  for i in range(readm_X_train.shape[0]):\n",
        "    if np.isnan(y_train['readmission_label'].values[i]) or y_train['death_label'].values[i] == 1:\n",
        "      rm_idx_train.append(i)\n",
        "\n",
        "  for i in range(readm_X_test.shape[0]):\n",
        "    if np.isnan(y_test['readmission_label'].values[i]) or y_train['death_label'].values[i] == 1:\n",
        "      rm_idx_test.append(i)\n",
        "\n",
        "  readm_X_train = np.delete(readm_X_train, rm_idx_train, 0)\n",
        "  readm_y_train = np.delete(np.array(readm_y_train), rm_idx_train, 0)\n",
        "\n",
        "  readm_X_test = np.delete(readm_X_test, rm_idx_test, 0)\n",
        "  readm_y_test = np.delete(np.array(readm_y_test), rm_idx_test, 0)\n",
        "\n",
        "  print(readm_X_train.shape)\n",
        "  print(readm_y_train.shape)\n",
        "\n",
        "  print(readm_X_test.shape)\n",
        "  print(readm_y_test.shape)\n",
        "\n",
        "  print(np.where(readm_y_train == 1))\n",
        "  print(np.where(readm_y_test == 1))  \n",
        "  return readm_X_train, readm_X_test, readm_y_train, readm_y_test"
      ],
      "metadata": {
        "id": "fE44FC8KFaL2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mortality_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
        "  # Processing Data for Mortality\n",
        "  mortality_X_train = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  mortality_X_test = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        mortality_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        mortality_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
        "\n",
        "  mortality_y_train = y_train['death_label']\n",
        "  mortality_y_test = y_test['death_label']\n",
        "\n",
        "\n",
        "  print(np.where(mortality_y_train == 1))\n",
        "  print(np.where(mortality_y_test == 1))\n",
        "  return mortality_X_train, mortality_X_test, mortality_y_train, mortality_y_test"
      ],
      "metadata": {
        "id": "e9Nk7yYjFk_n"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def los_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
        "  # Processing Data for Length of Stay\n",
        "  los_X_train = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
        "  los_X_test = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
        "\n",
        "  for i in range(X_train.shape[0]):\n",
        "    for j in range(X_train.shape[1]):\n",
        "      for k in range(X_train.shape[2]):\n",
        "        los_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
        "\n",
        "\n",
        "  for i in range(X_test.shape[0]):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      for k in range(X_test.shape[2]):\n",
        "        los_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
        "\n",
        "  los_y_train = (y_train['length_of_stay'] - np.full(len(y_train['length_of_stay']), np.mean(y_train['length_of_stay']))) / np.std(y_train['length_of_stay'])\n",
        "  los_y_test = (y_test['length_of_stay'] - np.full(len(y_test['length_of_stay']), np.mean(y_test['length_of_stay']))) / np.std(y_test['length_of_stay'])\n",
        "  \n",
        "\n",
        "  return los_X_train, los_X_test, los_y_train, los_y_test"
      ],
      "metadata": {
        "id": "GNeU2yqMFlHo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Readmission data for each method\n",
        "readm_mean_X_train, readm_mean_X_test, readm_mean_y_train, readm_mean_y_test = readm_preprocessing(X_train_mean_imputed, \n",
        "                                                                               X_test_mean_imputed, y_train, y_test)\n",
        "readm_cnn_X_train, readm_cnn_X_test, readm_cnn_y_train, readm_cnn_y_test = readm_preprocessing(cnn_X_train_imputed, \n",
        "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
        "readm_lstm_X_train, readm_lstm_X_test, readm_lstm_y_train, readm_lstm_y_test = readm_preprocessing(lstm_X_train_imputed, \n",
        "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
        "readm_cnn_lstm_X_train, readm_cnn_lstm_X_test, readm_cnn_lstm_y_train, readm_cnn_lstm_y_test = readm_preprocessing(cnn_lstm_X_train_imputed, \n",
        "                                                                           cnn_lstm_X_test_imputed, y_train, y_test)\n",
        "\n",
        "# Mortality data for each method\n",
        "mortality_mean_X_train, mortality_mean_X_test, mortality_mean_y_train, mortality_mean_y_test = mortality_preprocessing(X_train_mean_imputed, \n",
        "                                                                               X_test_mean_imputed, y_train, y_test)\n",
        "mortality_cnn_X_train, mortality_cnn_X_test, mortality_cnn_y_train, mortality_cnn_y_test = mortality_preprocessing(cnn_X_train_imputed, \n",
        "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
        "mortality_lstm_X_train, mortality_lstm_X_test, mortality_lstm_y_train, mortality_lstm_y_test = mortality_preprocessing(lstm_X_train_imputed, \n",
        "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
        "mortality_cnn_lstm_X_train, mortality_cnn_lstm_X_test, mortality_cnn_lstm_y_train, mortality_cnn_lstm_y_test = mortality_preprocessing(cnn_lstm_X_train_imputed, \n",
        "                                                                           cnn_lstm_X_test_imputed, y_train, y_test)\n",
        "\n",
        "\n",
        "# Length of stay data for each method\n",
        "los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test = los_preprocessing(X_train_mean_imputed, \n",
        "                                                                               X_test_mean_imputed, y_train, y_test)\n",
        "los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test = los_preprocessing(cnn_X_train_imputed, \n",
        "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
        "los_lstm_X_train, los_lstm_X_test, los_lstm_y_train, los_lstm_y_test = los_preprocessing(lstm_X_train_imputed, \n",
        "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
        "los_cnn_lstm_X_train, los_cnn_lstm_X_test, los_cnn_lstm_y_train, los_cnn_lstm_y_test = los_preprocessing(cnn_lstm_X_train_imputed, \n",
        "                                                                           cnn_lstm_X_test_imputed, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BmHqSFHGzPk",
        "outputId": "4b79034b-7e37-40be-a1c0-54249446e136"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(59, 48, 35)\n",
            "(59,)\n",
            "(15, 48, 35)\n",
            "(15,)\n",
            "(array([ 2,  6, 19, 21, 27, 28, 30, 31, 35, 38, 39, 41, 45, 48, 52, 55, 58]),)\n",
            "(array([ 3,  8,  9, 10, 13]),)\n",
            "(59, 48, 35)\n",
            "(59,)\n",
            "(15, 48, 35)\n",
            "(15,)\n",
            "(array([ 2,  6, 19, 21, 27, 28, 30, 31, 35, 38, 39, 41, 45, 48, 52, 55, 58]),)\n",
            "(array([ 3,  8,  9, 10, 13]),)\n",
            "(59, 48, 35)\n",
            "(59,)\n",
            "(15, 48, 35)\n",
            "(15,)\n",
            "(array([ 2,  6, 19, 21, 27, 28, 30, 31, 35, 38, 39, 41, 45, 48, 52, 55, 58]),)\n",
            "(array([ 3,  8,  9, 10, 13]),)\n",
            "(59, 48, 35)\n",
            "(59,)\n",
            "(15, 48, 35)\n",
            "(15,)\n",
            "(array([ 2,  6, 19, 21, 27, 28, 30, 31, 35, 38, 39, 41, 45, 48, 52, 55, 58]),)\n",
            "(array([ 3,  8,  9, 10, 13]),)\n",
            "(array([ 3,  6, 13, 26, 81, 93]),)\n",
            "(array([ 2,  6,  7, 20]),)\n",
            "(array([ 3,  6, 13, 26, 81, 93]),)\n",
            "(array([ 2,  6,  7, 20]),)\n",
            "(array([ 3,  6, 13, 26, 81, 93]),)\n",
            "(array([ 2,  6,  7, 20]),)\n",
            "(array([ 3,  6, 13, 26, 81, 93]),)\n",
            "(array([ 2,  6,  7, 20]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Classification Model\n",
        "\n",
        "es = EarlyStopping(patience=20, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
        "\n",
        "class_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
        "\n",
        "class_model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=[tf.keras.metrics.AUC(from_logits=True), tf.keras.metrics.AUC(curve='PR', from_logits=True)])"
      ],
      "metadata": {
        "id": "OPgncEK1QFNV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Regression Model\n",
        "\n",
        "es = EarlyStopping(patience=20, verbose=1, min_delta=0.001, monitor='loss', mode='auto', restore_best_weights=True)\n",
        "\n",
        "reg_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
        "  tf.keras.layers.Dense(1, activation='relu'),\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "reg_model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
      ],
      "metadata": {
        "id": "dfNt7NW2QRXj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_pred_model(model, batch_size, X_train, X_test, y_train, y_test):\n",
        "  hist = model.fit(X_train, y_train, epochs=100, batch_size=batch_size, verbose=2, callbacks=[es])\n",
        "\n",
        "  model.evaluate(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "_e1K1e2zQWwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Imputation\n",
        "train_eval_pred_model(class_model, 2, readm_mean_X_train, readm_mean_X_test, readm_mean_y_train, readm_mean_y_test)\n",
        "train_eval_pred_model(class_model, 2, mortality_mean_X_train, mortality_mean_X_test, mortality_mean_y_train, mortality_mean_y_test)\n",
        "train_eval_pred_model(reg_model, 1, los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix3RpjX9Q7f5",
        "outputId": "da3fdec7-7e1f-4c52-93c3-6441a6a73fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "31/31 - 2s - loss: 0.6086 - auc: 0.7726 - auc_1: 0.7010 - 2s/epoch - 59ms/step\n",
            "Epoch 2/200\n",
            "31/31 - 2s - loss: 0.6070 - auc: 0.7689 - auc_1: 0.6984 - 2s/epoch - 58ms/step\n",
            "Epoch 3/200\n",
            "31/31 - 2s - loss: 0.6056 - auc: 0.7659 - auc_1: 0.6919 - 2s/epoch - 57ms/step\n",
            "Epoch 4/200\n",
            "31/31 - 2s - loss: 0.6043 - auc: 0.7793 - auc_1: 0.7048 - 2s/epoch - 58ms/step\n",
            "Epoch 5/200\n",
            "31/31 - 2s - loss: 0.6030 - auc: 0.7793 - auc_1: 0.7086 - 2s/epoch - 57ms/step\n",
            "Epoch 6/200\n",
            "31/31 - 2s - loss: 0.6016 - auc: 0.7659 - auc_1: 0.6884 - 2s/epoch - 57ms/step\n",
            "Epoch 7/200\n",
            "31/31 - 2s - loss: 0.6004 - auc: 0.7646 - auc_1: 0.6911 - 2s/epoch - 57ms/step\n",
            "Epoch 8/200\n",
            "31/31 - 2s - loss: 0.5992 - auc: 0.7598 - auc_1: 0.6878 - 2s/epoch - 56ms/step\n",
            "Epoch 9/200\n",
            "31/31 - 2s - loss: 0.5981 - auc: 0.7579 - auc_1: 0.6902 - 2s/epoch - 55ms/step\n",
            "Epoch 10/200\n",
            "31/31 - 2s - loss: 0.5969 - auc: 0.7652 - auc_1: 0.6999 - 2s/epoch - 55ms/step\n",
            "Epoch 11/200\n",
            "31/31 - 2s - loss: 0.5957 - auc: 0.7640 - auc_1: 0.6975 - 2s/epoch - 55ms/step\n",
            "Epoch 12/200\n",
            "31/31 - 2s - loss: 0.5946 - auc: 0.7689 - auc_1: 0.7000 - 2s/epoch - 54ms/step\n",
            "Epoch 13/200\n",
            "31/31 - 2s - loss: 0.5936 - auc: 0.7689 - auc_1: 0.7000 - 2s/epoch - 57ms/step\n",
            "Epoch 14/200\n",
            "31/31 - 2s - loss: 0.5926 - auc: 0.7695 - auc_1: 0.7037 - 2s/epoch - 56ms/step\n",
            "Epoch 15/200\n",
            "31/31 - 2s - loss: 0.5917 - auc: 0.7634 - auc_1: 0.6898 - 2s/epoch - 55ms/step\n",
            "Epoch 16/200\n",
            "31/31 - 2s - loss: 0.5907 - auc: 0.7652 - auc_1: 0.6926 - 2s/epoch - 56ms/step\n",
            "Epoch 17/200\n",
            "31/31 - 2s - loss: 0.5898 - auc: 0.7665 - auc_1: 0.6880 - 2s/epoch - 55ms/step\n",
            "Epoch 18/200\n",
            "31/31 - 2s - loss: 0.5888 - auc: 0.7659 - auc_1: 0.6877 - 2s/epoch - 56ms/step\n",
            "Epoch 19/200\n",
            "31/31 - 2s - loss: 0.5879 - auc: 0.7689 - auc_1: 0.6987 - 2s/epoch - 56ms/step\n",
            "Epoch 20/200\n",
            "31/31 - 2s - loss: 0.5870 - auc: 0.7726 - auc_1: 0.6984 - 2s/epoch - 54ms/step\n",
            "Epoch 21/200\n",
            "31/31 - 2s - loss: 0.5862 - auc: 0.7701 - auc_1: 0.6962 - 2s/epoch - 54ms/step\n",
            "Epoch 22/200\n",
            "31/31 - 2s - loss: 0.5854 - auc: 0.7646 - auc_1: 0.6919 - 2s/epoch - 55ms/step\n",
            "Epoch 23/200\n",
            "31/31 - 2s - loss: 0.5845 - auc: 0.7671 - auc_1: 0.7010 - 2s/epoch - 55ms/step\n",
            "Epoch 24/200\n",
            "31/31 - 2s - loss: 0.5838 - auc: 0.7695 - auc_1: 0.7003 - 2s/epoch - 56ms/step\n",
            "Epoch 25/200\n",
            "31/31 - 2s - loss: 0.5831 - auc: 0.7750 - auc_1: 0.6990 - 2s/epoch - 56ms/step\n",
            "Epoch 26/200\n",
            "31/31 - 2s - loss: 0.5824 - auc: 0.7720 - auc_1: 0.6980 - 2s/epoch - 57ms/step\n",
            "Epoch 27/200\n",
            "31/31 - 2s - loss: 0.5816 - auc: 0.7707 - auc_1: 0.6960 - 2s/epoch - 57ms/step\n",
            "Epoch 28/200\n",
            "31/31 - 2s - loss: 0.5809 - auc: 0.7689 - auc_1: 0.6955 - 2s/epoch - 54ms/step\n",
            "Epoch 29/200\n",
            "31/31 - 2s - loss: 0.5802 - auc: 0.7659 - auc_1: 0.6957 - 2s/epoch - 54ms/step\n",
            "Epoch 30/200\n",
            "31/31 - 2s - loss: 0.5794 - auc: 0.7665 - auc_1: 0.6945 - 2s/epoch - 55ms/step\n",
            "Epoch 31/200\n",
            "31/31 - 2s - loss: 0.5788 - auc: 0.7701 - auc_1: 0.6979 - 2s/epoch - 55ms/step\n",
            "Epoch 32/200\n",
            "31/31 - 2s - loss: 0.5781 - auc: 0.7744 - auc_1: 0.6948 - 2s/epoch - 55ms/step\n",
            "Epoch 33/200\n",
            "31/31 - 2s - loss: 0.5775 - auc: 0.7695 - auc_1: 0.6910 - 2s/epoch - 55ms/step\n",
            "Epoch 34/200\n",
            "31/31 - 2s - loss: 0.5770 - auc: 0.7689 - auc_1: 0.6906 - 2s/epoch - 55ms/step\n",
            "Epoch 35/200\n",
            "31/31 - 2s - loss: 0.5763 - auc: 0.7707 - auc_1: 0.6989 - 2s/epoch - 55ms/step\n",
            "Epoch 36/200\n",
            "31/31 - 2s - loss: 0.5757 - auc: 0.7646 - auc_1: 0.6919 - 2s/epoch - 55ms/step\n",
            "Epoch 37/200\n",
            "31/31 - 2s - loss: 0.5751 - auc: 0.7652 - auc_1: 0.6933 - 2s/epoch - 57ms/step\n",
            "Epoch 38/200\n",
            "31/31 - 2s - loss: 0.5744 - auc: 0.7677 - auc_1: 0.6975 - 2s/epoch - 56ms/step\n",
            "Epoch 39/200\n",
            "31/31 - 2s - loss: 0.5739 - auc: 0.7659 - auc_1: 0.7028 - 2s/epoch - 56ms/step\n",
            "Epoch 40/200\n",
            "31/31 - 2s - loss: 0.5733 - auc: 0.7689 - auc_1: 0.7036 - 2s/epoch - 56ms/step\n",
            "Epoch 41/200\n",
            "31/31 - 2s - loss: 0.5728 - auc: 0.7689 - auc_1: 0.7036 - 2s/epoch - 57ms/step\n",
            "Epoch 42/200\n",
            "31/31 - 2s - loss: 0.5723 - auc: 0.7726 - auc_1: 0.7066 - 2s/epoch - 58ms/step\n",
            "Epoch 43/200\n",
            "31/31 - 2s - loss: 0.5718 - auc: 0.7671 - auc_1: 0.7004 - 2s/epoch - 56ms/step\n",
            "Epoch 44/200\n",
            "31/31 - 2s - loss: 0.5713 - auc: 0.7659 - auc_1: 0.6984 - 2s/epoch - 56ms/step\n",
            "Epoch 45/200\n",
            "31/31 - 2s - loss: 0.5709 - auc: 0.7652 - auc_1: 0.6982 - 2s/epoch - 57ms/step\n",
            "Epoch 46/200\n",
            "31/31 - 2s - loss: 0.5703 - auc: 0.7610 - auc_1: 0.6937 - 2s/epoch - 56ms/step\n",
            "Epoch 47/200\n",
            "31/31 - 2s - loss: 0.5699 - auc: 0.7604 - auc_1: 0.6920 - 2s/epoch - 57ms/step\n",
            "Epoch 48/200\n",
            "31/31 - 2s - loss: 0.5694 - auc: 0.7567 - auc_1: 0.6907 - 2s/epoch - 57ms/step\n",
            "Epoch 49/200\n",
            "31/31 - 2s - loss: 0.5690 - auc: 0.7604 - auc_1: 0.6942 - 2s/epoch - 56ms/step\n",
            "Epoch 50/200\n",
            "31/31 - 2s - loss: 0.5685 - auc: 0.7671 - auc_1: 0.7006 - 2s/epoch - 56ms/step\n",
            "Epoch 51/200\n",
            "31/31 - 2s - loss: 0.5681 - auc: 0.7774 - auc_1: 0.6997 - 2s/epoch - 56ms/step\n",
            "Epoch 52/200\n",
            "31/31 - 2s - loss: 0.5678 - auc: 0.7823 - auc_1: 0.7021 - 2s/epoch - 55ms/step\n",
            "Epoch 53/200\n",
            "31/31 - 2s - loss: 0.5672 - auc: 0.7817 - auc_1: 0.7018 - 2s/epoch - 57ms/step\n",
            "Epoch 54/200\n",
            "31/31 - 2s - loss: 0.5666 - auc: 0.7793 - auc_1: 0.6944 - 2s/epoch - 57ms/step\n",
            "Epoch 55/200\n",
            "31/31 - 2s - loss: 0.5663 - auc: 0.7732 - auc_1: 0.6872 - 2s/epoch - 55ms/step\n",
            "Epoch 56/200\n",
            "31/31 - 2s - loss: 0.5658 - auc: 0.7713 - auc_1: 0.6940 - 2s/epoch - 55ms/step\n",
            "Epoch 57/200\n",
            "31/31 - 2s - loss: 0.5654 - auc: 0.7713 - auc_1: 0.6940 - 2s/epoch - 56ms/step\n",
            "Epoch 58/200\n",
            "31/31 - 2s - loss: 0.5651 - auc: 0.7707 - auc_1: 0.6938 - 2s/epoch - 55ms/step\n",
            "Epoch 59/200\n",
            "31/31 - 2s - loss: 0.5647 - auc: 0.7726 - auc_1: 0.6978 - 2s/epoch - 56ms/step\n",
            "Epoch 60/200\n",
            "31/31 - 2s - loss: 0.5645 - auc: 0.7732 - auc_1: 0.6992 - 2s/epoch - 57ms/step\n",
            "Epoch 61/200\n",
            "31/31 - 2s - loss: 0.5639 - auc: 0.7732 - auc_1: 0.7064 - 2s/epoch - 57ms/step\n",
            "Epoch 62/200\n",
            "31/31 - 2s - loss: 0.5635 - auc: 0.7695 - auc_1: 0.7022 - 2s/epoch - 56ms/step\n",
            "Epoch 63/200\n",
            "31/31 - 2s - loss: 0.5631 - auc: 0.7677 - auc_1: 0.7017 - 2s/epoch - 56ms/step\n",
            "Epoch 64/200\n",
            "31/31 - 2s - loss: 0.5628 - auc: 0.7634 - auc_1: 0.6992 - 2s/epoch - 57ms/step\n",
            "Epoch 65/200\n",
            "31/31 - 2s - loss: 0.5624 - auc: 0.7634 - auc_1: 0.6992 - 2s/epoch - 56ms/step\n",
            "Epoch 66/200\n",
            "31/31 - 2s - loss: 0.5620 - auc: 0.7689 - auc_1: 0.7038 - 2s/epoch - 57ms/step\n",
            "Epoch 67/200\n",
            "31/31 - 2s - loss: 0.5617 - auc: 0.7665 - auc_1: 0.7018 - 2s/epoch - 56ms/step\n",
            "Epoch 68/200\n",
            "31/31 - 2s - loss: 0.5614 - auc: 0.7677 - auc_1: 0.6990 - 2s/epoch - 55ms/step\n",
            "Epoch 69/200\n",
            "31/31 - 2s - loss: 0.5610 - auc: 0.7677 - auc_1: 0.6990 - 2s/epoch - 56ms/step\n",
            "Epoch 70/200\n",
            "31/31 - 2s - loss: 0.5607 - auc: 0.7640 - auc_1: 0.6961 - 2s/epoch - 56ms/step\n",
            "Epoch 71/200\n",
            "31/31 - 2s - loss: 0.5604 - auc: 0.7579 - auc_1: 0.6903 - 2s/epoch - 56ms/step\n",
            "Epoch 72/200\n",
            "31/31 - 2s - loss: 0.5600 - auc: 0.7689 - auc_1: 0.7012 - 2s/epoch - 55ms/step\n",
            "Epoch 73/200\n",
            "31/31 - 2s - loss: 0.5598 - auc: 0.7689 - auc_1: 0.7012 - 2s/epoch - 56ms/step\n",
            "Epoch 74/200\n",
            "31/31 - 2s - loss: 0.5594 - auc: 0.7677 - auc_1: 0.7008 - 2s/epoch - 56ms/step\n",
            "Epoch 75/200\n",
            "31/31 - 2s - loss: 0.5591 - auc: 0.7720 - auc_1: 0.7057 - 2s/epoch - 56ms/step\n",
            "Epoch 76/200\n",
            "31/31 - 2s - loss: 0.5588 - auc: 0.7713 - auc_1: 0.7054 - 2s/epoch - 56ms/step\n",
            "Epoch 77/200\n",
            "31/31 - 2s - loss: 0.5586 - auc: 0.7713 - auc_1: 0.7054 - 2s/epoch - 57ms/step\n",
            "Epoch 78/200\n",
            "31/31 - 2s - loss: 0.5582 - auc: 0.7713 - auc_1: 0.7054 - 2s/epoch - 56ms/step\n",
            "Epoch 79/200\n",
            "31/31 - 2s - loss: 0.5579 - auc: 0.7713 - auc_1: 0.7054 - 2s/epoch - 56ms/step\n",
            "Epoch 80/200\n",
            "31/31 - 2s - loss: 0.5576 - auc: 0.7713 - auc_1: 0.7032 - 2s/epoch - 56ms/step\n",
            "Epoch 81/200\n",
            "31/31 - 2s - loss: 0.5573 - auc: 0.7683 - auc_1: 0.6991 - 2s/epoch - 55ms/step\n",
            "Epoch 82/200\n",
            "31/31 - 2s - loss: 0.5570 - auc: 0.7744 - auc_1: 0.7087 - 2s/epoch - 57ms/step\n",
            "Epoch 83/200\n",
            "31/31 - 2s - loss: 0.5567 - auc: 0.7762 - auc_1: 0.7181 - 2s/epoch - 56ms/step\n",
            "Epoch 84/200\n",
            "31/31 - 2s - loss: 0.5563 - auc: 0.7762 - auc_1: 0.7181 - 2s/epoch - 56ms/step\n",
            "Epoch 85/200\n",
            "31/31 - 2s - loss: 0.5560 - auc: 0.7738 - auc_1: 0.7158 - 2s/epoch - 55ms/step\n",
            "Epoch 86/200\n",
            "31/31 - 2s - loss: 0.5558 - auc: 0.7683 - auc_1: 0.6952 - 2s/epoch - 55ms/step\n",
            "Epoch 87/200\n",
            "31/31 - 2s - loss: 0.5557 - auc: 0.7720 - auc_1: 0.6962 - 2s/epoch - 56ms/step\n",
            "Epoch 88/200\n",
            "31/31 - 2s - loss: 0.5553 - auc: 0.7695 - auc_1: 0.6941 - 2s/epoch - 55ms/step\n",
            "Epoch 89/200\n",
            "31/31 - 2s - loss: 0.5551 - auc: 0.7787 - auc_1: 0.7064 - 2s/epoch - 57ms/step\n",
            "Epoch 90/200\n",
            "31/31 - 2s - loss: 0.5549 - auc: 0.7787 - auc_1: 0.7064 - 2s/epoch - 56ms/step\n",
            "Epoch 91/200\n",
            "31/31 - 2s - loss: 0.5546 - auc: 0.7787 - auc_1: 0.7064 - 2s/epoch - 56ms/step\n",
            "Epoch 92/200\n",
            "31/31 - 2s - loss: 0.5544 - auc: 0.7787 - auc_1: 0.7064 - 2s/epoch - 56ms/step\n",
            "Epoch 93/200\n",
            "31/31 - 2s - loss: 0.5541 - auc: 0.7762 - auc_1: 0.7044 - 2s/epoch - 56ms/step\n",
            "Epoch 94/200\n",
            "31/31 - 2s - loss: 0.5539 - auc: 0.7756 - auc_1: 0.7042 - 2s/epoch - 55ms/step\n",
            "Epoch 95/200\n",
            "31/31 - 2s - loss: 0.5537 - auc: 0.7823 - auc_1: 0.7098 - 2s/epoch - 56ms/step\n",
            "Epoch 96/200\n",
            "31/31 - 2s - loss: 0.5534 - auc: 0.7829 - auc_1: 0.7115 - 2s/epoch - 57ms/step\n",
            "Epoch 97/200\n",
            "31/31 - 2s - loss: 0.5532 - auc: 0.7787 - auc_1: 0.7067 - 2s/epoch - 55ms/step\n",
            "Epoch 98/200\n",
            "31/31 - 2s - loss: 0.5530 - auc: 0.7774 - auc_1: 0.7061 - 2s/epoch - 55ms/step\n",
            "Epoch 99/200\n",
            "31/31 - 2s - loss: 0.5528 - auc: 0.7780 - auc_1: 0.7064 - 2s/epoch - 56ms/step\n",
            "Epoch 100/200\n",
            "31/31 - 2s - loss: 0.5525 - auc: 0.7793 - auc_1: 0.7134 - 2s/epoch - 55ms/step\n",
            "Epoch 101/200\n",
            "31/31 - 2s - loss: 0.5524 - auc: 0.7671 - auc_1: 0.7024 - 2s/epoch - 56ms/step\n",
            "Epoch 102/200\n",
            "31/31 - 2s - loss: 0.5520 - auc: 0.7805 - auc_1: 0.7164 - 2s/epoch - 55ms/step\n",
            "Epoch 103/200\n",
            "31/31 - 2s - loss: 0.5519 - auc: 0.7793 - auc_1: 0.7155 - 2s/epoch - 55ms/step\n",
            "Epoch 104/200\n",
            "31/31 - 2s - loss: 0.5517 - auc: 0.7768 - auc_1: 0.7065 - 2s/epoch - 55ms/step\n",
            "Epoch 105/200\n",
            "31/31 - 2s - loss: 0.5514 - auc: 0.7768 - auc_1: 0.7065 - 2s/epoch - 56ms/step\n",
            "Epoch 106/200\n",
            "31/31 - 2s - loss: 0.5513 - auc: 0.7835 - auc_1: 0.7135 - 2s/epoch - 57ms/step\n",
            "Epoch 107/200\n",
            "31/31 - 2s - loss: 0.5510 - auc: 0.7835 - auc_1: 0.7135 - 2s/epoch - 56ms/step\n",
            "Epoch 108/200\n",
            "31/31 - 2s - loss: 0.5509 - auc: 0.7835 - auc_1: 0.7135 - 2s/epoch - 55ms/step\n",
            "Epoch 109/200\n",
            "31/31 - 2s - loss: 0.5506 - auc: 0.7835 - auc_1: 0.7135 - 2s/epoch - 57ms/step\n",
            "Epoch 110/200\n",
            "31/31 - 2s - loss: 0.5504 - auc: 0.7872 - auc_1: 0.7196 - 2s/epoch - 56ms/step\n",
            "Epoch 111/200\n",
            "31/31 - 2s - loss: 0.5503 - auc: 0.7866 - auc_1: 0.7194 - 2s/epoch - 56ms/step\n",
            "Epoch 112/200\n",
            "31/31 - 2s - loss: 0.5500 - auc: 0.7866 - auc_1: 0.7194 - 2s/epoch - 56ms/step\n",
            "Epoch 113/200\n",
            "31/31 - 2s - loss: 0.5499 - auc: 0.7848 - auc_1: 0.7188 - 2s/epoch - 55ms/step\n",
            "Epoch 114/200\n",
            "31/31 - 2s - loss: 0.5497 - auc: 0.7866 - auc_1: 0.7194 - 2s/epoch - 56ms/step\n",
            "Epoch 115/200\n",
            "31/31 - 2s - loss: 0.5495 - auc: 0.7848 - auc_1: 0.7188 - 2s/epoch - 56ms/step\n",
            "Epoch 116/200\n",
            "31/31 - 2s - loss: 0.5492 - auc: 0.7848 - auc_1: 0.7188 - 2s/epoch - 56ms/step\n",
            "Epoch 117/200\n",
            "31/31 - 2s - loss: 0.5491 - auc: 0.7787 - auc_1: 0.7109 - 2s/epoch - 57ms/step\n",
            "Epoch 118/200\n",
            "31/31 - 2s - loss: 0.5489 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 56ms/step\n",
            "Epoch 119/200\n",
            "31/31 - 2s - loss: 0.5487 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 56ms/step\n",
            "Epoch 120/200\n",
            "31/31 - 2s - loss: 0.5484 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 55ms/step\n",
            "Epoch 121/200\n",
            "31/31 - 2s - loss: 0.5483 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 56ms/step\n",
            "Epoch 122/200\n",
            "31/31 - 2s - loss: 0.5482 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 56ms/step\n",
            "Epoch 123/200\n",
            "31/31 - 2s - loss: 0.5479 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 57ms/step\n",
            "Epoch 124/200\n",
            "31/31 - 2s - loss: 0.5478 - auc: 0.7817 - auc_1: 0.7125 - 2s/epoch - 58ms/step\n",
            "Epoch 125/200\n",
            "31/31 - 2s - loss: 0.5476 - auc: 0.7823 - auc_1: 0.7192 - 2s/epoch - 56ms/step\n",
            "Epoch 126/200\n",
            "31/31 - 2s - loss: 0.5475 - auc: 0.7750 - auc_1: 0.7106 - 2s/epoch - 56ms/step\n",
            "Epoch 127/200\n",
            "31/31 - 2s - loss: 0.5472 - auc: 0.7780 - auc_1: 0.7136 - 2s/epoch - 56ms/step\n",
            "Epoch 128/200\n",
            "31/31 - 2s - loss: 0.5470 - auc: 0.7720 - auc_1: 0.7077 - 2s/epoch - 57ms/step\n",
            "Epoch 129/200\n",
            "31/31 - 2s - loss: 0.5468 - auc: 0.7762 - auc_1: 0.7135 - 2s/epoch - 57ms/step\n",
            "Epoch 130/200\n",
            "31/31 - 2s - loss: 0.5466 - auc: 0.7762 - auc_1: 0.7135 - 2s/epoch - 58ms/step\n",
            "Epoch 131/200\n",
            "31/31 - 2s - loss: 0.5465 - auc: 0.7780 - auc_1: 0.7220 - 2s/epoch - 58ms/step\n",
            "Epoch 132/200\n",
            "31/31 - 2s - loss: 0.5463 - auc: 0.7793 - auc_1: 0.7248 - 2s/epoch - 56ms/step\n",
            "Epoch 133/200\n",
            "31/31 - 2s - loss: 0.5461 - auc: 0.7774 - auc_1: 0.7243 - 2s/epoch - 56ms/step\n",
            "Epoch 134/200\n",
            "31/31 - 2s - loss: 0.5459 - auc: 0.7774 - auc_1: 0.7243 - 2s/epoch - 56ms/step\n",
            "Epoch 135/200\n",
            "31/31 - 2s - loss: 0.5457 - auc: 0.7774 - auc_1: 0.7243 - 2s/epoch - 56ms/step\n",
            "Epoch 136/200\n",
            "31/31 - 2s - loss: 0.5456 - auc: 0.7750 - auc_1: 0.7221 - 2s/epoch - 56ms/step\n",
            "Epoch 137/200\n",
            "31/31 - 2s - loss: 0.5454 - auc: 0.7750 - auc_1: 0.7221 - 2s/epoch - 56ms/step\n",
            "Epoch 138/200\n",
            "31/31 - 2s - loss: 0.5452 - auc: 0.7750 - auc_1: 0.7221 - 2s/epoch - 57ms/step\n",
            "Epoch 139/200\n",
            "31/31 - 2s - loss: 0.5451 - auc: 0.7750 - auc_1: 0.7221 - 2s/epoch - 57ms/step\n",
            "Epoch 140/200\n",
            "31/31 - 2s - loss: 0.5450 - auc: 0.7768 - auc_1: 0.7256 - 2s/epoch - 56ms/step\n",
            "Epoch 141/200\n",
            "31/31 - 2s - loss: 0.5447 - auc: 0.7811 - auc_1: 0.7291 - 2s/epoch - 57ms/step\n",
            "Epoch 142/200\n",
            "31/31 - 2s - loss: 0.5446 - auc: 0.7811 - auc_1: 0.7291 - 2s/epoch - 56ms/step\n",
            "Epoch 143/200\n",
            "31/31 - 2s - loss: 0.5444 - auc: 0.7835 - auc_1: 0.7313 - 2s/epoch - 57ms/step\n",
            "Epoch 144/200\n",
            "31/31 - 2s - loss: 0.5442 - auc: 0.7811 - auc_1: 0.7291 - 2s/epoch - 56ms/step\n",
            "Epoch 145/200\n",
            "31/31 - 2s - loss: 0.5441 - auc: 0.7811 - auc_1: 0.7291 - 2s/epoch - 56ms/step\n",
            "Epoch 146/200\n",
            "31/31 - 2s - loss: 0.5439 - auc: 0.7811 - auc_1: 0.7270 - 2s/epoch - 56ms/step\n",
            "Epoch 147/200\n",
            "31/31 - 2s - loss: 0.5438 - auc: 0.7811 - auc_1: 0.7322 - 2s/epoch - 58ms/step\n",
            "Epoch 148/200\n",
            "31/31 - 2s - loss: 0.5436 - auc: 0.7738 - auc_1: 0.7193 - 2s/epoch - 56ms/step\n",
            "Epoch 149/200\n",
            "31/31 - 2s - loss: 0.5435 - auc: 0.7780 - auc_1: 0.7206 - 2s/epoch - 55ms/step\n",
            "Epoch 150/200\n",
            "31/31 - 2s - loss: 0.5433 - auc: 0.7756 - auc_1: 0.7186 - 2s/epoch - 56ms/step\n",
            "Epoch 151/200\n",
            "31/31 - 2s - loss: 0.5431 - auc: 0.7823 - auc_1: 0.7258 - 2s/epoch - 56ms/step\n",
            "Epoch 152/200\n",
            "31/31 - 2s - loss: 0.5429 - auc: 0.7890 - auc_1: 0.7330 - 2s/epoch - 57ms/step\n",
            "Epoch 153/200\n",
            "31/31 - 2s - loss: 0.5428 - auc: 0.7860 - auc_1: 0.7295 - 2s/epoch - 57ms/step\n",
            "Epoch 154/200\n",
            "31/31 - 2s - loss: 0.5427 - auc: 0.7860 - auc_1: 0.7295 - 2s/epoch - 56ms/step\n",
            "Epoch 155/200\n",
            "31/31 - 2s - loss: 0.5426 - auc: 0.7860 - auc_1: 0.7295 - 2s/epoch - 56ms/step\n",
            "Epoch 156/200\n",
            "31/31 - 2s - loss: 0.5424 - auc: 0.7963 - auc_1: 0.7373 - 2s/epoch - 56ms/step\n",
            "Epoch 157/200\n",
            "31/31 - 2s - loss: 0.5422 - auc: 0.7951 - auc_1: 0.7291 - 2s/epoch - 57ms/step\n",
            "Epoch 158/200\n",
            "31/31 - 2s - loss: 0.5420 - auc: 0.7963 - auc_1: 0.7373 - 2s/epoch - 56ms/step\n",
            "Epoch 159/200\n",
            "31/31 - 2s - loss: 0.5419 - auc: 0.7945 - auc_1: 0.7288 - 2s/epoch - 57ms/step\n",
            "Epoch 160/200\n",
            "31/31 - 2s - loss: 0.5418 - auc: 0.7939 - auc_1: 0.7285 - 2s/epoch - 57ms/step\n",
            "Epoch 161/200\n",
            "31/31 - 2s - loss: 0.5416 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 56ms/step\n",
            "Epoch 162/200\n",
            "31/31 - 2s - loss: 0.5415 - auc: 0.7939 - auc_1: 0.7285 - 2s/epoch - 56ms/step\n",
            "Epoch 163/200\n",
            "31/31 - 2s - loss: 0.5412 - auc: 0.7939 - auc_1: 0.7285 - 2s/epoch - 56ms/step\n",
            "Epoch 164/200\n",
            "31/31 - 2s - loss: 0.5411 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 57ms/step\n",
            "Epoch 165/200\n",
            "31/31 - 2s - loss: 0.5409 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 58ms/step\n",
            "Epoch 166/200\n",
            "31/31 - 2s - loss: 0.5408 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 56ms/step\n",
            "Epoch 167/200\n",
            "31/31 - 2s - loss: 0.5407 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 56ms/step\n",
            "Epoch 168/200\n",
            "31/31 - 2s - loss: 0.5406 - auc: 0.7988 - auc_1: 0.7301 - 2s/epoch - 56ms/step\n",
            "Epoch 169/200\n",
            "31/31 - 2s - loss: 0.5404 - auc: 0.7963 - auc_1: 0.7224 - 2s/epoch - 57ms/step\n",
            "Epoch 170/200\n",
            "31/31 - 2s - loss: 0.5402 - auc: 0.7963 - auc_1: 0.7224 - 2s/epoch - 57ms/step\n",
            "Epoch 171/200\n",
            "31/31 - 2s - loss: 0.5401 - auc: 0.7963 - auc_1: 0.7224 - 2s/epoch - 57ms/step\n",
            "Epoch 172/200\n",
            "31/31 - 2s - loss: 0.5399 - auc: 0.7963 - auc_1: 0.7224 - 2s/epoch - 56ms/step\n",
            "Epoch 173/200\n",
            "31/31 - 2s - loss: 0.5398 - auc: 0.7933 - auc_1: 0.7178 - 2s/epoch - 56ms/step\n",
            "Epoch 174/200\n",
            "31/31 - 2s - loss: 0.5396 - auc: 0.7933 - auc_1: 0.7178 - 2s/epoch - 56ms/step\n",
            "Epoch 175/200\n",
            "31/31 - 2s - loss: 0.5395 - auc: 0.7927 - auc_1: 0.7176 - 2s/epoch - 57ms/step\n",
            "Epoch 176/200\n",
            "31/31 - 2s - loss: 0.5394 - auc: 0.7927 - auc_1: 0.7176 - 2s/epoch - 58ms/step\n",
            "Epoch 177/200\n",
            "31/31 - 2s - loss: 0.5392 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 58ms/step\n",
            "Epoch 178/200\n",
            "31/31 - 2s - loss: 0.5390 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 59ms/step\n",
            "Epoch 179/200\n",
            "31/31 - 2s - loss: 0.5389 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 59ms/step\n",
            "Epoch 180/200\n",
            "31/31 - 2s - loss: 0.5387 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 57ms/step\n",
            "Epoch 181/200\n",
            "31/31 - 2s - loss: 0.5386 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 57ms/step\n",
            "Epoch 182/200\n",
            "31/31 - 2s - loss: 0.5384 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 57ms/step\n",
            "Epoch 183/200\n",
            "31/31 - 2s - loss: 0.5383 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 58ms/step\n",
            "Epoch 184/200\n",
            "31/31 - 2s - loss: 0.5382 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 57ms/step\n",
            "Epoch 185/200\n",
            "31/31 - 2s - loss: 0.5380 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 58ms/step\n",
            "Epoch 186/200\n",
            "31/31 - 2s - loss: 0.5378 - auc: 0.7945 - auc_1: 0.7195 - 2s/epoch - 57ms/step\n",
            "Epoch 187/200\n",
            "31/31 - 2s - loss: 0.5378 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 58ms/step\n",
            "Epoch 188/200\n",
            "31/31 - 2s - loss: 0.5375 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 57ms/step\n",
            "Epoch 189/200\n",
            "31/31 - 2s - loss: 0.5374 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 57ms/step\n",
            "Epoch 190/200\n",
            "31/31 - 2s - loss: 0.5373 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 56ms/step\n",
            "Epoch 191/200\n",
            "31/31 - 2s - loss: 0.5371 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 57ms/step\n",
            "Epoch 192/200\n",
            "31/31 - 2s - loss: 0.5370 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 58ms/step\n",
            "Epoch 193/200\n",
            "31/31 - 2s - loss: 0.5368 - auc: 0.7927 - auc_1: 0.7171 - 2s/epoch - 58ms/step\n",
            "Epoch 194/200\n",
            "31/31 - 2s - loss: 0.5367 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 56ms/step\n",
            "Epoch 195/200\n",
            "31/31 - 2s - loss: 0.5365 - auc: 0.7915 - auc_1: 0.7163 - 2s/epoch - 57ms/step\n",
            "Epoch 196/200\n",
            "31/31 - 2s - loss: 0.5364 - auc: 0.7933 - auc_1: 0.7257 - 2s/epoch - 56ms/step\n",
            "Epoch 197/200\n",
            "31/31 - 2s - loss: 0.5364 - auc: 0.7921 - auc_1: 0.7253 - 2s/epoch - 57ms/step\n",
            "Epoch 198/200\n",
            "31/31 - 2s - loss: 0.5362 - auc: 0.7921 - auc_1: 0.7253 - 2s/epoch - 57ms/step\n",
            "Epoch 199/200\n",
            "31/31 - 2s - loss: 0.5360 - auc: 0.7951 - auc_1: 0.7297 - 2s/epoch - 58ms/step\n",
            "Epoch 200/200\n",
            "31/31 - 2s - loss: 0.5358 - auc: 0.7927 - auc_1: 0.7273 - 2s/epoch - 56ms/step\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.5589 - auc: 0.7037 - auc_1: 0.3257\n",
            "Epoch 1/200\n",
            "50/50 - 3s - loss: 0.3703 - auc: 0.8012 - auc_1: 0.4935 - 3s/epoch - 57ms/step\n",
            "Epoch 2/200\n",
            "50/50 - 3s - loss: 0.3654 - auc: 0.8075 - auc_1: 0.4956 - 3s/epoch - 58ms/step\n",
            "Epoch 3/200\n",
            "50/50 - 3s - loss: 0.3606 - auc: 0.8137 - auc_1: 0.5012 - 3s/epoch - 59ms/step\n",
            "Epoch 4/200\n",
            "50/50 - 3s - loss: 0.3557 - auc: 0.8036 - auc_1: 0.4969 - 3s/epoch - 58ms/step\n",
            "Epoch 5/200\n",
            "50/50 - 3s - loss: 0.3507 - auc: 0.8051 - auc_1: 0.4974 - 3s/epoch - 59ms/step\n",
            "Epoch 6/200\n",
            "50/50 - 3s - loss: 0.3458 - auc: 0.8051 - auc_1: 0.4957 - 3s/epoch - 57ms/step\n",
            "Epoch 7/200\n",
            "50/50 - 3s - loss: 0.3407 - auc: 0.8168 - auc_1: 0.5069 - 3s/epoch - 58ms/step\n",
            "Epoch 8/200\n",
            "50/50 - 3s - loss: 0.3357 - auc: 0.7989 - auc_1: 0.5006 - 3s/epoch - 57ms/step\n",
            "Epoch 9/200\n",
            "50/50 - 3s - loss: 0.3308 - auc: 0.8059 - auc_1: 0.5024 - 3s/epoch - 57ms/step\n",
            "Epoch 10/200\n",
            "50/50 - 3s - loss: 0.3258 - auc: 0.8121 - auc_1: 0.5046 - 3s/epoch - 57ms/step\n",
            "Epoch 11/200\n",
            "50/50 - 3s - loss: 0.3208 - auc: 0.8261 - auc_1: 0.5161 - 3s/epoch - 57ms/step\n",
            "Epoch 12/200\n",
            "50/50 - 3s - loss: 0.3158 - auc: 0.8113 - auc_1: 0.5099 - 3s/epoch - 57ms/step\n",
            "Epoch 13/200\n",
            "50/50 - 3s - loss: 0.3109 - auc: 0.8090 - auc_1: 0.5110 - 3s/epoch - 57ms/step\n",
            "Epoch 14/200\n",
            "50/50 - 3s - loss: 0.3061 - auc: 0.8183 - auc_1: 0.5074 - 3s/epoch - 58ms/step\n",
            "Epoch 15/200\n",
            "50/50 - 3s - loss: 0.3013 - auc: 0.8028 - auc_1: 0.5048 - 3s/epoch - 58ms/step\n",
            "Epoch 16/200\n",
            "50/50 - 3s - loss: 0.2966 - auc: 0.8075 - auc_1: 0.5061 - 3s/epoch - 57ms/step\n",
            "Epoch 17/200\n",
            "50/50 - 3s - loss: 0.2920 - auc: 0.8191 - auc_1: 0.5100 - 3s/epoch - 57ms/step\n",
            "Epoch 18/200\n",
            "50/50 - 3s - loss: 0.2874 - auc: 0.8245 - auc_1: 0.5155 - 3s/epoch - 58ms/step\n",
            "Epoch 19/200\n",
            "50/50 - 3s - loss: 0.2829 - auc: 0.7997 - auc_1: 0.5131 - 3s/epoch - 56ms/step\n",
            "Epoch 20/200\n",
            "50/50 - 3s - loss: 0.2785 - auc: 0.8098 - auc_1: 0.5218 - 3s/epoch - 57ms/step\n",
            "Epoch 21/200\n",
            "50/50 - 3s - loss: 0.2742 - auc: 0.8191 - auc_1: 0.5217 - 3s/epoch - 57ms/step\n",
            "Epoch 22/200\n",
            "50/50 - 3s - loss: 0.2701 - auc: 0.8043 - auc_1: 0.5189 - 3s/epoch - 56ms/step\n",
            "Epoch 23/200\n",
            "50/50 - 3s - loss: 0.2659 - auc: 0.8113 - auc_1: 0.5208 - 3s/epoch - 57ms/step\n",
            "Epoch 24/200\n",
            "50/50 - 3s - loss: 0.2620 - auc: 0.8191 - auc_1: 0.5235 - 3s/epoch - 57ms/step\n",
            "Epoch 25/200\n",
            "50/50 - 3s - loss: 0.2581 - auc: 0.8028 - auc_1: 0.5183 - 3s/epoch - 58ms/step\n",
            "Epoch 26/200\n",
            "50/50 - 3s - loss: 0.2543 - auc: 0.8075 - auc_1: 0.5194 - 3s/epoch - 57ms/step\n",
            "Epoch 27/200\n",
            "50/50 - 3s - loss: 0.2508 - auc: 0.8036 - auc_1: 0.5227 - 3s/epoch - 56ms/step\n",
            "Epoch 28/200\n",
            "50/50 - 3s - loss: 0.2473 - auc: 0.8144 - auc_1: 0.5340 - 3s/epoch - 58ms/step\n",
            "Epoch 29/200\n",
            "50/50 - 3s - loss: 0.2439 - auc: 0.8191 - auc_1: 0.5361 - 3s/epoch - 56ms/step\n",
            "Epoch 30/200\n",
            "50/50 - 3s - loss: 0.2407 - auc: 0.8020 - auc_1: 0.5324 - 3s/epoch - 57ms/step\n",
            "Epoch 31/200\n",
            "50/50 - 3s - loss: 0.2375 - auc: 0.8082 - auc_1: 0.5340 - 3s/epoch - 57ms/step\n",
            "Epoch 32/200\n",
            "50/50 - 3s - loss: 0.2346 - auc: 0.8152 - auc_1: 0.5360 - 3s/epoch - 57ms/step\n",
            "Epoch 33/200\n",
            "50/50 - 3s - loss: 0.2318 - auc: 0.8238 - auc_1: 0.5362 - 3s/epoch - 57ms/step\n",
            "Epoch 34/200\n",
            "50/50 - 3s - loss: 0.2291 - auc: 0.8269 - auc_1: 0.5372 - 3s/epoch - 58ms/step\n",
            "Epoch 35/200\n",
            "50/50 - 3s - loss: 0.2264 - auc: 0.8059 - auc_1: 0.5288 - 3s/epoch - 58ms/step\n",
            "Epoch 36/200\n",
            "50/50 - 3s - loss: 0.2240 - auc: 0.8106 - auc_1: 0.5300 - 3s/epoch - 57ms/step\n",
            "Epoch 37/200\n",
            "50/50 - 3s - loss: 0.2216 - auc: 0.8183 - auc_1: 0.5325 - 3s/epoch - 56ms/step\n",
            "Epoch 38/200\n",
            "50/50 - 3s - loss: 0.2194 - auc: 0.8269 - auc_1: 0.5494 - 3s/epoch - 57ms/step\n",
            "Epoch 39/200\n",
            "50/50 - 3s - loss: 0.2173 - auc: 0.8339 - auc_1: 0.5521 - 3s/epoch - 57ms/step\n",
            "Epoch 40/200\n",
            "50/50 - 3s - loss: 0.2153 - auc: 0.7904 - auc_1: 0.5373 - 3s/epoch - 56ms/step\n",
            "Epoch 41/200\n",
            "50/50 - 3s - loss: 0.2132 - auc: 0.7943 - auc_1: 0.5381 - 3s/epoch - 57ms/step\n",
            "Epoch 42/200\n",
            "50/50 - 3s - loss: 0.2113 - auc: 0.7958 - auc_1: 0.5385 - 3s/epoch - 57ms/step\n",
            "Epoch 43/200\n",
            "50/50 - 3s - loss: 0.2096 - auc: 0.8028 - auc_1: 0.5401 - 3s/epoch - 57ms/step\n",
            "Epoch 44/200\n",
            "50/50 - 3s - loss: 0.2078 - auc: 0.8090 - auc_1: 0.5421 - 3s/epoch - 58ms/step\n",
            "Epoch 45/200\n",
            "50/50 - 3s - loss: 0.2063 - auc: 0.8183 - auc_1: 0.5579 - 3s/epoch - 57ms/step\n",
            "Epoch 46/200\n",
            "50/50 - 3s - loss: 0.2047 - auc: 0.8222 - auc_1: 0.5553 - 3s/epoch - 58ms/step\n",
            "Epoch 47/200\n",
            "50/50 - 3s - loss: 0.2033 - auc: 0.8238 - auc_1: 0.5558 - 3s/epoch - 57ms/step\n",
            "Epoch 48/200\n",
            "50/50 - 3s - loss: 0.2019 - auc: 0.7943 - auc_1: 0.5494 - 3s/epoch - 56ms/step\n",
            "Epoch 49/200\n",
            "50/50 - 3s - loss: 0.2006 - auc: 0.7974 - auc_1: 0.5500 - 3s/epoch - 57ms/step\n",
            "Epoch 50/200\n",
            "50/50 - 3s - loss: 0.1993 - auc: 0.7997 - auc_1: 0.5505 - 3s/epoch - 56ms/step\n",
            "Epoch 51/200\n",
            "50/50 - 3s - loss: 0.1981 - auc: 0.8005 - auc_1: 0.5506 - 3s/epoch - 56ms/step\n",
            "Epoch 52/200\n",
            "50/50 - 3s - loss: 0.1970 - auc: 0.8051 - auc_1: 0.5478 - 3s/epoch - 55ms/step\n",
            "Epoch 53/200\n",
            "50/50 - 3s - loss: 0.1959 - auc: 0.8090 - auc_1: 0.5487 - 3s/epoch - 56ms/step\n",
            "Epoch 54/200\n",
            "50/50 - 3s - loss: 0.1948 - auc: 0.8137 - auc_1: 0.5499 - 3s/epoch - 56ms/step\n",
            "Epoch 55/200\n",
            "50/50 - 3s - loss: 0.1939 - auc: 0.8245 - auc_1: 0.5541 - 3s/epoch - 56ms/step\n",
            "Epoch 56/200\n",
            "50/50 - 3s - loss: 0.1929 - auc: 0.8284 - auc_1: 0.5599 - 3s/epoch - 56ms/step\n",
            "Epoch 57/200\n",
            "50/50 - 3s - loss: 0.1920 - auc: 0.8315 - auc_1: 0.5610 - 3s/epoch - 56ms/step\n",
            "Epoch 58/200\n",
            "50/50 - 3s - loss: 0.1913 - auc: 0.8339 - auc_1: 0.5576 - 3s/epoch - 57ms/step\n",
            "Epoch 59/200\n",
            "50/50 - 3s - loss: 0.1903 - auc: 0.8005 - auc_1: 0.5458 - 3s/epoch - 57ms/step\n",
            "Epoch 60/200\n",
            "50/50 - 3s - loss: 0.1896 - auc: 0.8005 - auc_1: 0.5458 - 3s/epoch - 56ms/step\n",
            "Epoch 61/200\n",
            "50/50 - 3s - loss: 0.1889 - auc: 0.8005 - auc_1: 0.5458 - 3s/epoch - 56ms/step\n",
            "Epoch 62/200\n",
            "50/50 - 3s - loss: 0.1882 - auc: 0.8012 - auc_1: 0.5458 - 3s/epoch - 57ms/step\n",
            "Epoch 63/200\n",
            "50/50 - 3s - loss: 0.1875 - auc: 0.8051 - auc_1: 0.5465 - 3s/epoch - 57ms/step\n",
            "Epoch 64/200\n",
            "50/50 - 3s - loss: 0.1869 - auc: 0.8075 - auc_1: 0.5470 - 3s/epoch - 58ms/step\n",
            "Epoch 65/200\n",
            "50/50 - 3s - loss: 0.1862 - auc: 0.8090 - auc_1: 0.5472 - 3s/epoch - 57ms/step\n",
            "Epoch 66/200\n",
            "50/50 - 3s - loss: 0.1857 - auc: 0.8137 - auc_1: 0.5480 - 3s/epoch - 58ms/step\n",
            "Epoch 67/200\n",
            "50/50 - 3s - loss: 0.1851 - auc: 0.8152 - auc_1: 0.5484 - 3s/epoch - 58ms/step\n",
            "Epoch 68/200\n",
            "50/50 - 3s - loss: 0.1846 - auc: 0.8152 - auc_1: 0.5484 - 3s/epoch - 59ms/step\n",
            "Epoch 69/200\n",
            "50/50 - 3s - loss: 0.1840 - auc: 0.8152 - auc_1: 0.5484 - 3s/epoch - 57ms/step\n",
            "Epoch 70/200\n",
            "50/50 - 3s - loss: 0.1835 - auc: 0.8183 - auc_1: 0.5489 - 3s/epoch - 57ms/step\n",
            "Epoch 71/200\n",
            "50/50 - 3s - loss: 0.1832 - auc: 0.8222 - auc_1: 0.5498 - 3s/epoch - 57ms/step\n",
            "Epoch 72/200\n",
            "50/50 - 3s - loss: 0.1826 - auc: 0.8362 - auc_1: 0.5714 - 3s/epoch - 57ms/step\n",
            "Epoch 73/200\n",
            "50/50 - 3s - loss: 0.1822 - auc: 0.8432 - auc_1: 0.5733 - 3s/epoch - 57ms/step\n",
            "Epoch 74/200\n",
            "50/50 - 3s - loss: 0.1817 - auc: 0.8525 - auc_1: 0.5759 - 3s/epoch - 56ms/step\n",
            "Epoch 75/200\n",
            "50/50 - 3s - loss: 0.1813 - auc: 0.8113 - auc_1: 0.5687 - 3s/epoch - 56ms/step\n",
            "Epoch 76/200\n",
            "50/50 - 3s - loss: 0.1809 - auc: 0.8160 - auc_1: 0.5927 - 3s/epoch - 57ms/step\n",
            "Epoch 77/200\n",
            "50/50 - 3s - loss: 0.1805 - auc: 0.8168 - auc_1: 0.5964 - 3s/epoch - 57ms/step\n",
            "Epoch 78/200\n",
            "50/50 - 3s - loss: 0.1801 - auc: 0.8168 - auc_1: 0.5964 - 3s/epoch - 57ms/step\n",
            "Epoch 79/200\n",
            "50/50 - 3s - loss: 0.1799 - auc: 0.8183 - auc_1: 0.5969 - 3s/epoch - 56ms/step\n",
            "Epoch 80/200\n",
            "50/50 - 3s - loss: 0.1795 - auc: 0.8207 - auc_1: 0.5980 - 3s/epoch - 57ms/step\n",
            "Epoch 81/200\n",
            "50/50 - 3s - loss: 0.1791 - auc: 0.8207 - auc_1: 0.5980 - 3s/epoch - 58ms/step\n",
            "Epoch 82/200\n",
            "50/50 - 3s - loss: 0.1788 - auc: 0.7764 - auc_1: 0.5839 - 3s/epoch - 58ms/step\n",
            "Epoch 83/200\n",
            "50/50 - 3s - loss: 0.1785 - auc: 0.7764 - auc_1: 0.5839 - 3s/epoch - 58ms/step\n",
            "Epoch 84/200\n",
            "50/50 - 3s - loss: 0.1782 - auc: 0.7764 - auc_1: 0.5839 - 3s/epoch - 58ms/step\n",
            "Epoch 85/200\n",
            "50/50 - 3s - loss: 0.1779 - auc: 0.7787 - auc_1: 0.5842 - 3s/epoch - 59ms/step\n",
            "Epoch 86/200\n",
            "50/50 - 3s - loss: 0.1777 - auc: 0.7787 - auc_1: 0.5842 - 3s/epoch - 57ms/step\n",
            "Epoch 87/200\n",
            "50/50 - 3s - loss: 0.1774 - auc: 0.7795 - auc_1: 0.5844 - 3s/epoch - 57ms/step\n",
            "Epoch 88/200\n",
            "50/50 - 3s - loss: 0.1772 - auc: 0.7803 - auc_1: 0.5809 - 3s/epoch - 57ms/step\n",
            "Epoch 89/200\n",
            "50/50 - 3s - loss: 0.1769 - auc: 0.7811 - auc_1: 0.5846 - 3s/epoch - 58ms/step\n",
            "Epoch 90/200\n",
            "50/50 - 3s - loss: 0.1767 - auc: 0.7811 - auc_1: 0.5846 - 3s/epoch - 58ms/step\n",
            "Epoch 91/200\n",
            "50/50 - 3s - loss: 0.1764 - auc: 0.7811 - auc_1: 0.5846 - 3s/epoch - 57ms/step\n",
            "Epoch 92/200\n",
            "50/50 - 3s - loss: 0.1762 - auc: 0.7826 - auc_1: 0.5848 - 3s/epoch - 57ms/step\n",
            "Epoch 93/200\n",
            "50/50 - 3s - loss: 0.1759 - auc: 0.7834 - auc_1: 0.5850 - 3s/epoch - 57ms/step\n",
            "Epoch 94/200\n",
            "50/50 - 3s - loss: 0.1757 - auc: 0.7834 - auc_1: 0.5850 - 3s/epoch - 57ms/step\n",
            "Epoch 95/200\n",
            "50/50 - 3s - loss: 0.1755 - auc: 0.7849 - auc_1: 0.5852 - 3s/epoch - 57ms/step\n",
            "Epoch 96/200\n",
            "50/50 - 3s - loss: 0.1753 - auc: 0.7873 - auc_1: 0.5857 - 3s/epoch - 58ms/step\n",
            "Epoch 97/200\n",
            "50/50 - 3s - loss: 0.1751 - auc: 0.7888 - auc_1: 0.5858 - 3s/epoch - 59ms/step\n",
            "Epoch 98/200\n",
            "50/50 - 3s - loss: 0.1748 - auc: 0.7888 - auc_1: 0.5858 - 3s/epoch - 57ms/step\n",
            "Epoch 99/200\n",
            "50/50 - 3s - loss: 0.1746 - auc: 0.7888 - auc_1: 0.5858 - 3s/epoch - 58ms/step\n",
            "Epoch 100/200\n",
            "50/50 - 3s - loss: 0.1745 - auc: 0.7888 - auc_1: 0.5858 - 3s/epoch - 58ms/step\n",
            "Epoch 101/200\n",
            "50/50 - 3s - loss: 0.1743 - auc: 0.7888 - auc_1: 0.5858 - 3s/epoch - 59ms/step\n",
            "Epoch 102/200\n",
            "50/50 - 3s - loss: 0.1740 - auc: 0.7904 - auc_1: 0.5860 - 3s/epoch - 60ms/step\n",
            "Epoch 103/200\n",
            "50/50 - 3s - loss: 0.1739 - auc: 0.7904 - auc_1: 0.5860 - 3s/epoch - 59ms/step\n",
            "Epoch 104/200\n",
            "50/50 - 3s - loss: 0.1737 - auc: 0.7935 - auc_1: 0.5991 - 3s/epoch - 59ms/step\n",
            "Epoch 105/200\n",
            "50/50 - 3s - loss: 0.1735 - auc: 0.7935 - auc_1: 0.5991 - 3s/epoch - 58ms/step\n",
            "Epoch 106/200\n",
            "50/50 - 3s - loss: 0.1734 - auc: 0.7943 - auc_1: 0.5994 - 3s/epoch - 58ms/step\n",
            "Epoch 107/200\n",
            "50/50 - 3s - loss: 0.1731 - auc: 0.7943 - auc_1: 0.5994 - 3s/epoch - 59ms/step\n",
            "Epoch 108/200\n",
            "50/50 - 3s - loss: 0.1730 - auc: 0.7958 - auc_1: 0.5996 - 3s/epoch - 60ms/step\n",
            "Epoch 109/200\n",
            "50/50 - 3s - loss: 0.1728 - auc: 0.7958 - auc_1: 0.6093 - 3s/epoch - 57ms/step\n",
            "Epoch 110/200\n",
            "50/50 - 3s - loss: 0.1726 - auc: 0.7989 - auc_1: 0.6097 - 3s/epoch - 56ms/step\n",
            "Epoch 111/200\n",
            "50/50 - 3s - loss: 0.1725 - auc: 0.7974 - auc_1: 0.5998 - 3s/epoch - 57ms/step\n",
            "Epoch 112/200\n",
            "50/50 - 3s - loss: 0.1723 - auc: 0.7989 - auc_1: 0.6097 - 3s/epoch - 58ms/step\n",
            "Epoch 113/200\n",
            "50/50 - 3s - loss: 0.1722 - auc: 0.7989 - auc_1: 0.6000 - 3s/epoch - 58ms/step\n",
            "Epoch 114/200\n",
            "50/50 - 3s - loss: 0.1721 - auc: 0.7974 - auc_1: 0.5917 - 3s/epoch - 58ms/step\n",
            "Epoch 115/200\n",
            "50/50 - 3s - loss: 0.1718 - auc: 0.7989 - auc_1: 0.6000 - 3s/epoch - 57ms/step\n",
            "Epoch 116/200\n",
            "50/50 - 3s - loss: 0.1718 - auc: 0.8005 - auc_1: 0.6090 - 3s/epoch - 58ms/step\n",
            "Epoch 117/200\n",
            "50/50 - 3s - loss: 0.1716 - auc: 0.8005 - auc_1: 0.6090 - 3s/epoch - 57ms/step\n",
            "Epoch 118/200\n",
            "50/50 - 3s - loss: 0.1714 - auc: 0.7989 - auc_1: 0.6000 - 3s/epoch - 58ms/step\n",
            "Epoch 119/200\n",
            "50/50 - 3s - loss: 0.1713 - auc: 0.8020 - auc_1: 0.6092 - 3s/epoch - 57ms/step\n",
            "Epoch 120/200\n",
            "50/50 - 3s - loss: 0.1712 - auc: 0.8028 - auc_1: 0.6096 - 3s/epoch - 58ms/step\n",
            "Epoch 121/200\n",
            "50/50 - 3s - loss: 0.1710 - auc: 0.8028 - auc_1: 0.6096 - 3s/epoch - 57ms/step\n",
            "Epoch 122/200\n",
            "50/50 - 3s - loss: 0.1708 - auc: 0.8051 - auc_1: 0.6101 - 3s/epoch - 56ms/step\n",
            "Epoch 123/200\n",
            "50/50 - 3s - loss: 0.1707 - auc: 0.8067 - auc_1: 0.6207 - 3s/epoch - 56ms/step\n",
            "Epoch 124/200\n",
            "50/50 - 3s - loss: 0.1706 - auc: 0.8082 - auc_1: 0.6209 - 3s/epoch - 56ms/step\n",
            "Epoch 125/200\n",
            "50/50 - 3s - loss: 0.1705 - auc: 0.8082 - auc_1: 0.6209 - 3s/epoch - 57ms/step\n",
            "Epoch 126/200\n",
            "50/50 - 3s - loss: 0.1703 - auc: 0.8082 - auc_1: 0.6209 - 3s/epoch - 56ms/step\n",
            "Epoch 127/200\n",
            "50/50 - 3s - loss: 0.1702 - auc: 0.8090 - auc_1: 0.6159 - 3s/epoch - 56ms/step\n",
            "Epoch 128/200\n",
            "50/50 - 3s - loss: 0.1701 - auc: 0.8090 - auc_1: 0.6159 - 3s/epoch - 56ms/step\n",
            "Epoch 129/200\n",
            "50/50 - 3s - loss: 0.1699 - auc: 0.8113 - auc_1: 0.6214 - 3s/epoch - 56ms/step\n",
            "Epoch 130/200\n",
            "50/50 - 3s - loss: 0.1698 - auc: 0.8106 - auc_1: 0.6162 - 3s/epoch - 57ms/step\n",
            "Epoch 131/200\n",
            "50/50 - 3s - loss: 0.1696 - auc: 0.8121 - auc_1: 0.6164 - 3s/epoch - 56ms/step\n",
            "Epoch 132/200\n",
            "50/50 - 3s - loss: 0.1696 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 56ms/step\n",
            "Epoch 133/200\n",
            "50/50 - 3s - loss: 0.1694 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 56ms/step\n",
            "Epoch 134/200\n",
            "50/50 - 3s - loss: 0.1693 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 56ms/step\n",
            "Epoch 135/200\n",
            "50/50 - 3s - loss: 0.1692 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 56ms/step\n",
            "Epoch 136/200\n",
            "50/50 - 3s - loss: 0.1691 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 55ms/step\n",
            "Epoch 137/200\n",
            "50/50 - 3s - loss: 0.1689 - auc: 0.8129 - auc_1: 0.6216 - 3s/epoch - 56ms/step\n",
            "Epoch 138/200\n",
            "50/50 - 3s - loss: 0.1688 - auc: 0.8144 - auc_1: 0.6219 - 3s/epoch - 56ms/step\n",
            "Epoch 139/200\n",
            "50/50 - 3s - loss: 0.1687 - auc: 0.8160 - auc_1: 0.6222 - 3s/epoch - 57ms/step\n",
            "Epoch 140/200\n",
            "50/50 - 3s - loss: 0.1686 - auc: 0.8160 - auc_1: 0.6222 - 3s/epoch - 55ms/step\n",
            "Epoch 141/200\n",
            "50/50 - 3s - loss: 0.1684 - auc: 0.8160 - auc_1: 0.6222 - 3s/epoch - 55ms/step\n",
            "Epoch 142/200\n",
            "50/50 - 3s - loss: 0.1683 - auc: 0.8160 - auc_1: 0.6222 - 3s/epoch - 56ms/step\n",
            "Epoch 143/200\n",
            "50/50 - 3s - loss: 0.1682 - auc: 0.8175 - auc_1: 0.6224 - 3s/epoch - 56ms/step\n",
            "Epoch 144/200\n",
            "50/50 - 3s - loss: 0.1681 - auc: 0.8175 - auc_1: 0.6224 - 3s/epoch - 55ms/step\n",
            "Epoch 145/200\n",
            "50/50 - 3s - loss: 0.1680 - auc: 0.8175 - auc_1: 0.6224 - 3s/epoch - 56ms/step\n",
            "Epoch 146/200\n",
            "50/50 - 3s - loss: 0.1679 - auc: 0.8191 - auc_1: 0.6227 - 3s/epoch - 56ms/step\n",
            "Epoch 147/200\n",
            "50/50 - 3s - loss: 0.1678 - auc: 0.8191 - auc_1: 0.6227 - 3s/epoch - 57ms/step\n",
            "Epoch 148/200\n",
            "50/50 - 3s - loss: 0.1676 - auc: 0.8175 - auc_1: 0.6224 - 3s/epoch - 58ms/step\n",
            "Epoch 149/200\n",
            "50/50 - 3s - loss: 0.1676 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 57ms/step\n",
            "Epoch 150/200\n",
            "50/50 - 3s - loss: 0.1675 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 58ms/step\n",
            "Epoch 151/200\n",
            "50/50 - 3s - loss: 0.1673 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 57ms/step\n",
            "Epoch 152/200\n",
            "50/50 - 3s - loss: 0.1673 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 58ms/step\n",
            "Epoch 153/200\n",
            "50/50 - 3s - loss: 0.1672 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 56ms/step\n",
            "Epoch 154/200\n",
            "50/50 - 3s - loss: 0.1670 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 56ms/step\n",
            "Epoch 155/200\n",
            "50/50 - 3s - loss: 0.1669 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 56ms/step\n",
            "Epoch 156/200\n",
            "50/50 - 3s - loss: 0.1668 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 57ms/step\n",
            "Epoch 157/200\n",
            "50/50 - 3s - loss: 0.1667 - auc: 0.8222 - auc_1: 0.6233 - 3s/epoch - 57ms/step\n",
            "Epoch 158/200\n",
            "50/50 - 3s - loss: 0.1666 - auc: 0.8238 - auc_1: 0.6236 - 3s/epoch - 56ms/step\n",
            "Epoch 159/200\n",
            "50/50 - 3s - loss: 0.1666 - auc: 0.8238 - auc_1: 0.6236 - 3s/epoch - 58ms/step\n",
            "Epoch 160/200\n",
            "50/50 - 3s - loss: 0.1665 - auc: 0.8238 - auc_1: 0.6236 - 3s/epoch - 58ms/step\n",
            "Epoch 161/200\n",
            "50/50 - 3s - loss: 0.1663 - auc: 0.8238 - auc_1: 0.6236 - 3s/epoch - 57ms/step\n",
            "Epoch 162/200\n",
            "50/50 - 3s - loss: 0.1663 - auc: 0.8253 - auc_1: 0.6239 - 3s/epoch - 56ms/step\n",
            "Epoch 163/200\n",
            "50/50 - 3s - loss: 0.1661 - auc: 0.8269 - auc_1: 0.6242 - 3s/epoch - 56ms/step\n",
            "Epoch 164/200\n",
            "50/50 - 3s - loss: 0.1660 - auc: 0.8269 - auc_1: 0.6242 - 3s/epoch - 56ms/step\n",
            "Epoch 165/200\n",
            "50/50 - 3s - loss: 0.1659 - auc: 0.8315 - auc_1: 0.6252 - 3s/epoch - 56ms/step\n",
            "Epoch 166/200\n",
            "50/50 - 3s - loss: 0.1658 - auc: 0.8331 - auc_1: 0.6255 - 3s/epoch - 57ms/step\n",
            "Epoch 167/200\n",
            "50/50 - 3s - loss: 0.1657 - auc: 0.8346 - auc_1: 0.6258 - 3s/epoch - 57ms/step\n",
            "Epoch 168/200\n",
            "50/50 - 3s - loss: 0.1656 - auc: 0.8377 - auc_1: 0.6266 - 3s/epoch - 56ms/step\n",
            "Epoch 169/200\n",
            "50/50 - 3s - loss: 0.1656 - auc: 0.8393 - auc_1: 0.6270 - 3s/epoch - 55ms/step\n",
            "Epoch 170/200\n",
            "50/50 - 3s - loss: 0.1654 - auc: 0.8393 - auc_1: 0.6270 - 3s/epoch - 56ms/step\n",
            "Epoch 171/200\n",
            "50/50 - 3s - loss: 0.1653 - auc: 0.8455 - auc_1: 0.6286 - 3s/epoch - 55ms/step\n",
            "Epoch 172/200\n",
            "50/50 - 3s - loss: 0.1652 - auc: 0.8470 - auc_1: 0.6290 - 3s/epoch - 56ms/step\n",
            "Epoch 173/200\n",
            "50/50 - 3s - loss: 0.1651 - auc: 0.8470 - auc_1: 0.6290 - 3s/epoch - 57ms/step\n",
            "Epoch 174/200\n",
            "50/50 - 3s - loss: 0.1651 - auc: 0.8470 - auc_1: 0.6290 - 3s/epoch - 57ms/step\n",
            "Epoch 175/200\n",
            "50/50 - 3s - loss: 0.1650 - auc: 0.8502 - auc_1: 0.6300 - 3s/epoch - 56ms/step\n",
            "Epoch 176/200\n",
            "50/50 - 3s - loss: 0.1649 - auc: 0.8502 - auc_1: 0.6300 - 3s/epoch - 57ms/step\n",
            "Epoch 177/200\n",
            "50/50 - 3s - loss: 0.1648 - auc: 0.8502 - auc_1: 0.6300 - 3s/epoch - 56ms/step\n",
            "Epoch 178/200\n",
            "50/50 - 3s - loss: 0.1647 - auc: 0.8502 - auc_1: 0.6300 - 3s/epoch - 56ms/step\n",
            "Epoch 179/200\n",
            "50/50 - 3s - loss: 0.1646 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 55ms/step\n",
            "Epoch 180/200\n",
            "50/50 - 3s - loss: 0.1645 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 56ms/step\n",
            "Epoch 181/200\n",
            "50/50 - 3s - loss: 0.1644 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 57ms/step\n",
            "Epoch 182/200\n",
            "50/50 - 3s - loss: 0.1643 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 55ms/step\n",
            "Epoch 183/200\n",
            "50/50 - 3s - loss: 0.1642 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 56ms/step\n",
            "Epoch 184/200\n",
            "50/50 - 3s - loss: 0.1641 - auc: 0.8517 - auc_1: 0.6305 - 3s/epoch - 56ms/step\n",
            "Epoch 185/200\n",
            "50/50 - 3s - loss: 0.1640 - auc: 0.8564 - auc_1: 0.6320 - 3s/epoch - 57ms/step\n",
            "Epoch 186/200\n",
            "50/50 - 3s - loss: 0.1639 - auc: 0.8564 - auc_1: 0.6320 - 3s/epoch - 57ms/step\n",
            "Epoch 187/200\n",
            "50/50 - 3s - loss: 0.1638 - auc: 0.8587 - auc_1: 0.6331 - 3s/epoch - 57ms/step\n",
            "Epoch 188/200\n",
            "50/50 - 3s - loss: 0.1638 - auc: 0.8579 - auc_1: 0.6326 - 3s/epoch - 56ms/step\n",
            "Epoch 189/200\n",
            "50/50 - 3s - loss: 0.1637 - auc: 0.8602 - auc_1: 0.6337 - 3s/epoch - 57ms/step\n",
            "Epoch 190/200\n",
            "50/50 - 3s - loss: 0.1636 - auc: 0.8595 - auc_1: 0.6331 - 3s/epoch - 57ms/step\n",
            "Epoch 191/200\n",
            "50/50 - 3s - loss: 0.1635 - auc: 0.8618 - auc_1: 0.6343 - 3s/epoch - 57ms/step\n",
            "Epoch 192/200\n",
            "50/50 - 3s - loss: 0.1635 - auc: 0.8579 - auc_1: 0.6326 - 3s/epoch - 58ms/step\n",
            "Epoch 193/200\n",
            "50/50 - 3s - loss: 0.1633 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 57ms/step\n",
            "Epoch 194/200\n",
            "50/50 - 3s - loss: 0.1632 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 57ms/step\n",
            "Epoch 195/200\n",
            "50/50 - 3s - loss: 0.1631 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 57ms/step\n",
            "Epoch 196/200\n",
            "50/50 - 3s - loss: 0.1631 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 57ms/step\n",
            "Epoch 197/200\n",
            "50/50 - 3s - loss: 0.1630 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 56ms/step\n",
            "Epoch 198/200\n",
            "50/50 - 3s - loss: 0.1629 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 56ms/step\n",
            "Epoch 199/200\n",
            "50/50 - 3s - loss: 0.1628 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 57ms/step\n",
            "Epoch 200/200\n",
            "50/50 - 3s - loss: 0.1627 - auc: 0.8634 - auc_1: 0.6350 - 3s/epoch - 56ms/step\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.4448 - auc: 0.6742 - auc_1: 0.2049\n",
            "Epoch 1/200\n",
            "99/99 - 3s - loss: 0.8119 - mean_absolute_error: 0.6099 - 3s/epoch - 33ms/step\n",
            "Epoch 2/200\n",
            "99/99 - 3s - loss: 0.8076 - mean_absolute_error: 0.6002 - 3s/epoch - 32ms/step\n",
            "Epoch 3/200\n",
            "99/99 - 3s - loss: 0.8071 - mean_absolute_error: 0.6006 - 3s/epoch - 32ms/step\n",
            "Epoch 4/200\n",
            "99/99 - 3s - loss: 0.8073 - mean_absolute_error: 0.6004 - 3s/epoch - 32ms/step\n",
            "Epoch 5/200\n",
            "99/99 - 3s - loss: 0.8069 - mean_absolute_error: 0.5970 - 3s/epoch - 32ms/step\n",
            "Epoch 6/200\n",
            "99/99 - 3s - loss: 0.8068 - mean_absolute_error: 0.5963 - 3s/epoch - 32ms/step\n",
            "Epoch 7/200\n",
            "99/99 - 3s - loss: 0.8070 - mean_absolute_error: 0.5990 - 3s/epoch - 31ms/step\n",
            "Epoch 8/200\n",
            "99/99 - 3s - loss: 0.8074 - mean_absolute_error: 0.5994 - 3s/epoch - 32ms/step\n",
            "Epoch 9/200\n",
            "99/99 - 3s - loss: 0.8063 - mean_absolute_error: 0.5954 - 3s/epoch - 32ms/step\n",
            "Epoch 10/200\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5941 - 3s/epoch - 32ms/step\n",
            "Epoch 11/200\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5949 - 3s/epoch - 32ms/step\n",
            "Epoch 12/200\n",
            "99/99 - 3s - loss: 0.8062 - mean_absolute_error: 0.5960 - 3s/epoch - 32ms/step\n",
            "Epoch 13/200\n",
            "99/99 - 3s - loss: 0.8072 - mean_absolute_error: 0.5996 - 3s/epoch - 32ms/step\n",
            "Epoch 14/200\n",
            "99/99 - 3s - loss: 0.8077 - mean_absolute_error: 0.5997 - 3s/epoch - 32ms/step\n",
            "Epoch 15/200\n",
            "99/99 - 3s - loss: 0.8085 - mean_absolute_error: 0.6017 - 3s/epoch - 32ms/step\n",
            "Epoch 16/200\n",
            "99/99 - 3s - loss: 0.8076 - mean_absolute_error: 0.6014 - 3s/epoch - 32ms/step\n",
            "Epoch 17/200\n",
            "99/99 - 3s - loss: 0.8062 - mean_absolute_error: 0.5958 - 3s/epoch - 32ms/step\n",
            "Epoch 18/200\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5948 - 3s/epoch - 32ms/step\n",
            "Epoch 19/200\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5951 - 3s/epoch - 32ms/step\n",
            "Epoch 20/200\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5944 - 3s/epoch - 32ms/step\n",
            "Epoch 21/200\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5940 - 3s/epoch - 32ms/step\n",
            "Epoch 22/200\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5944 - 3s/epoch - 32ms/step\n",
            "Epoch 23/200\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5950 - 3s/epoch - 32ms/step\n",
            "Epoch 24/200\n",
            "99/99 - 3s - loss: 0.8064 - mean_absolute_error: 0.5970 - 3s/epoch - 32ms/step\n",
            "Epoch 25/200\n",
            "99/99 - 3s - loss: 0.8067 - mean_absolute_error: 0.5988 - 3s/epoch - 32ms/step\n",
            "Epoch 26/200\n",
            "99/99 - 3s - loss: 0.8078 - mean_absolute_error: 0.6026 - 3s/epoch - 32ms/step\n",
            "Epoch 27/200\n",
            "99/99 - 3s - loss: 0.8071 - mean_absolute_error: 0.6002 - 3s/epoch - 32ms/step\n",
            "Epoch 28/200\n",
            "99/99 - 3s - loss: 0.8068 - mean_absolute_error: 0.5984 - 3s/epoch - 32ms/step\n",
            "Epoch 29/200\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "99/99 - 3s - loss: 0.8075 - mean_absolute_error: 0.6005 - 3s/epoch - 32ms/step\n",
            "Epoch 29: early stopping\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.1853 - mean_absolute_error: 0.8984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn-vae\n",
        "train_eval_pred_model(class_model, 2, readm_cnn_X_train, readm_cnn_X_test, readm_cnn_y_train, readm_cnn_y_test)\n",
        "train_eval_pred_model(class_model, 2, mortality_cnn_X_train, mortality_cnn_X_test, mortality_cnn_y_train, mortality_cnn_y_test)\n",
        "train_eval_pred_model(reg_model, 1, los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVD3rjMMRDVp",
        "outputId": "5814a7d7-57f3-4cbe-e738-2708659c74e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "31/31 - 2s - loss: 0.7599 - auc: 0.8262 - auc_1: 0.6182 - 2s/epoch - 57ms/step\n",
            "Epoch 2/200\n",
            "31/31 - 2s - loss: 0.7410 - auc: 0.8354 - auc_1: 0.6463 - 2s/epoch - 59ms/step\n",
            "Epoch 3/200\n",
            "31/31 - 2s - loss: 0.7242 - auc: 0.8226 - auc_1: 0.6308 - 2s/epoch - 59ms/step\n",
            "Epoch 4/200\n",
            "31/31 - 2s - loss: 0.7110 - auc: 0.8201 - auc_1: 0.6448 - 2s/epoch - 59ms/step\n",
            "Epoch 5/200\n",
            "31/31 - 2s - loss: 0.6998 - auc: 0.8244 - auc_1: 0.6409 - 2s/epoch - 60ms/step\n",
            "Epoch 6/200\n",
            "31/31 - 2s - loss: 0.6898 - auc: 0.8299 - auc_1: 0.6628 - 2s/epoch - 57ms/step\n",
            "Epoch 7/200\n",
            "31/31 - 2s - loss: 0.6805 - auc: 0.8372 - auc_1: 0.6665 - 2s/epoch - 59ms/step\n",
            "Epoch 8/200\n",
            "31/31 - 2s - loss: 0.6729 - auc: 0.8250 - auc_1: 0.6477 - 2s/epoch - 57ms/step\n",
            "Epoch 9/200\n",
            "31/31 - 2s - loss: 0.6663 - auc: 0.8110 - auc_1: 0.6325 - 2s/epoch - 61ms/step\n",
            "Epoch 10/200\n",
            "31/31 - 2s - loss: 0.6593 - auc: 0.8323 - auc_1: 0.6642 - 2s/epoch - 61ms/step\n",
            "Epoch 11/200\n",
            "31/31 - 2s - loss: 0.6533 - auc: 0.8317 - auc_1: 0.6646 - 2s/epoch - 57ms/step\n",
            "Epoch 12/200\n",
            "31/31 - 2s - loss: 0.6476 - auc: 0.8366 - auc_1: 0.6645 - 2s/epoch - 58ms/step\n",
            "Epoch 13/200\n",
            "31/31 - 2s - loss: 0.6428 - auc: 0.8390 - auc_1: 0.6783 - 2s/epoch - 58ms/step\n",
            "Epoch 14/200\n",
            "31/31 - 2s - loss: 0.6374 - auc: 0.8421 - auc_1: 0.6971 - 2s/epoch - 59ms/step\n",
            "Epoch 15/200\n",
            "31/31 - 2s - loss: 0.6333 - auc: 0.8378 - auc_1: 0.6852 - 2s/epoch - 60ms/step\n",
            "Epoch 16/200\n",
            "31/31 - 2s - loss: 0.6286 - auc: 0.8409 - auc_1: 0.7005 - 2s/epoch - 60ms/step\n",
            "Epoch 17/200\n",
            "31/31 - 2s - loss: 0.6246 - auc: 0.8348 - auc_1: 0.6819 - 2s/epoch - 59ms/step\n",
            "Epoch 18/200\n",
            "31/31 - 2s - loss: 0.6207 - auc: 0.8317 - auc_1: 0.6893 - 2s/epoch - 57ms/step\n",
            "Epoch 19/200\n",
            "31/31 - 2s - loss: 0.6168 - auc: 0.8378 - auc_1: 0.6945 - 2s/epoch - 57ms/step\n",
            "Epoch 20/200\n",
            "31/31 - 2s - loss: 0.6134 - auc: 0.8366 - auc_1: 0.7015 - 2s/epoch - 57ms/step\n",
            "Epoch 21/200\n",
            "31/31 - 2s - loss: 0.6101 - auc: 0.8433 - auc_1: 0.7102 - 2s/epoch - 60ms/step\n",
            "Epoch 22/200\n",
            "31/31 - 2s - loss: 0.6071 - auc: 0.8476 - auc_1: 0.7041 - 2s/epoch - 59ms/step\n",
            "Epoch 23/200\n",
            "31/31 - 2s - loss: 0.6039 - auc: 0.8463 - auc_1: 0.7034 - 2s/epoch - 58ms/step\n",
            "Epoch 24/200\n",
            "31/31 - 2s - loss: 0.6010 - auc: 0.8439 - auc_1: 0.7033 - 2s/epoch - 58ms/step\n",
            "Epoch 25/200\n",
            "31/31 - 2s - loss: 0.5980 - auc: 0.8396 - auc_1: 0.7045 - 2s/epoch - 59ms/step\n",
            "Epoch 26/200\n",
            "31/31 - 2s - loss: 0.5955 - auc: 0.8402 - auc_1: 0.7096 - 2s/epoch - 58ms/step\n",
            "Epoch 27/200\n",
            "31/31 - 2s - loss: 0.5929 - auc: 0.8372 - auc_1: 0.7073 - 2s/epoch - 62ms/step\n",
            "Epoch 28/200\n",
            "31/31 - 2s - loss: 0.5905 - auc: 0.8366 - auc_1: 0.7060 - 2s/epoch - 59ms/step\n",
            "Epoch 29/200\n",
            "31/31 - 2s - loss: 0.5880 - auc: 0.8396 - auc_1: 0.7116 - 2s/epoch - 60ms/step\n",
            "Epoch 30/200\n",
            "31/31 - 2s - loss: 0.5857 - auc: 0.8451 - auc_1: 0.7146 - 2s/epoch - 58ms/step\n",
            "Epoch 31/200\n",
            "31/31 - 2s - loss: 0.5834 - auc: 0.8476 - auc_1: 0.7172 - 2s/epoch - 60ms/step\n",
            "Epoch 32/200\n",
            "31/31 - 2s - loss: 0.5812 - auc: 0.8457 - auc_1: 0.7114 - 2s/epoch - 60ms/step\n",
            "Epoch 33/200\n",
            "31/31 - 2s - loss: 0.5792 - auc: 0.8500 - auc_1: 0.7189 - 2s/epoch - 61ms/step\n",
            "Epoch 34/200\n",
            "31/31 - 2s - loss: 0.5773 - auc: 0.8482 - auc_1: 0.7184 - 2s/epoch - 59ms/step\n",
            "Epoch 35/200\n",
            "31/31 - 2s - loss: 0.5756 - auc: 0.8506 - auc_1: 0.7113 - 2s/epoch - 59ms/step\n",
            "Epoch 36/200\n",
            "31/31 - 2s - loss: 0.5735 - auc: 0.8482 - auc_1: 0.7076 - 2s/epoch - 60ms/step\n",
            "Epoch 37/200\n",
            "31/31 - 2s - loss: 0.5717 - auc: 0.8482 - auc_1: 0.7110 - 2s/epoch - 61ms/step\n",
            "Epoch 38/200\n",
            "31/31 - 2s - loss: 0.5699 - auc: 0.8512 - auc_1: 0.7181 - 2s/epoch - 62ms/step\n",
            "Epoch 39/200\n",
            "31/31 - 2s - loss: 0.5683 - auc: 0.8476 - auc_1: 0.7138 - 2s/epoch - 59ms/step\n",
            "Epoch 40/200\n",
            "31/31 - 2s - loss: 0.5666 - auc: 0.8476 - auc_1: 0.7120 - 2s/epoch - 58ms/step\n",
            "Epoch 41/200\n",
            "31/31 - 2s - loss: 0.5649 - auc: 0.8482 - auc_1: 0.7156 - 2s/epoch - 57ms/step\n",
            "Epoch 42/200\n",
            "31/31 - 2s - loss: 0.5634 - auc: 0.8463 - auc_1: 0.7143 - 2s/epoch - 57ms/step\n",
            "Epoch 43/200\n",
            "31/31 - 2s - loss: 0.5621 - auc: 0.8500 - auc_1: 0.7178 - 2s/epoch - 59ms/step\n",
            "Epoch 44/200\n",
            "31/31 - 2s - loss: 0.5605 - auc: 0.8524 - auc_1: 0.7231 - 2s/epoch - 58ms/step\n",
            "Epoch 45/200\n",
            "31/31 - 2s - loss: 0.5593 - auc: 0.8506 - auc_1: 0.7221 - 2s/epoch - 58ms/step\n",
            "Epoch 46/200\n",
            "31/31 - 2s - loss: 0.5577 - auc: 0.8549 - auc_1: 0.7263 - 2s/epoch - 59ms/step\n",
            "Epoch 47/200\n",
            "31/31 - 2s - loss: 0.5565 - auc: 0.8530 - auc_1: 0.7244 - 2s/epoch - 58ms/step\n",
            "Epoch 48/200\n",
            "31/31 - 2s - loss: 0.5550 - auc: 0.8506 - auc_1: 0.7177 - 2s/epoch - 56ms/step\n",
            "Epoch 49/200\n",
            "31/31 - 2s - loss: 0.5539 - auc: 0.8482 - auc_1: 0.7118 - 2s/epoch - 57ms/step\n",
            "Epoch 50/200\n",
            "31/31 - 2s - loss: 0.5526 - auc: 0.8494 - auc_1: 0.7167 - 2s/epoch - 56ms/step\n",
            "Epoch 51/200\n",
            "31/31 - 2s - loss: 0.5514 - auc: 0.8555 - auc_1: 0.7202 - 2s/epoch - 57ms/step\n",
            "Epoch 52/200\n",
            "31/31 - 2s - loss: 0.5504 - auc: 0.8567 - auc_1: 0.7207 - 2s/epoch - 57ms/step\n",
            "Epoch 53/200\n",
            "31/31 - 2s - loss: 0.5490 - auc: 0.8598 - auc_1: 0.7235 - 2s/epoch - 56ms/step\n",
            "Epoch 54/200\n",
            "31/31 - 2s - loss: 0.5477 - auc: 0.8598 - auc_1: 0.7235 - 2s/epoch - 57ms/step\n",
            "Epoch 55/200\n",
            "31/31 - 2s - loss: 0.5467 - auc: 0.8640 - auc_1: 0.7367 - 2s/epoch - 58ms/step\n",
            "Epoch 56/200\n",
            "31/31 - 2s - loss: 0.5455 - auc: 0.8628 - auc_1: 0.7314 - 2s/epoch - 56ms/step\n",
            "Epoch 57/200\n",
            "31/31 - 2s - loss: 0.5445 - auc: 0.8598 - auc_1: 0.7289 - 2s/epoch - 57ms/step\n",
            "Epoch 58/200\n",
            "31/31 - 2s - loss: 0.5435 - auc: 0.8604 - auc_1: 0.7300 - 2s/epoch - 57ms/step\n",
            "Epoch 59/200\n",
            "31/31 - 2s - loss: 0.5425 - auc: 0.8561 - auc_1: 0.7262 - 2s/epoch - 56ms/step\n",
            "Epoch 60/200\n",
            "31/31 - 2s - loss: 0.5417 - auc: 0.8555 - auc_1: 0.7259 - 2s/epoch - 58ms/step\n",
            "Epoch 61/200\n",
            "31/31 - 2s - loss: 0.5405 - auc: 0.8567 - auc_1: 0.7275 - 2s/epoch - 56ms/step\n",
            "Epoch 62/200\n",
            "31/31 - 2s - loss: 0.5395 - auc: 0.8573 - auc_1: 0.7297 - 2s/epoch - 58ms/step\n",
            "Epoch 63/200\n",
            "31/31 - 2s - loss: 0.5385 - auc: 0.8579 - auc_1: 0.7309 - 2s/epoch - 56ms/step\n",
            "Epoch 64/200\n",
            "31/31 - 2s - loss: 0.5377 - auc: 0.8604 - auc_1: 0.7318 - 2s/epoch - 57ms/step\n",
            "Epoch 65/200\n",
            "31/31 - 2s - loss: 0.5367 - auc: 0.8591 - auc_1: 0.7332 - 2s/epoch - 58ms/step\n",
            "Epoch 66/200\n",
            "31/31 - 2s - loss: 0.5358 - auc: 0.8598 - auc_1: 0.7379 - 2s/epoch - 58ms/step\n",
            "Epoch 67/200\n",
            "31/31 - 2s - loss: 0.5350 - auc: 0.8677 - auc_1: 0.7454 - 2s/epoch - 56ms/step\n",
            "Epoch 68/200\n",
            "31/31 - 2s - loss: 0.5340 - auc: 0.8683 - auc_1: 0.7464 - 2s/epoch - 59ms/step\n",
            "Epoch 69/200\n",
            "31/31 - 2s - loss: 0.5331 - auc: 0.8659 - auc_1: 0.7381 - 2s/epoch - 58ms/step\n",
            "Epoch 70/200\n",
            "31/31 - 2s - loss: 0.5324 - auc: 0.8659 - auc_1: 0.7381 - 2s/epoch - 56ms/step\n",
            "Epoch 71/200\n",
            "31/31 - 2s - loss: 0.5316 - auc: 0.8671 - auc_1: 0.7394 - 2s/epoch - 56ms/step\n",
            "Epoch 72/200\n",
            "31/31 - 2s - loss: 0.5307 - auc: 0.8634 - auc_1: 0.7398 - 2s/epoch - 56ms/step\n",
            "Epoch 73/200\n",
            "31/31 - 2s - loss: 0.5300 - auc: 0.8640 - auc_1: 0.7407 - 2s/epoch - 56ms/step\n",
            "Epoch 74/200\n",
            "31/31 - 2s - loss: 0.5293 - auc: 0.8616 - auc_1: 0.7316 - 2s/epoch - 56ms/step\n",
            "Epoch 75/200\n",
            "31/31 - 2s - loss: 0.5287 - auc: 0.8622 - auc_1: 0.7364 - 2s/epoch - 56ms/step\n",
            "Epoch 76/200\n",
            "31/31 - 2s - loss: 0.5277 - auc: 0.8616 - auc_1: 0.7316 - 2s/epoch - 57ms/step\n",
            "Epoch 77/200\n",
            "31/31 - 2s - loss: 0.5271 - auc: 0.8646 - auc_1: 0.7343 - 2s/epoch - 57ms/step\n",
            "Epoch 78/200\n",
            "31/31 - 2s - loss: 0.5262 - auc: 0.8628 - auc_1: 0.7365 - 2s/epoch - 56ms/step\n",
            "Epoch 79/200\n",
            "31/31 - 2s - loss: 0.5256 - auc: 0.8628 - auc_1: 0.7365 - 2s/epoch - 58ms/step\n",
            "Epoch 80/200\n",
            "31/31 - 2s - loss: 0.5249 - auc: 0.8604 - auc_1: 0.7346 - 2s/epoch - 57ms/step\n",
            "Epoch 81/200\n",
            "31/31 - 2s - loss: 0.5242 - auc: 0.8604 - auc_1: 0.7346 - 2s/epoch - 59ms/step\n",
            "Epoch 82/200\n",
            "31/31 - 2s - loss: 0.5236 - auc: 0.8585 - auc_1: 0.7315 - 2s/epoch - 58ms/step\n",
            "Epoch 83/200\n",
            "31/31 - 2s - loss: 0.5229 - auc: 0.8573 - auc_1: 0.7307 - 2s/epoch - 57ms/step\n",
            "Epoch 84/200\n",
            "31/31 - 2s - loss: 0.5222 - auc: 0.8573 - auc_1: 0.7307 - 2s/epoch - 57ms/step\n",
            "Epoch 85/200\n",
            "31/31 - 2s - loss: 0.5216 - auc: 0.8585 - auc_1: 0.7309 - 2s/epoch - 56ms/step\n",
            "Epoch 86/200\n",
            "31/31 - 2s - loss: 0.5210 - auc: 0.8634 - auc_1: 0.7342 - 2s/epoch - 60ms/step\n",
            "Epoch 87/200\n",
            "31/31 - 2s - loss: 0.5205 - auc: 0.8628 - auc_1: 0.7349 - 2s/epoch - 57ms/step\n",
            "Epoch 88/200\n",
            "31/31 - 2s - loss: 0.5198 - auc: 0.8591 - auc_1: 0.7314 - 2s/epoch - 59ms/step\n",
            "Epoch 89/200\n",
            "31/31 - 2s - loss: 0.5193 - auc: 0.8604 - auc_1: 0.7356 - 2s/epoch - 58ms/step\n",
            "Epoch 90/200\n",
            "31/31 - 2s - loss: 0.5187 - auc: 0.8616 - auc_1: 0.7368 - 2s/epoch - 58ms/step\n",
            "Epoch 91/200\n",
            "31/31 - 2s - loss: 0.5180 - auc: 0.8628 - auc_1: 0.7411 - 2s/epoch - 58ms/step\n",
            "Epoch 92/200\n",
            "31/31 - 2s - loss: 0.5175 - auc: 0.8671 - auc_1: 0.7444 - 2s/epoch - 59ms/step\n",
            "Epoch 93/200\n",
            "31/31 - 2s - loss: 0.5169 - auc: 0.8671 - auc_1: 0.7444 - 2s/epoch - 57ms/step\n",
            "Epoch 94/200\n",
            "31/31 - 2s - loss: 0.5165 - auc: 0.8671 - auc_1: 0.7444 - 2s/epoch - 58ms/step\n",
            "Epoch 95/200\n",
            "31/31 - 2s - loss: 0.5160 - auc: 0.8689 - auc_1: 0.7473 - 2s/epoch - 58ms/step\n",
            "Epoch 96/200\n",
            "31/31 - 2s - loss: 0.5153 - auc: 0.8683 - auc_1: 0.7450 - 2s/epoch - 58ms/step\n",
            "Epoch 97/200\n",
            "31/31 - 2s - loss: 0.5147 - auc: 0.8689 - auc_1: 0.7461 - 2s/epoch - 57ms/step\n",
            "Epoch 98/200\n",
            "31/31 - 2s - loss: 0.5143 - auc: 0.8726 - auc_1: 0.7502 - 2s/epoch - 56ms/step\n",
            "Epoch 99/200\n",
            "31/31 - 2s - loss: 0.5138 - auc: 0.8695 - auc_1: 0.7472 - 2s/epoch - 56ms/step\n",
            "Epoch 100/200\n",
            "31/31 - 2s - loss: 0.5133 - auc: 0.8732 - auc_1: 0.7523 - 2s/epoch - 57ms/step\n",
            "Epoch 101/200\n",
            "31/31 - 2s - loss: 0.5129 - auc: 0.8726 - auc_1: 0.7541 - 2s/epoch - 58ms/step\n",
            "Epoch 102/200\n",
            "31/31 - 2s - loss: 0.5123 - auc: 0.8738 - auc_1: 0.7562 - 2s/epoch - 58ms/step\n",
            "Epoch 103/200\n",
            "31/31 - 2s - loss: 0.5119 - auc: 0.8713 - auc_1: 0.7532 - 2s/epoch - 58ms/step\n",
            "Epoch 104/200\n",
            "31/31 - 2s - loss: 0.5114 - auc: 0.8732 - auc_1: 0.7552 - 2s/epoch - 57ms/step\n",
            "Epoch 105/200\n",
            "31/31 - 2s - loss: 0.5108 - auc: 0.8732 - auc_1: 0.7552 - 2s/epoch - 56ms/step\n",
            "Epoch 106/200\n",
            "31/31 - 2s - loss: 0.5104 - auc: 0.8774 - auc_1: 0.7583 - 2s/epoch - 56ms/step\n",
            "Epoch 107/200\n",
            "31/31 - 2s - loss: 0.5099 - auc: 0.8732 - auc_1: 0.7531 - 2s/epoch - 57ms/step\n",
            "Epoch 108/200\n",
            "31/31 - 2s - loss: 0.5097 - auc: 0.8732 - auc_1: 0.7531 - 2s/epoch - 57ms/step\n",
            "Epoch 109/200\n",
            "31/31 - 2s - loss: 0.5090 - auc: 0.8732 - auc_1: 0.7531 - 2s/epoch - 56ms/step\n",
            "Epoch 110/200\n",
            "31/31 - 2s - loss: 0.5086 - auc: 0.8744 - auc_1: 0.7546 - 2s/epoch - 57ms/step\n",
            "Epoch 111/200\n",
            "31/31 - 2s - loss: 0.5083 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 57ms/step\n",
            "Epoch 112/200\n",
            "31/31 - 2s - loss: 0.5077 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 57ms/step\n",
            "Epoch 113/200\n",
            "31/31 - 2s - loss: 0.5073 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 56ms/step\n",
            "Epoch 114/200\n",
            "31/31 - 2s - loss: 0.5070 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 57ms/step\n",
            "Epoch 115/200\n",
            "31/31 - 2s - loss: 0.5064 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 57ms/step\n",
            "Epoch 116/200\n",
            "31/31 - 2s - loss: 0.5060 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 57ms/step\n",
            "Epoch 117/200\n",
            "31/31 - 2s - loss: 0.5057 - auc: 0.8713 - auc_1: 0.7514 - 2s/epoch - 55ms/step\n",
            "Epoch 118/200\n",
            "31/31 - 2s - loss: 0.5052 - auc: 0.8677 - auc_1: 0.7453 - 2s/epoch - 56ms/step\n",
            "Epoch 119/200\n",
            "31/31 - 2s - loss: 0.5048 - auc: 0.8677 - auc_1: 0.7453 - 2s/epoch - 58ms/step\n",
            "Epoch 120/200\n",
            "31/31 - 2s - loss: 0.5043 - auc: 0.8695 - auc_1: 0.7474 - 2s/epoch - 56ms/step\n",
            "Epoch 121/200\n",
            "31/31 - 2s - loss: 0.5040 - auc: 0.8695 - auc_1: 0.7474 - 2s/epoch - 57ms/step\n",
            "Epoch 122/200\n",
            "31/31 - 2s - loss: 0.5037 - auc: 0.8695 - auc_1: 0.7474 - 2s/epoch - 57ms/step\n",
            "Epoch 123/200\n",
            "31/31 - 2s - loss: 0.5032 - auc: 0.8713 - auc_1: 0.7495 - 2s/epoch - 56ms/step\n",
            "Epoch 124/200\n",
            "31/31 - 2s - loss: 0.5028 - auc: 0.8713 - auc_1: 0.7495 - 2s/epoch - 56ms/step\n",
            "Epoch 125/200\n",
            "31/31 - 2s - loss: 0.5024 - auc: 0.8713 - auc_1: 0.7495 - 2s/epoch - 57ms/step\n",
            "Epoch 126/200\n",
            "31/31 - 2s - loss: 0.5021 - auc: 0.8732 - auc_1: 0.7526 - 2s/epoch - 59ms/step\n",
            "Epoch 127/200\n",
            "31/31 - 2s - loss: 0.5016 - auc: 0.8732 - auc_1: 0.7526 - 2s/epoch - 57ms/step\n",
            "Epoch 128/200\n",
            "31/31 - 2s - loss: 0.5014 - auc: 0.8732 - auc_1: 0.7526 - 2s/epoch - 58ms/step\n",
            "Epoch 129/200\n",
            "31/31 - 2s - loss: 0.5008 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 58ms/step\n",
            "Epoch 130/200\n",
            "31/31 - 2s - loss: 0.5005 - auc: 0.8756 - auc_1: 0.7551 - 2s/epoch - 58ms/step\n",
            "Epoch 131/200\n",
            "31/31 - 2s - loss: 0.5001 - auc: 0.8713 - auc_1: 0.7504 - 2s/epoch - 57ms/step\n",
            "Epoch 132/200\n",
            "31/31 - 2s - loss: 0.4997 - auc: 0.8713 - auc_1: 0.7504 - 2s/epoch - 56ms/step\n",
            "Epoch 133/200\n",
            "31/31 - 2s - loss: 0.4994 - auc: 0.8713 - auc_1: 0.7504 - 2s/epoch - 57ms/step\n",
            "Epoch 134/200\n",
            "31/31 - 2s - loss: 0.4990 - auc: 0.8713 - auc_1: 0.7504 - 2s/epoch - 58ms/step\n",
            "Epoch 135/200\n",
            "31/31 - 2s - loss: 0.4986 - auc: 0.8720 - auc_1: 0.7517 - 2s/epoch - 58ms/step\n",
            "Epoch 136/200\n",
            "31/31 - 2s - loss: 0.4983 - auc: 0.8701 - auc_1: 0.7488 - 2s/epoch - 58ms/step\n",
            "Epoch 137/200\n",
            "31/31 - 2s - loss: 0.4979 - auc: 0.8713 - auc_1: 0.7503 - 2s/epoch - 59ms/step\n",
            "Epoch 138/200\n",
            "31/31 - 2s - loss: 0.4975 - auc: 0.8713 - auc_1: 0.7503 - 2s/epoch - 56ms/step\n",
            "Epoch 139/200\n",
            "31/31 - 2s - loss: 0.4973 - auc: 0.8689 - auc_1: 0.7480 - 2s/epoch - 56ms/step\n",
            "Epoch 140/200\n",
            "31/31 - 2s - loss: 0.4971 - auc: 0.8689 - auc_1: 0.7480 - 2s/epoch - 57ms/step\n",
            "Epoch 141/200\n",
            "31/31 - 2s - loss: 0.4966 - auc: 0.8707 - auc_1: 0.7499 - 2s/epoch - 56ms/step\n",
            "Epoch 142/200\n",
            "31/31 - 2s - loss: 0.4962 - auc: 0.8707 - auc_1: 0.7499 - 2s/epoch - 57ms/step\n",
            "Epoch 143/200\n",
            "31/31 - 2s - loss: 0.4958 - auc: 0.8707 - auc_1: 0.7499 - 2s/epoch - 57ms/step\n",
            "Epoch 144/200\n",
            "31/31 - 2s - loss: 0.4956 - auc: 0.8695 - auc_1: 0.7490 - 2s/epoch - 57ms/step\n",
            "Epoch 145/200\n",
            "31/31 - 2s - loss: 0.4952 - auc: 0.8726 - auc_1: 0.7518 - 2s/epoch - 57ms/step\n",
            "Epoch 146/200\n",
            "31/31 - 2s - loss: 0.4950 - auc: 0.8707 - auc_1: 0.7499 - 2s/epoch - 58ms/step\n",
            "Epoch 147/200\n",
            "31/31 - 2s - loss: 0.4946 - auc: 0.8726 - auc_1: 0.7543 - 2s/epoch - 57ms/step\n",
            "Epoch 148/200\n",
            "31/31 - 2s - loss: 0.4943 - auc: 0.8707 - auc_1: 0.7524 - 2s/epoch - 57ms/step\n",
            "Epoch 149/200\n",
            "31/31 - 2s - loss: 0.4939 - auc: 0.8726 - auc_1: 0.7543 - 2s/epoch - 58ms/step\n",
            "Epoch 150/200\n",
            "31/31 - 2s - loss: 0.4938 - auc: 0.8707 - auc_1: 0.7524 - 2s/epoch - 57ms/step\n",
            "Epoch 151/200\n",
            "31/31 - 2s - loss: 0.4933 - auc: 0.8707 - auc_1: 0.7524 - 2s/epoch - 56ms/step\n",
            "Epoch 152/200\n",
            "31/31 - 2s - loss: 0.4930 - auc: 0.8726 - auc_1: 0.7543 - 2s/epoch - 57ms/step\n",
            "Epoch 153/200\n",
            "31/31 - 2s - loss: 0.4927 - auc: 0.8726 - auc_1: 0.7543 - 2s/epoch - 57ms/step\n",
            "Epoch 154/200\n",
            "31/31 - 2s - loss: 0.4924 - auc: 0.8738 - auc_1: 0.7557 - 2s/epoch - 58ms/step\n",
            "Epoch 155/200\n",
            "31/31 - 2s - loss: 0.4921 - auc: 0.8738 - auc_1: 0.7557 - 2s/epoch - 57ms/step\n",
            "Epoch 156/200\n",
            "31/31 - 2s - loss: 0.4918 - auc: 0.8738 - auc_1: 0.7533 - 2s/epoch - 58ms/step\n",
            "Epoch 157/200\n",
            "31/31 - 2s - loss: 0.4914 - auc: 0.8720 - auc_1: 0.7515 - 2s/epoch - 57ms/step\n",
            "Epoch 158/200\n",
            "31/31 - 2s - loss: 0.4911 - auc: 0.8756 - auc_1: 0.7583 - 2s/epoch - 56ms/step\n",
            "Epoch 159/200\n",
            "31/31 - 2s - loss: 0.4909 - auc: 0.8744 - auc_1: 0.7544 - 2s/epoch - 57ms/step\n",
            "Epoch 160/200\n",
            "31/31 - 2s - loss: 0.4906 - auc: 0.8750 - auc_1: 0.7552 - 2s/epoch - 56ms/step\n",
            "Epoch 161/200\n",
            "31/31 - 2s - loss: 0.4903 - auc: 0.8750 - auc_1: 0.7552 - 2s/epoch - 56ms/step\n",
            "Epoch 162/200\n",
            "31/31 - 2s - loss: 0.4902 - auc: 0.8701 - auc_1: 0.7473 - 2s/epoch - 56ms/step\n",
            "Epoch 163/200\n",
            "31/31 - 2s - loss: 0.4895 - auc: 0.8713 - auc_1: 0.7501 - 2s/epoch - 57ms/step\n",
            "Epoch 164/200\n",
            "31/31 - 2s - loss: 0.4892 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 56ms/step\n",
            "Epoch 165/200\n",
            "31/31 - 2s - loss: 0.4890 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 55ms/step\n",
            "Epoch 166/200\n",
            "31/31 - 2s - loss: 0.4888 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 57ms/step\n",
            "Epoch 167/200\n",
            "31/31 - 2s - loss: 0.4884 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 57ms/step\n",
            "Epoch 168/200\n",
            "31/31 - 2s - loss: 0.4882 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 57ms/step\n",
            "Epoch 169/200\n",
            "31/31 - 2s - loss: 0.4879 - auc: 0.8720 - auc_1: 0.7521 - 2s/epoch - 56ms/step\n",
            "Epoch 170/200\n",
            "31/31 - 2s - loss: 0.4877 - auc: 0.8726 - auc_1: 0.7516 - 2s/epoch - 56ms/step\n",
            "Epoch 171/200\n",
            "31/31 - 2s - loss: 0.4872 - auc: 0.8726 - auc_1: 0.7516 - 2s/epoch - 57ms/step\n",
            "Epoch 172/200\n",
            "31/31 - 2s - loss: 0.4869 - auc: 0.8726 - auc_1: 0.7516 - 2s/epoch - 57ms/step\n",
            "Epoch 173/200\n",
            "31/31 - 2s - loss: 0.4866 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 58ms/step\n",
            "Epoch 174/200\n",
            "31/31 - 2s - loss: 0.4864 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 57ms/step\n",
            "Epoch 175/200\n",
            "31/31 - 2s - loss: 0.4860 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 56ms/step\n",
            "Epoch 176/200\n",
            "31/31 - 2s - loss: 0.4859 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 56ms/step\n",
            "Epoch 177/200\n",
            "31/31 - 2s - loss: 0.4855 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 57ms/step\n",
            "Epoch 178/200\n",
            "31/31 - 2s - loss: 0.4852 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 58ms/step\n",
            "Epoch 179/200\n",
            "31/31 - 2s - loss: 0.4850 - auc: 0.8720 - auc_1: 0.7527 - 2s/epoch - 59ms/step\n",
            "Epoch 180/200\n",
            "31/31 - 2s - loss: 0.4847 - auc: 0.8750 - auc_1: 0.7557 - 2s/epoch - 56ms/step\n",
            "Epoch 181/200\n",
            "31/31 - 2s - loss: 0.4844 - auc: 0.8774 - auc_1: 0.7597 - 2s/epoch - 57ms/step\n",
            "Epoch 182/200\n",
            "31/31 - 2s - loss: 0.4841 - auc: 0.8774 - auc_1: 0.7597 - 2s/epoch - 58ms/step\n",
            "Epoch 183/200\n",
            "31/31 - 2s - loss: 0.4838 - auc: 0.8774 - auc_1: 0.7597 - 2s/epoch - 58ms/step\n",
            "Epoch 184/200\n",
            "31/31 - 2s - loss: 0.4836 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 57ms/step\n",
            "Epoch 185/200\n",
            "31/31 - 2s - loss: 0.4833 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 57ms/step\n",
            "Epoch 186/200\n",
            "31/31 - 2s - loss: 0.4830 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 56ms/step\n",
            "Epoch 187/200\n",
            "31/31 - 2s - loss: 0.4830 - auc: 0.8738 - auc_1: 0.7563 - 2s/epoch - 57ms/step\n",
            "Epoch 188/200\n",
            "31/31 - 2s - loss: 0.4826 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 59ms/step\n",
            "Epoch 189/200\n",
            "31/31 - 2s - loss: 0.4821 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 58ms/step\n",
            "Epoch 190/200\n",
            "31/31 - 2s - loss: 0.4819 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 57ms/step\n",
            "Epoch 191/200\n",
            "31/31 - 2s - loss: 0.4816 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 56ms/step\n",
            "Epoch 192/200\n",
            "31/31 - 2s - loss: 0.4813 - auc: 0.8744 - auc_1: 0.7567 - 2s/epoch - 58ms/step\n",
            "Epoch 193/200\n",
            "31/31 - 2s - loss: 0.4811 - auc: 0.8726 - auc_1: 0.7546 - 2s/epoch - 57ms/step\n",
            "Epoch 194/200\n",
            "31/31 - 2s - loss: 0.4808 - auc: 0.8750 - auc_1: 0.7578 - 2s/epoch - 56ms/step\n",
            "Epoch 195/200\n",
            "31/31 - 2s - loss: 0.4804 - auc: 0.8750 - auc_1: 0.7578 - 2s/epoch - 57ms/step\n",
            "Epoch 196/200\n",
            "31/31 - 2s - loss: 0.4802 - auc: 0.8750 - auc_1: 0.7578 - 2s/epoch - 57ms/step\n",
            "Epoch 197/200\n",
            "31/31 - 2s - loss: 0.4802 - auc: 0.8744 - auc_1: 0.7574 - 2s/epoch - 58ms/step\n",
            "Epoch 198/200\n",
            "31/31 - 2s - loss: 0.4799 - auc: 0.8744 - auc_1: 0.7574 - 2s/epoch - 58ms/step\n",
            "Epoch 199/200\n",
            "31/31 - 2s - loss: 0.4795 - auc: 0.8744 - auc_1: 0.7574 - 2s/epoch - 58ms/step\n",
            "Epoch 200/200\n",
            "31/31 - 2s - loss: 0.4791 - auc: 0.8750 - auc_1: 0.7578 - 2s/epoch - 57ms/step\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.5846 - auc: 0.5370 - auc_1: 0.2563\n",
            "Epoch 1/200\n",
            "50/50 - 3s - loss: 0.3346 - auc: 0.8439 - auc_1: 0.4975 - 3s/epoch - 57ms/step\n",
            "Epoch 2/200\n",
            "50/50 - 3s - loss: 0.3300 - auc: 0.8463 - auc_1: 0.4993 - 3s/epoch - 58ms/step\n",
            "Epoch 3/200\n",
            "50/50 - 3s - loss: 0.3255 - auc: 0.8455 - auc_1: 0.5003 - 3s/epoch - 57ms/step\n",
            "Epoch 4/200\n",
            "50/50 - 3s - loss: 0.3210 - auc: 0.8416 - auc_1: 0.5031 - 3s/epoch - 56ms/step\n",
            "Epoch 5/200\n",
            "50/50 - 3s - loss: 0.3166 - auc: 0.8455 - auc_1: 0.5039 - 3s/epoch - 56ms/step\n",
            "Epoch 6/200\n",
            "50/50 - 3s - loss: 0.3121 - auc: 0.8393 - auc_1: 0.5114 - 3s/epoch - 56ms/step\n",
            "Epoch 7/200\n",
            "50/50 - 3s - loss: 0.3077 - auc: 0.8432 - auc_1: 0.5124 - 3s/epoch - 56ms/step\n",
            "Epoch 8/200\n",
            "50/50 - 3s - loss: 0.3034 - auc: 0.8525 - auc_1: 0.5196 - 3s/epoch - 56ms/step\n",
            "Epoch 9/200\n",
            "50/50 - 3s - loss: 0.2991 - auc: 0.8447 - auc_1: 0.5109 - 3s/epoch - 57ms/step\n",
            "Epoch 10/200\n",
            "50/50 - 3s - loss: 0.2949 - auc: 0.8416 - auc_1: 0.5105 - 3s/epoch - 56ms/step\n",
            "Epoch 11/200\n",
            "50/50 - 3s - loss: 0.2908 - auc: 0.8439 - auc_1: 0.5106 - 3s/epoch - 57ms/step\n",
            "Epoch 12/200\n",
            "50/50 - 3s - loss: 0.2868 - auc: 0.8478 - auc_1: 0.5138 - 3s/epoch - 57ms/step\n",
            "Epoch 13/200\n",
            "50/50 - 3s - loss: 0.2828 - auc: 0.8447 - auc_1: 0.5147 - 3s/epoch - 55ms/step\n",
            "Epoch 14/200\n",
            "50/50 - 3s - loss: 0.2790 - auc: 0.8509 - auc_1: 0.5187 - 3s/epoch - 56ms/step\n",
            "Epoch 15/200\n",
            "50/50 - 3s - loss: 0.2752 - auc: 0.8339 - auc_1: 0.5273 - 3s/epoch - 55ms/step\n",
            "Epoch 16/200\n",
            "50/50 - 3s - loss: 0.2716 - auc: 0.8408 - auc_1: 0.5290 - 3s/epoch - 55ms/step\n",
            "Epoch 17/200\n",
            "50/50 - 3s - loss: 0.2681 - auc: 0.8439 - auc_1: 0.5315 - 3s/epoch - 56ms/step\n",
            "Epoch 18/200\n",
            "50/50 - 3s - loss: 0.2645 - auc: 0.8470 - auc_1: 0.5322 - 3s/epoch - 55ms/step\n",
            "Epoch 19/200\n",
            "50/50 - 3s - loss: 0.2611 - auc: 0.8470 - auc_1: 0.5329 - 3s/epoch - 55ms/step\n",
            "Epoch 20/200\n",
            "50/50 - 3s - loss: 0.2578 - auc: 0.8494 - auc_1: 0.5371 - 3s/epoch - 56ms/step\n",
            "Epoch 21/200\n",
            "50/50 - 3s - loss: 0.2546 - auc: 0.8393 - auc_1: 0.5287 - 3s/epoch - 56ms/step\n",
            "Epoch 22/200\n",
            "50/50 - 3s - loss: 0.2516 - auc: 0.8439 - auc_1: 0.5328 - 3s/epoch - 56ms/step\n",
            "Epoch 23/200\n",
            "50/50 - 3s - loss: 0.2485 - auc: 0.8424 - auc_1: 0.5322 - 3s/epoch - 56ms/step\n",
            "Epoch 24/200\n",
            "50/50 - 3s - loss: 0.2456 - auc: 0.8455 - auc_1: 0.5317 - 3s/epoch - 56ms/step\n",
            "Epoch 25/200\n",
            "50/50 - 3s - loss: 0.2428 - auc: 0.8478 - auc_1: 0.5584 - 3s/epoch - 56ms/step\n",
            "Epoch 26/200\n",
            "50/50 - 3s - loss: 0.2399 - auc: 0.8517 - auc_1: 0.5240 - 3s/epoch - 55ms/step\n",
            "Epoch 27/200\n",
            "50/50 - 3s - loss: 0.2373 - auc: 0.8447 - auc_1: 0.5165 - 3s/epoch - 56ms/step\n",
            "Epoch 28/200\n",
            "50/50 - 3s - loss: 0.2348 - auc: 0.8486 - auc_1: 0.5324 - 3s/epoch - 55ms/step\n",
            "Epoch 29/200\n",
            "50/50 - 3s - loss: 0.2322 - auc: 0.8564 - auc_1: 0.5390 - 3s/epoch - 55ms/step\n",
            "Epoch 30/200\n",
            "50/50 - 3s - loss: 0.2299 - auc: 0.8463 - auc_1: 0.5376 - 3s/epoch - 55ms/step\n",
            "Epoch 31/200\n",
            "50/50 - 3s - loss: 0.2274 - auc: 0.8455 - auc_1: 0.5317 - 3s/epoch - 56ms/step\n",
            "Epoch 32/200\n",
            "50/50 - 3s - loss: 0.2253 - auc: 0.8525 - auc_1: 0.5586 - 3s/epoch - 56ms/step\n",
            "Epoch 33/200\n",
            "50/50 - 3s - loss: 0.2231 - auc: 0.8463 - auc_1: 0.5569 - 3s/epoch - 55ms/step\n",
            "Epoch 34/200\n",
            "50/50 - 3s - loss: 0.2212 - auc: 0.8517 - auc_1: 0.5607 - 3s/epoch - 55ms/step\n",
            "Epoch 35/200\n",
            "50/50 - 3s - loss: 0.2190 - auc: 0.8548 - auc_1: 0.5664 - 3s/epoch - 57ms/step\n",
            "Epoch 36/200\n",
            "50/50 - 3s - loss: 0.2172 - auc: 0.8556 - auc_1: 0.5594 - 3s/epoch - 56ms/step\n",
            "Epoch 37/200\n",
            "50/50 - 3s - loss: 0.2153 - auc: 0.8564 - auc_1: 0.5617 - 3s/epoch - 56ms/step\n",
            "Epoch 38/200\n",
            "50/50 - 3s - loss: 0.2138 - auc: 0.8595 - auc_1: 0.5629 - 3s/epoch - 56ms/step\n",
            "Epoch 39/200\n",
            "50/50 - 3s - loss: 0.2119 - auc: 0.8626 - auc_1: 0.5686 - 3s/epoch - 56ms/step\n",
            "Epoch 40/200\n",
            "50/50 - 3s - loss: 0.2102 - auc: 0.8533 - auc_1: 0.5588 - 3s/epoch - 56ms/step\n",
            "Epoch 41/200\n",
            "50/50 - 3s - loss: 0.2086 - auc: 0.8455 - auc_1: 0.5581 - 3s/epoch - 56ms/step\n",
            "Epoch 42/200\n",
            "50/50 - 3s - loss: 0.2070 - auc: 0.8463 - auc_1: 0.5604 - 3s/epoch - 57ms/step\n",
            "Epoch 43/200\n",
            "50/50 - 3s - loss: 0.2055 - auc: 0.8502 - auc_1: 0.5652 - 3s/epoch - 56ms/step\n",
            "Epoch 44/200\n",
            "50/50 - 3s - loss: 0.2040 - auc: 0.8533 - auc_1: 0.5660 - 3s/epoch - 56ms/step\n",
            "Epoch 45/200\n",
            "50/50 - 3s - loss: 0.2027 - auc: 0.8571 - auc_1: 0.5684 - 3s/epoch - 56ms/step\n",
            "Epoch 46/200\n",
            "50/50 - 3s - loss: 0.2012 - auc: 0.8595 - auc_1: 0.5663 - 3s/epoch - 57ms/step\n",
            "Epoch 47/200\n",
            "50/50 - 3s - loss: 0.2000 - auc: 0.8641 - auc_1: 0.5719 - 3s/epoch - 57ms/step\n",
            "Epoch 48/200\n",
            "50/50 - 3s - loss: 0.1989 - auc: 0.8641 - auc_1: 0.5719 - 3s/epoch - 55ms/step\n",
            "Epoch 49/200\n",
            "50/50 - 3s - loss: 0.1975 - auc: 0.8634 - auc_1: 0.5702 - 3s/epoch - 55ms/step\n",
            "Epoch 50/200\n",
            "50/50 - 3s - loss: 0.1962 - auc: 0.8649 - auc_1: 0.5695 - 3s/epoch - 55ms/step\n",
            "Epoch 51/200\n",
            "50/50 - 3s - loss: 0.1950 - auc: 0.8696 - auc_1: 0.5710 - 3s/epoch - 55ms/step\n",
            "Epoch 52/200\n",
            "50/50 - 3s - loss: 0.1940 - auc: 0.8711 - auc_1: 0.5715 - 3s/epoch - 56ms/step\n",
            "Epoch 53/200\n",
            "50/50 - 3s - loss: 0.1928 - auc: 0.8742 - auc_1: 0.5768 - 3s/epoch - 55ms/step\n",
            "Epoch 54/200\n",
            "50/50 - 3s - loss: 0.1916 - auc: 0.8766 - auc_1: 0.5793 - 3s/epoch - 56ms/step\n",
            "Epoch 55/200\n",
            "50/50 - 3s - loss: 0.1907 - auc: 0.8758 - auc_1: 0.5764 - 3s/epoch - 56ms/step\n",
            "Epoch 56/200\n",
            "50/50 - 3s - loss: 0.1897 - auc: 0.8812 - auc_1: 0.5768 - 3s/epoch - 56ms/step\n",
            "Epoch 57/200\n",
            "50/50 - 3s - loss: 0.1888 - auc: 0.8641 - auc_1: 0.5741 - 3s/epoch - 56ms/step\n",
            "Epoch 58/200\n",
            "50/50 - 3s - loss: 0.1881 - auc: 0.8688 - auc_1: 0.5753 - 3s/epoch - 56ms/step\n",
            "Epoch 59/200\n",
            "50/50 - 3s - loss: 0.1870 - auc: 0.8688 - auc_1: 0.5743 - 3s/epoch - 55ms/step\n",
            "Epoch 60/200\n",
            "50/50 - 3s - loss: 0.1862 - auc: 0.8711 - auc_1: 0.5751 - 3s/epoch - 55ms/step\n",
            "Epoch 61/200\n",
            "50/50 - 3s - loss: 0.1854 - auc: 0.8727 - auc_1: 0.5758 - 3s/epoch - 57ms/step\n",
            "Epoch 62/200\n",
            "50/50 - 3s - loss: 0.1846 - auc: 0.8734 - auc_1: 0.5760 - 3s/epoch - 56ms/step\n",
            "Epoch 63/200\n",
            "50/50 - 3s - loss: 0.1838 - auc: 0.8758 - auc_1: 0.5795 - 3s/epoch - 58ms/step\n",
            "Epoch 64/200\n",
            "50/50 - 3s - loss: 0.1831 - auc: 0.8773 - auc_1: 0.5820 - 3s/epoch - 59ms/step\n",
            "Epoch 65/200\n",
            "50/50 - 3s - loss: 0.1824 - auc: 0.8610 - auc_1: 0.5736 - 3s/epoch - 59ms/step\n",
            "Epoch 66/200\n",
            "50/50 - 3s - loss: 0.1817 - auc: 0.8626 - auc_1: 0.5740 - 3s/epoch - 57ms/step\n",
            "Epoch 67/200\n",
            "50/50 - 3s - loss: 0.1811 - auc: 0.8626 - auc_1: 0.5740 - 3s/epoch - 57ms/step\n",
            "Epoch 68/200\n",
            "50/50 - 3s - loss: 0.1805 - auc: 0.8672 - auc_1: 0.5754 - 3s/epoch - 57ms/step\n",
            "Epoch 69/200\n",
            "50/50 - 3s - loss: 0.1799 - auc: 0.8680 - auc_1: 0.5777 - 3s/epoch - 57ms/step\n",
            "Epoch 70/200\n",
            "50/50 - 3s - loss: 0.1792 - auc: 0.8672 - auc_1: 0.5802 - 3s/epoch - 56ms/step\n",
            "Epoch 71/200\n",
            "50/50 - 3s - loss: 0.1788 - auc: 0.8719 - auc_1: 0.5816 - 3s/epoch - 57ms/step\n",
            "Epoch 72/200\n",
            "50/50 - 3s - loss: 0.1781 - auc: 0.8742 - auc_1: 0.5804 - 3s/epoch - 58ms/step\n",
            "Epoch 73/200\n",
            "50/50 - 3s - loss: 0.1775 - auc: 0.8727 - auc_1: 0.5792 - 3s/epoch - 57ms/step\n",
            "Epoch 74/200\n",
            "50/50 - 3s - loss: 0.1770 - auc: 0.8758 - auc_1: 0.5803 - 3s/epoch - 58ms/step\n",
            "Epoch 75/200\n",
            "50/50 - 3s - loss: 0.1765 - auc: 0.8773 - auc_1: 0.5809 - 3s/epoch - 57ms/step\n",
            "Epoch 76/200\n",
            "50/50 - 3s - loss: 0.1762 - auc: 0.8789 - auc_1: 0.5814 - 3s/epoch - 57ms/step\n",
            "Epoch 77/200\n",
            "50/50 - 3s - loss: 0.1755 - auc: 0.8789 - auc_1: 0.5814 - 3s/epoch - 58ms/step\n",
            "Epoch 78/200\n",
            "50/50 - 3s - loss: 0.1751 - auc: 0.8797 - auc_1: 0.5844 - 3s/epoch - 57ms/step\n",
            "Epoch 79/200\n",
            "50/50 - 3s - loss: 0.1747 - auc: 0.8797 - auc_1: 0.5844 - 3s/epoch - 57ms/step\n",
            "Epoch 80/200\n",
            "50/50 - 3s - loss: 0.1743 - auc: 0.8812 - auc_1: 0.5849 - 3s/epoch - 56ms/step\n",
            "Epoch 81/200\n",
            "50/50 - 3s - loss: 0.1738 - auc: 0.8820 - auc_1: 0.5884 - 3s/epoch - 56ms/step\n",
            "Epoch 82/200\n",
            "50/50 - 3s - loss: 0.1735 - auc: 0.8804 - auc_1: 0.5820 - 3s/epoch - 57ms/step\n",
            "Epoch 83/200\n",
            "50/50 - 3s - loss: 0.1731 - auc: 0.8804 - auc_1: 0.5820 - 3s/epoch - 56ms/step\n",
            "Epoch 84/200\n",
            "50/50 - 3s - loss: 0.1728 - auc: 0.8820 - auc_1: 0.5826 - 3s/epoch - 56ms/step\n",
            "Epoch 85/200\n",
            "50/50 - 3s - loss: 0.1723 - auc: 0.8820 - auc_1: 0.5826 - 3s/epoch - 55ms/step\n",
            "Epoch 86/200\n",
            "50/50 - 3s - loss: 0.1720 - auc: 0.8843 - auc_1: 0.5858 - 3s/epoch - 57ms/step\n",
            "Epoch 87/200\n",
            "50/50 - 3s - loss: 0.1717 - auc: 0.8859 - auc_1: 0.5865 - 3s/epoch - 56ms/step\n",
            "Epoch 88/200\n",
            "50/50 - 3s - loss: 0.1714 - auc: 0.8882 - auc_1: 0.5901 - 3s/epoch - 55ms/step\n",
            "Epoch 89/200\n",
            "50/50 - 3s - loss: 0.1711 - auc: 0.8882 - auc_1: 0.5901 - 3s/epoch - 55ms/step\n",
            "Epoch 90/200\n",
            "50/50 - 3s - loss: 0.1708 - auc: 0.8882 - auc_1: 0.5901 - 3s/epoch - 56ms/step\n",
            "Epoch 91/200\n",
            "50/50 - 3s - loss: 0.1705 - auc: 0.8905 - auc_1: 0.5942 - 3s/epoch - 55ms/step\n",
            "Epoch 92/200\n",
            "50/50 - 3s - loss: 0.1702 - auc: 0.8913 - auc_1: 0.5983 - 3s/epoch - 55ms/step\n",
            "Epoch 93/200\n",
            "50/50 - 3s - loss: 0.1700 - auc: 0.8913 - auc_1: 0.5983 - 3s/epoch - 57ms/step\n",
            "Epoch 94/200\n",
            "50/50 - 3s - loss: 0.1696 - auc: 0.8913 - auc_1: 0.5983 - 3s/epoch - 56ms/step\n",
            "Epoch 95/200\n",
            "50/50 - 3s - loss: 0.1695 - auc: 0.8913 - auc_1: 0.5983 - 3s/epoch - 56ms/step\n",
            "Epoch 96/200\n",
            "50/50 - 3s - loss: 0.1691 - auc: 0.8921 - auc_1: 0.6022 - 3s/epoch - 56ms/step\n",
            "Epoch 97/200\n",
            "50/50 - 3s - loss: 0.1689 - auc: 0.8898 - auc_1: 0.5907 - 3s/epoch - 56ms/step\n",
            "Epoch 98/200\n",
            "50/50 - 3s - loss: 0.1687 - auc: 0.8921 - auc_1: 0.5941 - 3s/epoch - 56ms/step\n",
            "Epoch 99/200\n",
            "50/50 - 3s - loss: 0.1684 - auc: 0.8921 - auc_1: 0.5941 - 3s/epoch - 56ms/step\n",
            "Epoch 100/200\n",
            "50/50 - 3s - loss: 0.1683 - auc: 0.8944 - auc_1: 0.6042 - 3s/epoch - 57ms/step\n",
            "Epoch 101/200\n",
            "50/50 - 3s - loss: 0.1681 - auc: 0.8944 - auc_1: 0.6042 - 3s/epoch - 57ms/step\n",
            "Epoch 102/200\n",
            "50/50 - 3s - loss: 0.1676 - auc: 0.8944 - auc_1: 0.6042 - 3s/epoch - 56ms/step\n",
            "Epoch 103/200\n",
            "50/50 - 3s - loss: 0.1675 - auc: 0.8960 - auc_1: 0.6049 - 3s/epoch - 56ms/step\n",
            "Epoch 104/200\n",
            "50/50 - 3s - loss: 0.1673 - auc: 0.8975 - auc_1: 0.6056 - 3s/epoch - 57ms/step\n",
            "Epoch 105/200\n",
            "50/50 - 3s - loss: 0.1671 - auc: 0.8975 - auc_1: 0.6056 - 3s/epoch - 57ms/step\n",
            "Epoch 106/200\n",
            "50/50 - 3s - loss: 0.1669 - auc: 0.8991 - auc_1: 0.6134 - 3s/epoch - 56ms/step\n",
            "Epoch 107/200\n",
            "50/50 - 3s - loss: 0.1667 - auc: 0.8991 - auc_1: 0.6134 - 3s/epoch - 57ms/step\n",
            "Epoch 108/200\n",
            "50/50 - 3s - loss: 0.1666 - auc: 0.9006 - auc_1: 0.6142 - 3s/epoch - 57ms/step\n",
            "Epoch 109/200\n",
            "50/50 - 3s - loss: 0.1662 - auc: 0.8991 - auc_1: 0.6134 - 3s/epoch - 56ms/step\n",
            "Epoch 110/200\n",
            "50/50 - 3s - loss: 0.1661 - auc: 0.9022 - auc_1: 0.6149 - 3s/epoch - 56ms/step\n",
            "Epoch 111/200\n",
            "50/50 - 3s - loss: 0.1658 - auc: 0.9006 - auc_1: 0.6142 - 3s/epoch - 57ms/step\n",
            "Epoch 112/200\n",
            "50/50 - 3s - loss: 0.1657 - auc: 0.9006 - auc_1: 0.6142 - 3s/epoch - 56ms/step\n",
            "Epoch 113/200\n",
            "50/50 - 3s - loss: 0.1657 - auc: 0.9022 - auc_1: 0.6149 - 3s/epoch - 56ms/step\n",
            "Epoch 114/200\n",
            "50/50 - 3s - loss: 0.1654 - auc: 0.9037 - auc_1: 0.6157 - 3s/epoch - 57ms/step\n",
            "Epoch 115/200\n",
            "50/50 - 3s - loss: 0.1651 - auc: 0.9037 - auc_1: 0.6157 - 3s/epoch - 57ms/step\n",
            "Epoch 116/200\n",
            "50/50 - 3s - loss: 0.1651 - auc: 0.9037 - auc_1: 0.6157 - 3s/epoch - 56ms/step\n",
            "Epoch 117/200\n",
            "50/50 - 3s - loss: 0.1648 - auc: 0.9037 - auc_1: 0.6157 - 3s/epoch - 56ms/step\n",
            "Epoch 118/200\n",
            "50/50 - 3s - loss: 0.1648 - auc: 0.9068 - auc_1: 0.6175 - 3s/epoch - 56ms/step\n",
            "Epoch 119/200\n",
            "50/50 - 3s - loss: 0.1645 - auc: 0.9053 - auc_1: 0.6166 - 3s/epoch - 56ms/step\n",
            "Epoch 120/200\n",
            "50/50 - 3s - loss: 0.1644 - auc: 0.9037 - auc_1: 0.6157 - 3s/epoch - 56ms/step\n",
            "Epoch 121/200\n",
            "50/50 - 3s - loss: 0.1642 - auc: 0.9053 - auc_1: 0.6166 - 3s/epoch - 55ms/step\n",
            "Epoch 122/200\n",
            "50/50 - 3s - loss: 0.1639 - auc: 0.9084 - auc_1: 0.6258 - 3s/epoch - 56ms/step\n",
            "Epoch 123/200\n",
            "50/50 - 3s - loss: 0.1638 - auc: 0.9084 - auc_1: 0.6258 - 3s/epoch - 56ms/step\n",
            "Epoch 124/200\n",
            "50/50 - 3s - loss: 0.1638 - auc: 0.8866 - auc_1: 0.6175 - 3s/epoch - 55ms/step\n",
            "Epoch 125/200\n",
            "50/50 - 3s - loss: 0.1636 - auc: 0.8866 - auc_1: 0.6175 - 3s/epoch - 55ms/step\n",
            "Epoch 126/200\n",
            "50/50 - 3s - loss: 0.1635 - auc: 0.9099 - auc_1: 0.6267 - 3s/epoch - 55ms/step\n",
            "Epoch 127/200\n",
            "50/50 - 3s - loss: 0.1633 - auc: 0.9099 - auc_1: 0.6267 - 3s/epoch - 55ms/step\n",
            "Epoch 128/200\n",
            "50/50 - 3s - loss: 0.1634 - auc: 0.9053 - auc_1: 0.6241 - 3s/epoch - 55ms/step\n",
            "Epoch 129/200\n",
            "50/50 - 3s - loss: 0.1630 - auc: 0.8866 - auc_1: 0.6175 - 3s/epoch - 56ms/step\n",
            "Epoch 130/200\n",
            "50/50 - 3s - loss: 0.1628 - auc: 0.8866 - auc_1: 0.6175 - 3s/epoch - 57ms/step\n",
            "Epoch 131/200\n",
            "50/50 - 3s - loss: 0.1626 - auc: 0.9115 - auc_1: 0.6276 - 3s/epoch - 56ms/step\n",
            "Epoch 132/200\n",
            "50/50 - 3s - loss: 0.1625 - auc: 0.9115 - auc_1: 0.6276 - 3s/epoch - 56ms/step\n",
            "Epoch 133/200\n",
            "50/50 - 3s - loss: 0.1624 - auc: 0.8890 - auc_1: 0.6187 - 3s/epoch - 56ms/step\n",
            "Epoch 134/200\n",
            "50/50 - 3s - loss: 0.1623 - auc: 0.8882 - auc_1: 0.6182 - 3s/epoch - 56ms/step\n",
            "Epoch 135/200\n",
            "50/50 - 3s - loss: 0.1621 - auc: 0.8882 - auc_1: 0.6182 - 3s/epoch - 55ms/step\n",
            "Epoch 136/200\n",
            "50/50 - 3s - loss: 0.1620 - auc: 0.8882 - auc_1: 0.6182 - 3s/epoch - 56ms/step\n",
            "Epoch 137/200\n",
            "50/50 - 3s - loss: 0.1619 - auc: 0.8905 - auc_1: 0.6197 - 3s/epoch - 57ms/step\n",
            "Epoch 138/200\n",
            "50/50 - 3s - loss: 0.1617 - auc: 0.8913 - auc_1: 0.6282 - 3s/epoch - 56ms/step\n",
            "Epoch 139/200\n",
            "50/50 - 3s - loss: 0.1616 - auc: 0.8905 - auc_1: 0.6194 - 3s/epoch - 56ms/step\n",
            "Epoch 140/200\n",
            "50/50 - 3s - loss: 0.1614 - auc: 0.8929 - auc_1: 0.6289 - 3s/epoch - 56ms/step\n",
            "Epoch 141/200\n",
            "50/50 - 3s - loss: 0.1613 - auc: 0.8944 - auc_1: 0.6297 - 3s/epoch - 56ms/step\n",
            "Epoch 142/200\n",
            "50/50 - 3s - loss: 0.1612 - auc: 0.8936 - auc_1: 0.6291 - 3s/epoch - 57ms/step\n",
            "Epoch 143/200\n",
            "50/50 - 3s - loss: 0.1610 - auc: 0.8936 - auc_1: 0.6295 - 3s/epoch - 56ms/step\n",
            "Epoch 144/200\n",
            "50/50 - 3s - loss: 0.1608 - auc: 0.8936 - auc_1: 0.6291 - 3s/epoch - 56ms/step\n",
            "Epoch 145/200\n",
            "50/50 - 3s - loss: 0.1607 - auc: 0.8921 - auc_1: 0.6284 - 3s/epoch - 56ms/step\n",
            "Epoch 146/200\n",
            "50/50 - 3s - loss: 0.1606 - auc: 0.8944 - auc_1: 0.6297 - 3s/epoch - 56ms/step\n",
            "Epoch 147/200\n",
            "50/50 - 3s - loss: 0.1604 - auc: 0.8929 - auc_1: 0.6289 - 3s/epoch - 56ms/step\n",
            "Epoch 148/200\n",
            "50/50 - 3s - loss: 0.1603 - auc: 0.8936 - auc_1: 0.6404 - 3s/epoch - 55ms/step\n",
            "Epoch 149/200\n",
            "50/50 - 3s - loss: 0.1602 - auc: 0.8952 - auc_1: 0.6415 - 3s/epoch - 56ms/step\n",
            "Epoch 150/200\n",
            "50/50 - 3s - loss: 0.1602 - auc: 0.8967 - auc_1: 0.6418 - 3s/epoch - 56ms/step\n",
            "Epoch 151/200\n",
            "50/50 - 3s - loss: 0.1599 - auc: 0.8967 - auc_1: 0.6418 - 3s/epoch - 56ms/step\n",
            "Epoch 152/200\n",
            "50/50 - 3s - loss: 0.1598 - auc: 0.8960 - auc_1: 0.6413 - 3s/epoch - 56ms/step\n",
            "Epoch 153/200\n",
            "50/50 - 3s - loss: 0.1597 - auc: 0.8975 - auc_1: 0.6424 - 3s/epoch - 56ms/step\n",
            "Epoch 154/200\n",
            "50/50 - 3s - loss: 0.1596 - auc: 0.8975 - auc_1: 0.6424 - 3s/epoch - 55ms/step\n",
            "Epoch 155/200\n",
            "50/50 - 3s - loss: 0.1593 - auc: 0.8967 - auc_1: 0.6418 - 3s/epoch - 56ms/step\n",
            "Epoch 156/200\n",
            "50/50 - 3s - loss: 0.1592 - auc: 0.8967 - auc_1: 0.6418 - 3s/epoch - 55ms/step\n",
            "Epoch 157/200\n",
            "50/50 - 3s - loss: 0.1591 - auc: 0.8967 - auc_1: 0.6418 - 3s/epoch - 56ms/step\n",
            "Epoch 158/200\n",
            "50/50 - 3s - loss: 0.1589 - auc: 0.8967 - auc_1: 0.6415 - 3s/epoch - 55ms/step\n",
            "Epoch 159/200\n",
            "50/50 - 3s - loss: 0.1590 - auc: 0.8983 - auc_1: 0.6426 - 3s/epoch - 56ms/step\n",
            "Epoch 160/200\n",
            "50/50 - 3s - loss: 0.1589 - auc: 0.8975 - auc_1: 0.6421 - 3s/epoch - 56ms/step\n",
            "Epoch 161/200\n",
            "50/50 - 3s - loss: 0.1586 - auc: 0.8967 - auc_1: 0.6415 - 3s/epoch - 56ms/step\n",
            "Epoch 162/200\n",
            "50/50 - 3s - loss: 0.1585 - auc: 0.8975 - auc_1: 0.6421 - 3s/epoch - 57ms/step\n",
            "Epoch 163/200\n",
            "50/50 - 3s - loss: 0.1584 - auc: 0.8975 - auc_1: 0.6417 - 3s/epoch - 56ms/step\n",
            "Epoch 164/200\n",
            "50/50 - 3s - loss: 0.1582 - auc: 0.8991 - auc_1: 0.6538 - 3s/epoch - 56ms/step\n",
            "Epoch 165/200\n",
            "50/50 - 3s - loss: 0.1582 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 166/200\n",
            "50/50 - 3s - loss: 0.1581 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 167/200\n",
            "50/50 - 3s - loss: 0.1577 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 56ms/step\n",
            "Epoch 168/200\n",
            "50/50 - 3s - loss: 0.1577 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 169/200\n",
            "50/50 - 3s - loss: 0.1577 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 170/200\n",
            "50/50 - 3s - loss: 0.1576 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 55ms/step\n",
            "Epoch 171/200\n",
            "50/50 - 3s - loss: 0.1573 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 56ms/step\n",
            "Epoch 172/200\n",
            "50/50 - 3s - loss: 0.1571 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 173/200\n",
            "50/50 - 3s - loss: 0.1570 - auc: 0.9006 - auc_1: 0.6546 - 3s/epoch - 57ms/step\n",
            "Epoch 174/200\n",
            "50/50 - 3s - loss: 0.1570 - auc: 0.9006 - auc_1: 0.6542 - 3s/epoch - 56ms/step\n",
            "Epoch 175/200\n",
            "50/50 - 3s - loss: 0.1569 - auc: 0.9014 - auc_1: 0.6548 - 3s/epoch - 57ms/step\n",
            "Epoch 176/200\n",
            "50/50 - 3s - loss: 0.1567 - auc: 0.9014 - auc_1: 0.6548 - 3s/epoch - 56ms/step\n",
            "Epoch 177/200\n",
            "50/50 - 3s - loss: 0.1566 - auc: 0.9014 - auc_1: 0.6548 - 3s/epoch - 56ms/step\n",
            "Epoch 178/200\n",
            "50/50 - 3s - loss: 0.1565 - auc: 0.9022 - auc_1: 0.6550 - 3s/epoch - 56ms/step\n",
            "Epoch 179/200\n",
            "50/50 - 3s - loss: 0.1564 - auc: 0.9022 - auc_1: 0.6550 - 3s/epoch - 56ms/step\n",
            "Epoch 180/200\n",
            "50/50 - 3s - loss: 0.1563 - auc: 0.9022 - auc_1: 0.6550 - 3s/epoch - 56ms/step\n",
            "Epoch 181/200\n",
            "50/50 - 3s - loss: 0.1561 - auc: 0.9022 - auc_1: 0.6550 - 3s/epoch - 57ms/step\n",
            "Epoch 182/200\n",
            "50/50 - 3s - loss: 0.1560 - auc: 0.9022 - auc_1: 0.6550 - 3s/epoch - 56ms/step\n",
            "Epoch 183/200\n",
            "50/50 - 3s - loss: 0.1558 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 58ms/step\n",
            "Epoch 184/200\n",
            "50/50 - 3s - loss: 0.1557 - auc: 0.9030 - auc_1: 0.6552 - 3s/epoch - 57ms/step\n",
            "Epoch 185/200\n",
            "50/50 - 3s - loss: 0.1557 - auc: 0.9030 - auc_1: 0.6552 - 3s/epoch - 56ms/step\n",
            "Epoch 186/200\n",
            "50/50 - 3s - loss: 0.1553 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 55ms/step\n",
            "Epoch 187/200\n",
            "50/50 - 3s - loss: 0.1553 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 55ms/step\n",
            "Epoch 188/200\n",
            "50/50 - 3s - loss: 0.1552 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 55ms/step\n",
            "Epoch 189/200\n",
            "50/50 - 3s - loss: 0.1551 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 56ms/step\n",
            "Epoch 190/200\n",
            "50/50 - 3s - loss: 0.1551 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 56ms/step\n",
            "Epoch 191/200\n",
            "50/50 - 3s - loss: 0.1549 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 56ms/step\n",
            "Epoch 192/200\n",
            "50/50 - 3s - loss: 0.1548 - auc: 0.9022 - auc_1: 0.6617 - 3s/epoch - 56ms/step\n",
            "Epoch 193/200\n",
            "50/50 - 3s - loss: 0.1546 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 56ms/step\n",
            "Epoch 194/200\n",
            "50/50 - 3s - loss: 0.1545 - auc: 0.9030 - auc_1: 0.6623 - 3s/epoch - 56ms/step\n",
            "Epoch 195/200\n",
            "50/50 - 3s - loss: 0.1544 - auc: 0.9037 - auc_1: 0.6624 - 3s/epoch - 56ms/step\n",
            "Epoch 196/200\n",
            "50/50 - 3s - loss: 0.1543 - auc: 0.9045 - auc_1: 0.6630 - 3s/epoch - 56ms/step\n",
            "Epoch 197/200\n",
            "50/50 - 3s - loss: 0.1542 - auc: 0.9045 - auc_1: 0.6630 - 3s/epoch - 56ms/step\n",
            "Epoch 198/200\n",
            "50/50 - 3s - loss: 0.1540 - auc: 0.9045 - auc_1: 0.6630 - 3s/epoch - 56ms/step\n",
            "Epoch 199/200\n",
            "50/50 - 3s - loss: 0.1539 - auc: 0.9030 - auc_1: 0.6623 - 3s/epoch - 56ms/step\n",
            "Epoch 200/200\n",
            "50/50 - 3s - loss: 0.1538 - auc: 0.9030 - auc_1: 0.6623 - 3s/epoch - 55ms/step\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 0.3599 - auc: 0.7045 - auc_1: 0.5165\n",
            "Epoch 1/200\n",
            "99/99 - 3s - loss: 0.7692 - mean_absolute_error: 0.5928 - 3s/epoch - 32ms/step\n",
            "Epoch 2/200\n",
            "99/99 - 3s - loss: 0.7802 - mean_absolute_error: 0.5982 - 3s/epoch - 32ms/step\n",
            "Epoch 3/200\n",
            "99/99 - 3s - loss: 0.7750 - mean_absolute_error: 0.5994 - 3s/epoch - 32ms/step\n",
            "Epoch 4/200\n",
            "99/99 - 3s - loss: 0.7676 - mean_absolute_error: 0.5853 - 3s/epoch - 32ms/step\n",
            "Epoch 5/200\n",
            "99/99 - 3s - loss: 0.7641 - mean_absolute_error: 0.5803 - 3s/epoch - 32ms/step\n",
            "Epoch 6/200\n",
            "99/99 - 3s - loss: 0.7634 - mean_absolute_error: 0.5779 - 3s/epoch - 32ms/step\n",
            "Epoch 7/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5741 - 3s/epoch - 32ms/step\n",
            "Epoch 8/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5733 - 3s/epoch - 32ms/step\n",
            "Epoch 9/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5735 - 3s/epoch - 32ms/step\n",
            "Epoch 10/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5731 - 3s/epoch - 32ms/step\n",
            "Epoch 11/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5731 - 3s/epoch - 32ms/step\n",
            "Epoch 12/200\n",
            "99/99 - 3s - loss: 0.7627 - mean_absolute_error: 0.5722 - 3s/epoch - 32ms/step\n",
            "Epoch 13/200\n",
            "99/99 - 3s - loss: 0.7627 - mean_absolute_error: 0.5725 - 3s/epoch - 32ms/step\n",
            "Epoch 14/200\n",
            "99/99 - 3s - loss: 0.7627 - mean_absolute_error: 0.5727 - 3s/epoch - 32ms/step\n",
            "Epoch 15/200\n",
            "99/99 - 3s - loss: 0.7627 - mean_absolute_error: 0.5726 - 3s/epoch - 32ms/step\n",
            "Epoch 16/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5729 - 3s/epoch - 32ms/step\n",
            "Epoch 17/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5740 - 3s/epoch - 32ms/step\n",
            "Epoch 18/200\n",
            "99/99 - 3s - loss: 0.7628 - mean_absolute_error: 0.5738 - 3s/epoch - 32ms/step\n",
            "Epoch 19/200\n",
            "99/99 - 3s - loss: 0.7629 - mean_absolute_error: 0.5750 - 3s/epoch - 31ms/step\n",
            "Epoch 20/200\n",
            "99/99 - 3s - loss: 0.7633 - mean_absolute_error: 0.5775 - 3s/epoch - 32ms/step\n",
            "Epoch 21/200\n",
            "99/99 - 3s - loss: 0.7654 - mean_absolute_error: 0.5834 - 3s/epoch - 32ms/step\n",
            "Epoch 22/200\n",
            "99/99 - 3s - loss: 0.7670 - mean_absolute_error: 0.5842 - 3s/epoch - 31ms/step\n",
            "Epoch 23/200\n",
            "99/99 - 3s - loss: 0.7648 - mean_absolute_error: 0.5827 - 3s/epoch - 32ms/step\n",
            "Epoch 24/200\n",
            "99/99 - 3s - loss: 0.7665 - mean_absolute_error: 0.5841 - 3s/epoch - 32ms/step\n",
            "Epoch 25/200\n",
            "99/99 - 3s - loss: 0.7673 - mean_absolute_error: 0.5857 - 3s/epoch - 32ms/step\n",
            "Epoch 26/200\n",
            "99/99 - 3s - loss: 0.7631 - mean_absolute_error: 0.5766 - 3s/epoch - 31ms/step\n",
            "Epoch 27/200\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "99/99 - 3s - loss: 0.7634 - mean_absolute_error: 0.5781 - 3s/epoch - 31ms/step\n",
            "Epoch 27: early stopping\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.9861 - mean_absolute_error: 0.7814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm-vae\n",
        "train_eval_pred_model(class_model, 2, readm_lstm_X_train, readm_lstm_X_test, readm_lstm_y_train, readm_lstm_y_test)\n",
        "train_eval_pred_model(class_model, 2, mortality_lstm_X_train, mortality_lstm_X_test, mortality_lstm_y_train, mortality_lstm_y_test)\n",
        "train_eval_pred_model(reg_model, 1, los_lstm_X_train, los_lstm_X_test, los_lstm_y_train, los_lstm_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD_HKuwdRD0j",
        "outputId": "f0de725b-2488-48f5-e627-2a44311ef6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 - 2s - loss: 1.0666 - auc: 0.8549 - auc_1: 0.7090 - 2s/epoch - 57ms/step\n",
            "Epoch 2/100\n",
            "31/31 - 2s - loss: 1.0266 - auc: 0.8689 - auc_1: 0.7076 - 2s/epoch - 57ms/step\n",
            "Epoch 3/100\n",
            "31/31 - 2s - loss: 0.9892 - auc: 0.8750 - auc_1: 0.7207 - 2s/epoch - 56ms/step\n",
            "Epoch 4/100\n",
            "31/31 - 2s - loss: 0.9550 - auc: 0.8713 - auc_1: 0.7090 - 2s/epoch - 56ms/step\n",
            "Epoch 5/100\n",
            "31/31 - 2s - loss: 0.9249 - auc: 0.8561 - auc_1: 0.6953 - 2s/epoch - 55ms/step\n",
            "Epoch 6/100\n",
            "31/31 - 2s - loss: 0.8960 - auc: 0.8457 - auc_1: 0.6711 - 2s/epoch - 56ms/step\n",
            "Epoch 7/100\n",
            "31/31 - 2s - loss: 0.8699 - auc: 0.8671 - auc_1: 0.6979 - 2s/epoch - 56ms/step\n",
            "Epoch 8/100\n",
            "31/31 - 2s - loss: 0.8459 - auc: 0.8689 - auc_1: 0.6931 - 2s/epoch - 56ms/step\n",
            "Epoch 9/100\n",
            "31/31 - 2s - loss: 0.8248 - auc: 0.8561 - auc_1: 0.6771 - 2s/epoch - 57ms/step\n",
            "Epoch 10/100\n",
            "31/31 - 2s - loss: 0.8046 - auc: 0.8463 - auc_1: 0.6623 - 2s/epoch - 56ms/step\n",
            "Epoch 11/100\n",
            "31/31 - 2s - loss: 0.7841 - auc: 0.8537 - auc_1: 0.6693 - 2s/epoch - 56ms/step\n",
            "Epoch 12/100\n",
            "31/31 - 2s - loss: 0.7672 - auc: 0.8500 - auc_1: 0.6667 - 2s/epoch - 56ms/step\n",
            "Epoch 13/100\n",
            "31/31 - 2s - loss: 0.7515 - auc: 0.8549 - auc_1: 0.6677 - 2s/epoch - 56ms/step\n",
            "Epoch 14/100\n",
            "31/31 - 2s - loss: 0.7345 - auc: 0.8518 - auc_1: 0.6673 - 2s/epoch - 56ms/step\n",
            "Epoch 15/100\n",
            "31/31 - 2s - loss: 0.7211 - auc: 0.8457 - auc_1: 0.6591 - 2s/epoch - 57ms/step\n",
            "Epoch 16/100\n",
            "31/31 - 2s - loss: 0.7069 - auc: 0.8689 - auc_1: 0.6772 - 2s/epoch - 56ms/step\n",
            "Epoch 17/100\n",
            "31/31 - 2s - loss: 0.6946 - auc: 0.8634 - auc_1: 0.6695 - 2s/epoch - 55ms/step\n",
            "Epoch 18/100\n",
            "31/31 - 2s - loss: 0.6824 - auc: 0.8610 - auc_1: 0.6636 - 2s/epoch - 55ms/step\n",
            "Epoch 19/100\n",
            "31/31 - 2s - loss: 0.6709 - auc: 0.8646 - auc_1: 0.6707 - 2s/epoch - 56ms/step\n",
            "Epoch 20/100\n",
            "31/31 - 2s - loss: 0.6603 - auc: 0.8622 - auc_1: 0.6648 - 2s/epoch - 56ms/step\n",
            "Epoch 21/100\n",
            "31/31 - 2s - loss: 0.6500 - auc: 0.8610 - auc_1: 0.6648 - 2s/epoch - 56ms/step\n",
            "Epoch 22/100\n",
            "31/31 - 2s - loss: 0.6411 - auc: 0.8585 - auc_1: 0.6635 - 2s/epoch - 56ms/step\n",
            "Epoch 23/100\n",
            "31/31 - 2s - loss: 0.6318 - auc: 0.8610 - auc_1: 0.6600 - 2s/epoch - 57ms/step\n",
            "Epoch 24/100\n",
            "31/31 - 2s - loss: 0.6231 - auc: 0.8628 - auc_1: 0.6627 - 2s/epoch - 56ms/step\n",
            "Epoch 25/100\n",
            "31/31 - 2s - loss: 0.6147 - auc: 0.8659 - auc_1: 0.6674 - 2s/epoch - 57ms/step\n",
            "Epoch 26/100\n",
            "31/31 - 2s - loss: 0.6080 - auc: 0.8616 - auc_1: 0.6602 - 2s/epoch - 56ms/step\n",
            "Epoch 27/100\n",
            "31/31 - 2s - loss: 0.5998 - auc: 0.8598 - auc_1: 0.6632 - 2s/epoch - 57ms/step\n",
            "Epoch 28/100\n",
            "31/31 - 2s - loss: 0.5930 - auc: 0.8585 - auc_1: 0.6513 - 2s/epoch - 56ms/step\n",
            "Epoch 29/100\n",
            "31/31 - 2s - loss: 0.5865 - auc: 0.8567 - auc_1: 0.6521 - 2s/epoch - 56ms/step\n",
            "Epoch 30/100\n",
            "31/31 - 2s - loss: 0.5798 - auc: 0.8585 - auc_1: 0.6558 - 2s/epoch - 55ms/step\n",
            "Epoch 31/100\n",
            "31/31 - 2s - loss: 0.5741 - auc: 0.8561 - auc_1: 0.6544 - 2s/epoch - 56ms/step\n",
            "Epoch 32/100\n",
            "31/31 - 2s - loss: 0.5683 - auc: 0.8610 - auc_1: 0.6589 - 2s/epoch - 56ms/step\n",
            "Epoch 33/100\n",
            "31/31 - 2s - loss: 0.5634 - auc: 0.8610 - auc_1: 0.6563 - 2s/epoch - 56ms/step\n",
            "Epoch 34/100\n",
            "31/31 - 2s - loss: 0.5581 - auc: 0.8616 - auc_1: 0.6577 - 2s/epoch - 55ms/step\n",
            "Epoch 35/100\n",
            "31/31 - 2s - loss: 0.5531 - auc: 0.8616 - auc_1: 0.6577 - 2s/epoch - 56ms/step\n",
            "Epoch 36/100\n",
            "31/31 - 2s - loss: 0.5484 - auc: 0.8591 - auc_1: 0.6564 - 2s/epoch - 55ms/step\n",
            "Epoch 37/100\n",
            "31/31 - 2s - loss: 0.5440 - auc: 0.8604 - auc_1: 0.6507 - 2s/epoch - 57ms/step\n",
            "Epoch 38/100\n",
            "31/31 - 2s - loss: 0.5394 - auc: 0.8598 - auc_1: 0.6529 - 2s/epoch - 56ms/step\n",
            "Epoch 39/100\n",
            "31/31 - 2s - loss: 0.5353 - auc: 0.8604 - auc_1: 0.6567 - 2s/epoch - 56ms/step\n",
            "Epoch 40/100\n",
            "31/31 - 2s - loss: 0.5310 - auc: 0.8616 - auc_1: 0.6560 - 2s/epoch - 56ms/step\n",
            "Epoch 41/100\n",
            "31/31 - 2s - loss: 0.5272 - auc: 0.8591 - auc_1: 0.6581 - 2s/epoch - 55ms/step\n",
            "Epoch 42/100\n",
            "31/31 - 2s - loss: 0.5237 - auc: 0.8628 - auc_1: 0.6628 - 2s/epoch - 56ms/step\n",
            "Epoch 43/100\n",
            "31/31 - 2s - loss: 0.5204 - auc: 0.8610 - auc_1: 0.6620 - 2s/epoch - 56ms/step\n",
            "Epoch 44/100\n",
            "31/31 - 2s - loss: 0.5170 - auc: 0.8610 - auc_1: 0.6594 - 2s/epoch - 58ms/step\n",
            "Epoch 45/100\n",
            "31/31 - 2s - loss: 0.5139 - auc: 0.8634 - auc_1: 0.6632 - 2s/epoch - 57ms/step\n",
            "Epoch 46/100\n",
            "31/31 - 2s - loss: 0.5104 - auc: 0.8604 - auc_1: 0.6507 - 2s/epoch - 56ms/step\n",
            "Epoch 47/100\n",
            "31/31 - 2s - loss: 0.5076 - auc: 0.8616 - auc_1: 0.6570 - 2s/epoch - 56ms/step\n",
            "Epoch 48/100\n",
            "31/31 - 2s - loss: 0.5048 - auc: 0.8604 - auc_1: 0.6571 - 2s/epoch - 56ms/step\n",
            "Epoch 49/100\n",
            "31/31 - 2s - loss: 0.5019 - auc: 0.8616 - auc_1: 0.6616 - 2s/epoch - 57ms/step\n",
            "Epoch 50/100\n",
            "31/31 - 2s - loss: 0.4995 - auc: 0.8665 - auc_1: 0.6679 - 2s/epoch - 57ms/step\n",
            "Epoch 51/100\n",
            "31/31 - 2s - loss: 0.4968 - auc: 0.8640 - auc_1: 0.6615 - 2s/epoch - 56ms/step\n",
            "Epoch 52/100\n",
            "31/31 - 2s - loss: 0.4945 - auc: 0.8604 - auc_1: 0.6563 - 2s/epoch - 56ms/step\n",
            "Epoch 53/100\n",
            "31/31 - 2s - loss: 0.4919 - auc: 0.8659 - auc_1: 0.6649 - 2s/epoch - 55ms/step\n",
            "Epoch 54/100\n",
            "31/31 - 2s - loss: 0.4892 - auc: 0.8652 - auc_1: 0.6711 - 2s/epoch - 56ms/step\n",
            "Epoch 55/100\n",
            "31/31 - 2s - loss: 0.4870 - auc: 0.8622 - auc_1: 0.6680 - 2s/epoch - 55ms/step\n",
            "Epoch 56/100\n",
            "31/31 - 2s - loss: 0.4847 - auc: 0.8634 - auc_1: 0.6706 - 2s/epoch - 55ms/step\n",
            "Epoch 57/100\n",
            "31/31 - 2s - loss: 0.4827 - auc: 0.8671 - auc_1: 0.6733 - 2s/epoch - 55ms/step\n",
            "Epoch 58/100\n",
            "31/31 - 2s - loss: 0.4809 - auc: 0.8646 - auc_1: 0.6693 - 2s/epoch - 56ms/step\n",
            "Epoch 59/100\n",
            "31/31 - 2s - loss: 0.4788 - auc: 0.8652 - auc_1: 0.6714 - 2s/epoch - 56ms/step\n",
            "Epoch 60/100\n",
            "31/31 - 2s - loss: 0.4772 - auc: 0.8683 - auc_1: 0.6783 - 2s/epoch - 56ms/step\n",
            "Epoch 61/100\n",
            "31/31 - 2s - loss: 0.4751 - auc: 0.8683 - auc_1: 0.6752 - 2s/epoch - 57ms/step\n",
            "Epoch 62/100\n",
            "31/31 - 2s - loss: 0.4732 - auc: 0.8683 - auc_1: 0.6752 - 2s/epoch - 57ms/step\n",
            "Epoch 63/100\n",
            "31/31 - 2s - loss: 0.4713 - auc: 0.8665 - auc_1: 0.6733 - 2s/epoch - 56ms/step\n",
            "Epoch 64/100\n",
            "31/31 - 2s - loss: 0.4697 - auc: 0.8652 - auc_1: 0.6708 - 2s/epoch - 56ms/step\n",
            "Epoch 65/100\n",
            "31/31 - 2s - loss: 0.4679 - auc: 0.8683 - auc_1: 0.6742 - 2s/epoch - 56ms/step\n",
            "Epoch 66/100\n",
            "31/31 - 2s - loss: 0.4663 - auc: 0.8671 - auc_1: 0.6735 - 2s/epoch - 57ms/step\n",
            "Epoch 67/100\n",
            "31/31 - 2s - loss: 0.4648 - auc: 0.8671 - auc_1: 0.6735 - 2s/epoch - 59ms/step\n",
            "Epoch 68/100\n",
            "31/31 - 2s - loss: 0.4631 - auc: 0.8689 - auc_1: 0.6776 - 2s/epoch - 58ms/step\n",
            "Epoch 69/100\n",
            "31/31 - 2s - loss: 0.4618 - auc: 0.8695 - auc_1: 0.6784 - 2s/epoch - 57ms/step\n",
            "Epoch 70/100\n",
            "31/31 - 2s - loss: 0.4602 - auc: 0.8683 - auc_1: 0.6772 - 2s/epoch - 56ms/step\n",
            "Epoch 71/100\n",
            "31/31 - 2s - loss: 0.4589 - auc: 0.8701 - auc_1: 0.6810 - 2s/epoch - 58ms/step\n",
            "Epoch 72/100\n",
            "31/31 - 2s - loss: 0.4575 - auc: 0.8701 - auc_1: 0.6810 - 2s/epoch - 57ms/step\n",
            "Epoch 73/100\n",
            "31/31 - 2s - loss: 0.4563 - auc: 0.8671 - auc_1: 0.6741 - 2s/epoch - 58ms/step\n",
            "Epoch 74/100\n",
            "31/31 - 2s - loss: 0.4551 - auc: 0.8659 - auc_1: 0.6660 - 2s/epoch - 57ms/step\n",
            "Epoch 75/100\n",
            "31/31 - 2s - loss: 0.4540 - auc: 0.8652 - auc_1: 0.6655 - 2s/epoch - 56ms/step\n",
            "Epoch 76/100\n",
            "31/31 - 2s - loss: 0.4526 - auc: 0.8665 - auc_1: 0.6704 - 2s/epoch - 56ms/step\n",
            "Epoch 77/100\n",
            "31/31 - 2s - loss: 0.4516 - auc: 0.8677 - auc_1: 0.6716 - 2s/epoch - 57ms/step\n",
            "Epoch 78/100\n",
            "31/31 - 2s - loss: 0.4503 - auc: 0.8677 - auc_1: 0.6716 - 2s/epoch - 55ms/step\n",
            "Epoch 79/100\n",
            "31/31 - 2s - loss: 0.4491 - auc: 0.8683 - auc_1: 0.6828 - 2s/epoch - 56ms/step\n",
            "Epoch 80/100\n",
            "31/31 - 2s - loss: 0.4479 - auc: 0.8732 - auc_1: 0.6929 - 2s/epoch - 57ms/step\n",
            "Epoch 81/100\n",
            "31/31 - 2s - loss: 0.4469 - auc: 0.8726 - auc_1: 0.6922 - 2s/epoch - 56ms/step\n",
            "Epoch 82/100\n",
            "31/31 - 2s - loss: 0.4459 - auc: 0.8756 - auc_1: 0.6971 - 2s/epoch - 57ms/step\n",
            "Epoch 83/100\n",
            "31/31 - 2s - loss: 0.4448 - auc: 0.8762 - auc_1: 0.6987 - 2s/epoch - 57ms/step\n",
            "Epoch 84/100\n",
            "31/31 - 2s - loss: 0.4436 - auc: 0.8768 - auc_1: 0.7004 - 2s/epoch - 56ms/step\n",
            "Epoch 85/100\n",
            "31/31 - 2s - loss: 0.4425 - auc: 0.8744 - auc_1: 0.6951 - 2s/epoch - 56ms/step\n",
            "Epoch 86/100\n",
            "31/31 - 2s - loss: 0.4418 - auc: 0.8720 - auc_1: 0.6920 - 2s/epoch - 55ms/step\n",
            "Epoch 87/100\n",
            "31/31 - 2s - loss: 0.4410 - auc: 0.8701 - auc_1: 0.6880 - 2s/epoch - 55ms/step\n",
            "Epoch 88/100\n",
            "31/31 - 2s - loss: 0.4399 - auc: 0.8720 - auc_1: 0.6912 - 2s/epoch - 56ms/step\n",
            "Epoch 89/100\n",
            "31/31 - 2s - loss: 0.4393 - auc: 0.8732 - auc_1: 0.6939 - 2s/epoch - 55ms/step\n",
            "Epoch 90/100\n",
            "31/31 - 2s - loss: 0.4384 - auc: 0.8732 - auc_1: 0.6939 - 2s/epoch - 55ms/step\n",
            "Epoch 91/100\n",
            "31/31 - 2s - loss: 0.4375 - auc: 0.8750 - auc_1: 0.6963 - 2s/epoch - 56ms/step\n",
            "Epoch 92/100\n",
            "31/31 - 2s - loss: 0.4368 - auc: 0.8744 - auc_1: 0.6958 - 2s/epoch - 58ms/step\n",
            "Epoch 93/100\n",
            "31/31 - 2s - loss: 0.4359 - auc: 0.8744 - auc_1: 0.6958 - 2s/epoch - 55ms/step\n",
            "Epoch 94/100\n",
            "31/31 - 2s - loss: 0.4352 - auc: 0.8750 - auc_1: 0.6964 - 2s/epoch - 58ms/step\n",
            "Epoch 95/100\n",
            "31/31 - 2s - loss: 0.4345 - auc: 0.8762 - auc_1: 0.6985 - 2s/epoch - 57ms/step\n",
            "Epoch 96/100\n",
            "31/31 - 2s - loss: 0.4336 - auc: 0.8732 - auc_1: 0.6920 - 2s/epoch - 57ms/step\n",
            "Epoch 97/100\n",
            "31/31 - 2s - loss: 0.4329 - auc: 0.8768 - auc_1: 0.6975 - 2s/epoch - 55ms/step\n",
            "Epoch 98/100\n",
            "31/31 - 2s - loss: 0.4322 - auc: 0.8768 - auc_1: 0.6975 - 2s/epoch - 53ms/step\n",
            "Epoch 99/100\n",
            "31/31 - 2s - loss: 0.4315 - auc: 0.8793 - auc_1: 0.7104 - 2s/epoch - 55ms/step\n",
            "Epoch 100/100\n",
            "31/31 - 2s - loss: 0.4307 - auc: 0.8780 - auc_1: 0.6925 - 2s/epoch - 55ms/step\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6368 - auc: 0.5741 - auc_1: 0.3413\n",
            "Epoch 1/100\n",
            "50/50 - 3s - loss: 0.3312 - auc: 0.9410 - auc_1: 0.5782 - 3s/epoch - 57ms/step\n",
            "Epoch 2/100\n",
            "50/50 - 3s - loss: 0.3245 - auc: 0.9394 - auc_1: 0.5775 - 3s/epoch - 56ms/step\n",
            "Epoch 3/100\n",
            "50/50 - 3s - loss: 0.3176 - auc: 0.9387 - auc_1: 0.5499 - 3s/epoch - 56ms/step\n",
            "Epoch 4/100\n",
            "50/50 - 3s - loss: 0.3106 - auc: 0.9371 - auc_1: 0.5492 - 3s/epoch - 57ms/step\n",
            "Epoch 5/100\n",
            "50/50 - 3s - loss: 0.3035 - auc: 0.9340 - auc_1: 0.5480 - 3s/epoch - 58ms/step\n",
            "Epoch 6/100\n",
            "50/50 - 3s - loss: 0.2964 - auc: 0.9356 - auc_1: 0.5486 - 3s/epoch - 57ms/step\n",
            "Epoch 7/100\n",
            "50/50 - 3s - loss: 0.2894 - auc: 0.9340 - auc_1: 0.5480 - 3s/epoch - 57ms/step\n",
            "Epoch 8/100\n",
            "50/50 - 3s - loss: 0.2825 - auc: 0.9356 - auc_1: 0.5486 - 3s/epoch - 58ms/step\n",
            "Epoch 9/100\n",
            "50/50 - 3s - loss: 0.2756 - auc: 0.9317 - auc_1: 0.5472 - 3s/epoch - 57ms/step\n",
            "Epoch 10/100\n",
            "50/50 - 3s - loss: 0.2689 - auc: 0.9293 - auc_1: 0.5464 - 3s/epoch - 58ms/step\n",
            "Epoch 11/100\n",
            "50/50 - 3s - loss: 0.2621 - auc: 0.9286 - auc_1: 0.5462 - 3s/epoch - 58ms/step\n",
            "Epoch 12/100\n",
            "50/50 - 3s - loss: 0.2555 - auc: 0.9293 - auc_1: 0.5464 - 3s/epoch - 56ms/step\n",
            "Epoch 13/100\n",
            "50/50 - 3s - loss: 0.2491 - auc: 0.9293 - auc_1: 0.5464 - 3s/epoch - 57ms/step\n",
            "Epoch 14/100\n",
            "50/50 - 3s - loss: 0.2429 - auc: 0.9270 - auc_1: 0.5457 - 3s/epoch - 58ms/step\n",
            "Epoch 15/100\n",
            "50/50 - 3s - loss: 0.2368 - auc: 0.9278 - auc_1: 0.5459 - 3s/epoch - 59ms/step\n",
            "Epoch 16/100\n",
            "50/50 - 3s - loss: 0.2312 - auc: 0.9262 - auc_1: 0.5454 - 3s/epoch - 59ms/step\n",
            "Epoch 17/100\n",
            "50/50 - 3s - loss: 0.2255 - auc: 0.9278 - auc_1: 0.5459 - 3s/epoch - 58ms/step\n",
            "Epoch 18/100\n",
            "50/50 - 3s - loss: 0.2201 - auc: 0.9255 - auc_1: 0.5452 - 3s/epoch - 58ms/step\n",
            "Epoch 19/100\n",
            "50/50 - 3s - loss: 0.2151 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 58ms/step\n",
            "Epoch 20/100\n",
            "50/50 - 3s - loss: 0.2099 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 58ms/step\n",
            "Epoch 21/100\n",
            "50/50 - 3s - loss: 0.2052 - auc: 0.9262 - auc_1: 0.5454 - 3s/epoch - 57ms/step\n",
            "Epoch 22/100\n",
            "50/50 - 3s - loss: 0.2007 - auc: 0.9231 - auc_1: 0.5446 - 3s/epoch - 60ms/step\n",
            "Epoch 23/100\n",
            "50/50 - 3s - loss: 0.1965 - auc: 0.9247 - auc_1: 0.5450 - 3s/epoch - 58ms/step\n",
            "Epoch 24/100\n",
            "50/50 - 3s - loss: 0.1926 - auc: 0.9255 - auc_1: 0.5452 - 3s/epoch - 58ms/step\n",
            "Epoch 25/100\n",
            "50/50 - 3s - loss: 0.1889 - auc: 0.9224 - auc_1: 0.5444 - 3s/epoch - 58ms/step\n",
            "Epoch 26/100\n",
            "50/50 - 3s - loss: 0.1853 - auc: 0.9231 - auc_1: 0.5446 - 3s/epoch - 57ms/step\n",
            "Epoch 27/100\n",
            "50/50 - 3s - loss: 0.1821 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 57ms/step\n",
            "Epoch 28/100\n",
            "50/50 - 3s - loss: 0.1790 - auc: 0.9255 - auc_1: 0.5452 - 3s/epoch - 57ms/step\n",
            "Epoch 29/100\n",
            "50/50 - 3s - loss: 0.1761 - auc: 0.9200 - auc_1: 0.5438 - 3s/epoch - 59ms/step\n",
            "Epoch 30/100\n",
            "50/50 - 3s - loss: 0.1735 - auc: 0.9200 - auc_1: 0.5438 - 3s/epoch - 60ms/step\n",
            "Epoch 31/100\n",
            "50/50 - 3s - loss: 0.1708 - auc: 0.9208 - auc_1: 0.5440 - 3s/epoch - 58ms/step\n",
            "Epoch 32/100\n",
            "50/50 - 3s - loss: 0.1686 - auc: 0.9216 - auc_1: 0.5442 - 3s/epoch - 57ms/step\n",
            "Epoch 33/100\n",
            "50/50 - 3s - loss: 0.1663 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 58ms/step\n",
            "Epoch 34/100\n",
            "50/50 - 3s - loss: 0.1643 - auc: 0.9255 - auc_1: 0.5452 - 3s/epoch - 58ms/step\n",
            "Epoch 35/100\n",
            "50/50 - 3s - loss: 0.1624 - auc: 0.9278 - auc_1: 0.5459 - 3s/epoch - 56ms/step\n",
            "Epoch 36/100\n",
            "50/50 - 3s - loss: 0.1606 - auc: 0.9154 - auc_1: 0.5427 - 3s/epoch - 56ms/step\n",
            "Epoch 37/100\n",
            "50/50 - 3s - loss: 0.1591 - auc: 0.9169 - auc_1: 0.5431 - 3s/epoch - 57ms/step\n",
            "Epoch 38/100\n",
            "50/50 - 3s - loss: 0.1576 - auc: 0.9169 - auc_1: 0.5431 - 3s/epoch - 57ms/step\n",
            "Epoch 39/100\n",
            "50/50 - 3s - loss: 0.1561 - auc: 0.9177 - auc_1: 0.5432 - 3s/epoch - 57ms/step\n",
            "Epoch 40/100\n",
            "50/50 - 3s - loss: 0.1546 - auc: 0.9193 - auc_1: 0.5436 - 3s/epoch - 58ms/step\n",
            "Epoch 41/100\n",
            "50/50 - 3s - loss: 0.1533 - auc: 0.9193 - auc_1: 0.5436 - 3s/epoch - 58ms/step\n",
            "Epoch 42/100\n",
            "50/50 - 3s - loss: 0.1521 - auc: 0.9193 - auc_1: 0.5436 - 3s/epoch - 59ms/step\n",
            "Epoch 43/100\n",
            "50/50 - 3s - loss: 0.1509 - auc: 0.9200 - auc_1: 0.5438 - 3s/epoch - 58ms/step\n",
            "Epoch 44/100\n",
            "50/50 - 3s - loss: 0.1499 - auc: 0.9224 - auc_1: 0.5444 - 3s/epoch - 59ms/step\n",
            "Epoch 45/100\n",
            "50/50 - 3s - loss: 0.1489 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 58ms/step\n",
            "Epoch 46/100\n",
            "50/50 - 3s - loss: 0.1479 - auc: 0.9239 - auc_1: 0.5448 - 3s/epoch - 59ms/step\n",
            "Epoch 47/100\n",
            "50/50 - 3s - loss: 0.1470 - auc: 0.9278 - auc_1: 0.5459 - 3s/epoch - 57ms/step\n",
            "Epoch 48/100\n",
            "50/50 - 3s - loss: 0.1461 - auc: 0.9286 - auc_1: 0.5462 - 3s/epoch - 59ms/step\n",
            "Epoch 49/100\n",
            "50/50 - 3s - loss: 0.1452 - auc: 0.9309 - auc_1: 0.5470 - 3s/epoch - 58ms/step\n",
            "Epoch 50/100\n",
            "50/50 - 3s - loss: 0.1444 - auc: 0.9317 - auc_1: 0.5473 - 3s/epoch - 59ms/step\n",
            "Epoch 51/100\n",
            "50/50 - 3s - loss: 0.1436 - auc: 0.9332 - auc_1: 0.5478 - 3s/epoch - 60ms/step\n",
            "Epoch 52/100\n",
            "50/50 - 3s - loss: 0.1429 - auc: 0.9030 - auc_1: 0.5405 - 3s/epoch - 57ms/step\n",
            "Epoch 53/100\n",
            "50/50 - 3s - loss: 0.1423 - auc: 0.9037 - auc_1: 0.5406 - 3s/epoch - 58ms/step\n",
            "Epoch 54/100\n",
            "50/50 - 3s - loss: 0.1416 - auc: 0.9037 - auc_1: 0.5406 - 3s/epoch - 60ms/step\n",
            "Epoch 55/100\n",
            "50/50 - 3s - loss: 0.1410 - auc: 0.9045 - auc_1: 0.5407 - 3s/epoch - 57ms/step\n",
            "Epoch 56/100\n",
            "50/50 - 3s - loss: 0.1403 - auc: 0.9045 - auc_1: 0.5407 - 3s/epoch - 57ms/step\n",
            "Epoch 57/100\n",
            "50/50 - 3s - loss: 0.1397 - auc: 0.9053 - auc_1: 0.5408 - 3s/epoch - 59ms/step\n",
            "Epoch 58/100\n",
            "50/50 - 3s - loss: 0.1392 - auc: 0.9053 - auc_1: 0.5408 - 3s/epoch - 59ms/step\n",
            "Epoch 59/100\n",
            "50/50 - 3s - loss: 0.1385 - auc: 0.9061 - auc_1: 0.5410 - 3s/epoch - 56ms/step\n",
            "Epoch 60/100\n",
            "50/50 - 3s - loss: 0.1380 - auc: 0.9061 - auc_1: 0.5410 - 3s/epoch - 55ms/step\n",
            "Epoch 61/100\n",
            "50/50 - 3s - loss: 0.1376 - auc: 0.9068 - auc_1: 0.5412 - 3s/epoch - 56ms/step\n",
            "Epoch 62/100\n",
            "50/50 - 3s - loss: 0.1371 - auc: 0.9068 - auc_1: 0.5412 - 3s/epoch - 56ms/step\n",
            "Epoch 63/100\n",
            "50/50 - 3s - loss: 0.1365 - auc: 0.9076 - auc_1: 0.5413 - 3s/epoch - 58ms/step\n",
            "Epoch 64/100\n",
            "50/50 - 3s - loss: 0.1360 - auc: 0.9092 - auc_1: 0.5417 - 3s/epoch - 57ms/step\n",
            "Epoch 65/100\n",
            "50/50 - 3s - loss: 0.1356 - auc: 0.9092 - auc_1: 0.5417 - 3s/epoch - 56ms/step\n",
            "Epoch 66/100\n",
            "50/50 - 3s - loss: 0.1352 - auc: 0.9107 - auc_1: 0.5420 - 3s/epoch - 60ms/step\n",
            "Epoch 67/100\n",
            "50/50 - 3s - loss: 0.1348 - auc: 0.9107 - auc_1: 0.5420 - 3s/epoch - 57ms/step\n",
            "Epoch 68/100\n",
            "50/50 - 3s - loss: 0.1344 - auc: 0.9107 - auc_1: 0.5420 - 3s/epoch - 55ms/step\n",
            "Epoch 69/100\n",
            "50/50 - 3s - loss: 0.1340 - auc: 0.9115 - auc_1: 0.5422 - 3s/epoch - 56ms/step\n",
            "Epoch 70/100\n",
            "50/50 - 3s - loss: 0.1336 - auc: 0.9115 - auc_1: 0.5422 - 3s/epoch - 57ms/step\n",
            "Epoch 71/100\n",
            "50/50 - 3s - loss: 0.1333 - auc: 0.9115 - auc_1: 0.5422 - 3s/epoch - 55ms/step\n",
            "Epoch 72/100\n",
            "50/50 - 3s - loss: 0.1328 - auc: 0.9123 - auc_1: 0.5423 - 3s/epoch - 54ms/step\n",
            "Epoch 73/100\n",
            "50/50 - 3s - loss: 0.1324 - auc: 0.9123 - auc_1: 0.5423 - 3s/epoch - 55ms/step\n",
            "Epoch 74/100\n",
            "50/50 - 3s - loss: 0.1322 - auc: 0.9123 - auc_1: 0.5423 - 3s/epoch - 57ms/step\n",
            "Epoch 75/100\n",
            "50/50 - 3s - loss: 0.1318 - auc: 0.9123 - auc_1: 0.5423 - 3s/epoch - 58ms/step\n",
            "Epoch 76/100\n",
            "50/50 - 3s - loss: 0.1316 - auc: 0.9138 - auc_1: 0.5426 - 3s/epoch - 57ms/step\n",
            "Epoch 77/100\n",
            "50/50 - 3s - loss: 0.1311 - auc: 0.9138 - auc_1: 0.5426 - 3s/epoch - 56ms/step\n",
            "Epoch 78/100\n",
            "50/50 - 3s - loss: 0.1308 - auc: 0.9138 - auc_1: 0.5426 - 3s/epoch - 56ms/step\n",
            "Epoch 79/100\n",
            "50/50 - 3s - loss: 0.1305 - auc: 0.9138 - auc_1: 0.5426 - 3s/epoch - 59ms/step\n",
            "Epoch 80/100\n",
            "50/50 - 3s - loss: 0.1303 - auc: 0.9146 - auc_1: 0.5428 - 3s/epoch - 58ms/step\n",
            "Epoch 81/100\n",
            "50/50 - 3s - loss: 0.1299 - auc: 0.9154 - auc_1: 0.5431 - 3s/epoch - 56ms/step\n",
            "Epoch 82/100\n",
            "50/50 - 3s - loss: 0.1296 - auc: 0.9161 - auc_1: 0.5432 - 3s/epoch - 57ms/step\n",
            "Epoch 83/100\n",
            "50/50 - 3s - loss: 0.1294 - auc: 0.9161 - auc_1: 0.5432 - 3s/epoch - 57ms/step\n",
            "Epoch 84/100\n",
            "50/50 - 3s - loss: 0.1291 - auc: 0.9177 - auc_1: 0.5437 - 3s/epoch - 57ms/step\n",
            "Epoch 85/100\n",
            "50/50 - 3s - loss: 0.1287 - auc: 0.9161 - auc_1: 0.5432 - 3s/epoch - 58ms/step\n",
            "Epoch 86/100\n",
            "50/50 - 3s - loss: 0.1285 - auc: 0.9161 - auc_1: 0.5432 - 3s/epoch - 58ms/step\n",
            "Epoch 87/100\n",
            "50/50 - 3s - loss: 0.1283 - auc: 0.9161 - auc_1: 0.5432 - 3s/epoch - 59ms/step\n",
            "Epoch 88/100\n",
            "50/50 - 3s - loss: 0.1282 - auc: 0.9169 - auc_1: 0.5434 - 3s/epoch - 59ms/step\n",
            "Epoch 89/100\n",
            "50/50 - 3s - loss: 0.1278 - auc: 0.9177 - auc_1: 0.5437 - 3s/epoch - 59ms/step\n",
            "Epoch 90/100\n",
            "50/50 - 3s - loss: 0.1277 - auc: 0.9169 - auc_1: 0.5434 - 3s/epoch - 61ms/step\n",
            "Epoch 91/100\n",
            "50/50 - 3s - loss: 0.1273 - auc: 0.9177 - auc_1: 0.5437 - 3s/epoch - 58ms/step\n",
            "Epoch 92/100\n",
            "50/50 - 3s - loss: 0.1271 - auc: 0.9185 - auc_1: 0.5439 - 3s/epoch - 58ms/step\n",
            "Epoch 93/100\n",
            "50/50 - 3s - loss: 0.1269 - auc: 0.9193 - auc_1: 0.5441 - 3s/epoch - 58ms/step\n",
            "Epoch 94/100\n",
            "50/50 - 3s - loss: 0.1267 - auc: 0.9193 - auc_1: 0.5441 - 3s/epoch - 57ms/step\n",
            "Epoch 95/100\n",
            "50/50 - 3s - loss: 0.1265 - auc: 0.9193 - auc_1: 0.5441 - 3s/epoch - 56ms/step\n",
            "Epoch 96/100\n",
            "50/50 - 3s - loss: 0.1262 - auc: 0.9193 - auc_1: 0.5441 - 3s/epoch - 58ms/step\n",
            "Epoch 97/100\n",
            "50/50 - 3s - loss: 0.1260 - auc: 0.9193 - auc_1: 0.5441 - 3s/epoch - 56ms/step\n",
            "Epoch 98/100\n",
            "50/50 - 3s - loss: 0.1258 - auc: 0.9200 - auc_1: 0.5443 - 3s/epoch - 56ms/step\n",
            "Epoch 99/100\n",
            "50/50 - 3s - loss: 0.1257 - auc: 0.9200 - auc_1: 0.5443 - 3s/epoch - 59ms/step\n",
            "Epoch 100/100\n",
            "50/50 - 3s - loss: 0.1255 - auc: 0.9208 - auc_1: 0.5445 - 3s/epoch - 58ms/step\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.5159 - auc: 0.4848 - auc_1: 0.4021\n",
            "Epoch 1/100\n",
            "99/99 - 3s - loss: 0.8070 - mean_absolute_error: 0.5990 - 3s/epoch - 33ms/step\n",
            "Epoch 2/100\n",
            "99/99 - 3s - loss: 0.8063 - mean_absolute_error: 0.5958 - 3s/epoch - 32ms/step\n",
            "Epoch 3/100\n",
            "99/99 - 3s - loss: 0.8062 - mean_absolute_error: 0.5949 - 3s/epoch - 33ms/step\n",
            "Epoch 4/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5946 - 3s/epoch - 33ms/step\n",
            "Epoch 5/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5945 - 3s/epoch - 33ms/step\n",
            "Epoch 6/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5948 - 3s/epoch - 33ms/step\n",
            "Epoch 7/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5937 - 3s/epoch - 34ms/step\n",
            "Epoch 8/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5941 - 3s/epoch - 34ms/step\n",
            "Epoch 9/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5937 - 3s/epoch - 33ms/step\n",
            "Epoch 10/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5943 - 3s/epoch - 32ms/step\n",
            "Epoch 11/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5936 - 3s/epoch - 33ms/step\n",
            "Epoch 12/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5941 - 3s/epoch - 34ms/step\n",
            "Epoch 13/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5936 - 3s/epoch - 34ms/step\n",
            "Epoch 14/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5940 - 3s/epoch - 33ms/step\n",
            "Epoch 15/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5949 - 3s/epoch - 32ms/step\n",
            "Epoch 16/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5946 - 3s/epoch - 32ms/step\n",
            "Epoch 17/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5940 - 3s/epoch - 32ms/step\n",
            "Epoch 18/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5942 - 3s/epoch - 33ms/step\n",
            "Epoch 19/100\n",
            "99/99 - 3s - loss: 0.8061 - mean_absolute_error: 0.5944 - 3s/epoch - 33ms/step\n",
            "Epoch 20/100\n",
            "99/99 - 3s - loss: 0.8060 - mean_absolute_error: 0.5941 - 3s/epoch - 32ms/step\n",
            "Epoch 21/100\n",
            "99/99 - 3s - loss: 0.8062 - mean_absolute_error: 0.5954 - 3s/epoch - 32ms/step\n",
            "Epoch 22/100\n",
            "99/99 - 3s - loss: 0.8071 - mean_absolute_error: 0.5990 - 3s/epoch - 32ms/step\n",
            "Epoch 23/100\n",
            "99/99 - 3s - loss: 0.8075 - mean_absolute_error: 0.6001 - 3s/epoch - 34ms/step\n",
            "Epoch 24/100\n",
            "99/99 - 3s - loss: 0.8109 - mean_absolute_error: 0.6099 - 3s/epoch - 33ms/step\n",
            "Epoch 25/100\n",
            "99/99 - 3s - loss: 0.8095 - mean_absolute_error: 0.6047 - 3s/epoch - 33ms/step\n",
            "Epoch 26/100\n",
            "99/99 - 3s - loss: 0.8079 - mean_absolute_error: 0.6018 - 3s/epoch - 32ms/step\n",
            "Epoch 27/100\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "99/99 - 3s - loss: 0.8065 - mean_absolute_error: 0.5969 - 3s/epoch - 31ms/step\n",
            "Epoch 27: early stopping\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 1.0003 - mean_absolute_error: 0.8100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn-lstm-vae\n",
        "train_eval_pred_model(class_model, 2, readm_cnn_lstm_X_train, readm_cnn_lstm_X_test, readm_cnn_lstm_y_train, readm_cnn_lstm_y_test)\n",
        "train_eval_pred_model(class_model, 2, mortality_cnn_lstm_X_train, mortality_cnn_lstm_X_test, mortality_cnn_lstm_y_train, mortality_cnn_lstm_y_test)\n",
        "train_eval_pred_model(reg_model, 1, los_cnn_lstm_X_train, los_cnn_lstm_X_test, los_cnn_lstm_y_train, los_cnn_lstm_y_test )"
      ],
      "metadata": {
        "id": "u_nmHYOzRLoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0846e01a-4345-471b-bd45-90c8e75a8429"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 - 2s - loss: 0.5653 - auc: 0.7915 - auc_1: 0.6996 - 2s/epoch - 57ms/step\n",
            "Epoch 2/100\n",
            "31/31 - 2s - loss: 0.5625 - auc: 0.7976 - auc_1: 0.7017 - 2s/epoch - 57ms/step\n",
            "Epoch 3/100\n",
            "31/31 - 2s - loss: 0.5602 - auc: 0.7951 - auc_1: 0.6982 - 2s/epoch - 59ms/step\n",
            "Epoch 4/100\n",
            "31/31 - 2s - loss: 0.5582 - auc: 0.7957 - auc_1: 0.6881 - 2s/epoch - 56ms/step\n",
            "Epoch 5/100\n",
            "31/31 - 2s - loss: 0.5562 - auc: 0.7945 - auc_1: 0.6912 - 2s/epoch - 57ms/step\n",
            "Epoch 6/100\n",
            "31/31 - 2s - loss: 0.5542 - auc: 0.7957 - auc_1: 0.6995 - 2s/epoch - 56ms/step\n",
            "Epoch 7/100\n",
            "31/31 - 2s - loss: 0.5523 - auc: 0.7963 - auc_1: 0.6990 - 2s/epoch - 56ms/step\n",
            "Epoch 8/100\n",
            "31/31 - 2s - loss: 0.5507 - auc: 0.7982 - auc_1: 0.7018 - 2s/epoch - 57ms/step\n",
            "Epoch 9/100\n",
            "31/31 - 2s - loss: 0.5494 - auc: 0.7963 - auc_1: 0.7001 - 2s/epoch - 56ms/step\n",
            "Epoch 10/100\n",
            "31/31 - 2s - loss: 0.5480 - auc: 0.7933 - auc_1: 0.6981 - 2s/epoch - 57ms/step\n",
            "Epoch 11/100\n",
            "31/31 - 2s - loss: 0.5465 - auc: 0.7915 - auc_1: 0.6913 - 2s/epoch - 57ms/step\n",
            "Epoch 12/100\n",
            "31/31 - 2s - loss: 0.5453 - auc: 0.7909 - auc_1: 0.6895 - 2s/epoch - 56ms/step\n",
            "Epoch 13/100\n",
            "31/31 - 2s - loss: 0.5441 - auc: 0.7927 - auc_1: 0.6836 - 2s/epoch - 56ms/step\n",
            "Epoch 14/100\n",
            "31/31 - 2s - loss: 0.5426 - auc: 0.7927 - auc_1: 0.6836 - 2s/epoch - 56ms/step\n",
            "Epoch 15/100\n",
            "31/31 - 2s - loss: 0.5417 - auc: 0.7927 - auc_1: 0.6862 - 2s/epoch - 57ms/step\n",
            "Epoch 16/100\n",
            "31/31 - 2s - loss: 0.5404 - auc: 0.7909 - auc_1: 0.6835 - 2s/epoch - 58ms/step\n",
            "Epoch 17/100\n",
            "31/31 - 2s - loss: 0.5397 - auc: 0.7902 - auc_1: 0.6850 - 2s/epoch - 57ms/step\n",
            "Epoch 18/100\n",
            "31/31 - 2s - loss: 0.5383 - auc: 0.7945 - auc_1: 0.6970 - 2s/epoch - 57ms/step\n",
            "Epoch 19/100\n",
            "31/31 - 2s - loss: 0.5374 - auc: 0.7945 - auc_1: 0.6970 - 2s/epoch - 57ms/step\n",
            "Epoch 20/100\n",
            "31/31 - 2s - loss: 0.5363 - auc: 0.7957 - auc_1: 0.7002 - 2s/epoch - 56ms/step\n",
            "Epoch 21/100\n",
            "31/31 - 2s - loss: 0.5355 - auc: 0.7957 - auc_1: 0.7002 - 2s/epoch - 56ms/step\n",
            "Epoch 22/100\n",
            "31/31 - 2s - loss: 0.5347 - auc: 0.7957 - auc_1: 0.7002 - 2s/epoch - 56ms/step\n",
            "Epoch 23/100\n",
            "31/31 - 2s - loss: 0.5338 - auc: 0.7933 - auc_1: 0.6983 - 2s/epoch - 56ms/step\n",
            "Epoch 24/100\n",
            "31/31 - 2s - loss: 0.5329 - auc: 0.7933 - auc_1: 0.6983 - 2s/epoch - 58ms/step\n",
            "Epoch 25/100\n",
            "31/31 - 2s - loss: 0.5321 - auc: 0.7939 - auc_1: 0.6979 - 2s/epoch - 57ms/step\n",
            "Epoch 26/100\n",
            "31/31 - 2s - loss: 0.5316 - auc: 0.7951 - auc_1: 0.6988 - 2s/epoch - 57ms/step\n",
            "Epoch 27/100\n",
            "31/31 - 2s - loss: 0.5307 - auc: 0.7951 - auc_1: 0.6975 - 2s/epoch - 57ms/step\n",
            "Epoch 28/100\n",
            "31/31 - 2s - loss: 0.5298 - auc: 0.7951 - auc_1: 0.7004 - 2s/epoch - 56ms/step\n",
            "Epoch 29/100\n",
            "31/31 - 2s - loss: 0.5292 - auc: 0.7945 - auc_1: 0.7002 - 2s/epoch - 56ms/step\n",
            "Epoch 30/100\n",
            "31/31 - 2s - loss: 0.5283 - auc: 0.7945 - auc_1: 0.6967 - 2s/epoch - 56ms/step\n",
            "Epoch 31/100\n",
            "31/31 - 2s - loss: 0.5276 - auc: 0.7970 - auc_1: 0.7021 - 2s/epoch - 56ms/step\n",
            "Epoch 32/100\n",
            "31/31 - 2s - loss: 0.5270 - auc: 0.7957 - auc_1: 0.7012 - 2s/epoch - 57ms/step\n",
            "Epoch 33/100\n",
            "31/31 - 2s - loss: 0.5262 - auc: 0.7939 - auc_1: 0.6961 - 2s/epoch - 56ms/step\n",
            "Epoch 34/100\n",
            "31/31 - 2s - loss: 0.5256 - auc: 0.7939 - auc_1: 0.6961 - 2s/epoch - 55ms/step\n",
            "Epoch 35/100\n",
            "31/31 - 2s - loss: 0.5253 - auc: 0.7945 - auc_1: 0.6911 - 2s/epoch - 57ms/step\n",
            "Epoch 36/100\n",
            "31/31 - 2s - loss: 0.5242 - auc: 0.7939 - auc_1: 0.6884 - 2s/epoch - 57ms/step\n",
            "Epoch 37/100\n",
            "31/31 - 2s - loss: 0.5237 - auc: 0.7951 - auc_1: 0.6895 - 2s/epoch - 57ms/step\n",
            "Epoch 38/100\n",
            "31/31 - 2s - loss: 0.5230 - auc: 0.7951 - auc_1: 0.6895 - 2s/epoch - 61ms/step\n",
            "Epoch 39/100\n",
            "31/31 - 2s - loss: 0.5224 - auc: 0.7933 - auc_1: 0.6880 - 2s/epoch - 57ms/step\n",
            "Epoch 40/100\n",
            "31/31 - 2s - loss: 0.5216 - auc: 0.7933 - auc_1: 0.6880 - 2s/epoch - 57ms/step\n",
            "Epoch 41/100\n",
            "31/31 - 2s - loss: 0.5210 - auc: 0.7970 - auc_1: 0.6890 - 2s/epoch - 56ms/step\n",
            "Epoch 42/100\n",
            "31/31 - 2s - loss: 0.5206 - auc: 0.7970 - auc_1: 0.6890 - 2s/epoch - 56ms/step\n",
            "Epoch 43/100\n",
            "31/31 - 2s - loss: 0.5201 - auc: 0.7970 - auc_1: 0.6890 - 2s/epoch - 58ms/step\n",
            "Epoch 44/100\n",
            "31/31 - 2s - loss: 0.5193 - auc: 0.7970 - auc_1: 0.6890 - 2s/epoch - 58ms/step\n",
            "Epoch 45/100\n",
            "31/31 - 2s - loss: 0.5188 - auc: 0.7963 - auc_1: 0.6888 - 2s/epoch - 57ms/step\n",
            "Epoch 46/100\n",
            "31/31 - 2s - loss: 0.5181 - auc: 0.7963 - auc_1: 0.6888 - 2s/epoch - 58ms/step\n",
            "Epoch 47/100\n",
            "31/31 - 2s - loss: 0.5177 - auc: 0.7939 - auc_1: 0.6857 - 2s/epoch - 57ms/step\n",
            "Epoch 48/100\n",
            "31/31 - 2s - loss: 0.5171 - auc: 0.7951 - auc_1: 0.6878 - 2s/epoch - 58ms/step\n",
            "Epoch 49/100\n",
            "31/31 - 2s - loss: 0.5165 - auc: 0.7963 - auc_1: 0.6888 - 2s/epoch - 58ms/step\n",
            "Epoch 50/100\n",
            "31/31 - 2s - loss: 0.5159 - auc: 0.7951 - auc_1: 0.6878 - 2s/epoch - 58ms/step\n",
            "Epoch 51/100\n",
            "31/31 - 2s - loss: 0.5153 - auc: 0.7951 - auc_1: 0.6878 - 2s/epoch - 57ms/step\n",
            "Epoch 52/100\n",
            "31/31 - 2s - loss: 0.5154 - auc: 0.7963 - auc_1: 0.6880 - 2s/epoch - 57ms/step\n",
            "Epoch 53/100\n",
            "31/31 - 2s - loss: 0.5143 - auc: 0.8006 - auc_1: 0.6894 - 2s/epoch - 58ms/step\n",
            "Epoch 54/100\n",
            "31/31 - 2s - loss: 0.5137 - auc: 0.7988 - auc_1: 0.6862 - 2s/epoch - 56ms/step\n",
            "Epoch 55/100\n",
            "31/31 - 2s - loss: 0.5132 - auc: 0.7994 - auc_1: 0.6878 - 2s/epoch - 58ms/step\n",
            "Epoch 56/100\n",
            "31/31 - 2s - loss: 0.5126 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 57ms/step\n",
            "Epoch 57/100\n",
            "31/31 - 2s - loss: 0.5123 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 56ms/step\n",
            "Epoch 58/100\n",
            "31/31 - 2s - loss: 0.5117 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 57ms/step\n",
            "Epoch 59/100\n",
            "31/31 - 2s - loss: 0.5111 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 57ms/step\n",
            "Epoch 60/100\n",
            "31/31 - 2s - loss: 0.5110 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 57ms/step\n",
            "Epoch 61/100\n",
            "31/31 - 2s - loss: 0.5102 - auc: 0.7982 - auc_1: 0.6858 - 2s/epoch - 56ms/step\n",
            "Epoch 62/100\n",
            "31/31 - 2s - loss: 0.5098 - auc: 0.7970 - auc_1: 0.6849 - 2s/epoch - 58ms/step\n",
            "Epoch 63/100\n",
            "31/31 - 2s - loss: 0.5090 - auc: 0.7963 - auc_1: 0.6847 - 2s/epoch - 57ms/step\n",
            "Epoch 64/100\n",
            "31/31 - 2s - loss: 0.5088 - auc: 0.7957 - auc_1: 0.6844 - 2s/epoch - 56ms/step\n",
            "Epoch 65/100\n",
            "31/31 - 2s - loss: 0.5082 - auc: 0.7963 - auc_1: 0.6847 - 2s/epoch - 57ms/step\n",
            "Epoch 66/100\n",
            "31/31 - 2s - loss: 0.5078 - auc: 0.8018 - auc_1: 0.6866 - 2s/epoch - 57ms/step\n",
            "Epoch 67/100\n",
            "31/31 - 2s - loss: 0.5074 - auc: 0.8018 - auc_1: 0.6885 - 2s/epoch - 56ms/step\n",
            "Epoch 68/100\n",
            "31/31 - 2s - loss: 0.5065 - auc: 0.8024 - auc_1: 0.6938 - 2s/epoch - 57ms/step\n",
            "Epoch 69/100\n",
            "31/31 - 2s - loss: 0.5060 - auc: 0.8012 - auc_1: 0.6879 - 2s/epoch - 57ms/step\n",
            "Epoch 70/100\n",
            "31/31 - 2s - loss: 0.5057 - auc: 0.8012 - auc_1: 0.6929 - 2s/epoch - 57ms/step\n",
            "Epoch 71/100\n",
            "31/31 - 2s - loss: 0.5051 - auc: 0.8018 - auc_1: 0.6932 - 2s/epoch - 58ms/step\n",
            "Epoch 72/100\n",
            "31/31 - 2s - loss: 0.5047 - auc: 0.8006 - auc_1: 0.6926 - 2s/epoch - 59ms/step\n",
            "Epoch 73/100\n",
            "31/31 - 2s - loss: 0.5044 - auc: 0.8018 - auc_1: 0.6932 - 2s/epoch - 59ms/step\n",
            "Epoch 74/100\n",
            "31/31 - 2s - loss: 0.5038 - auc: 0.8012 - auc_1: 0.6930 - 2s/epoch - 57ms/step\n",
            "Epoch 75/100\n",
            "31/31 - 2s - loss: 0.5038 - auc: 0.8079 - auc_1: 0.6958 - 2s/epoch - 56ms/step\n",
            "Epoch 76/100\n",
            "31/31 - 2s - loss: 0.5030 - auc: 0.8085 - auc_1: 0.6961 - 2s/epoch - 56ms/step\n",
            "Epoch 77/100\n",
            "31/31 - 2s - loss: 0.5026 - auc: 0.8073 - auc_1: 0.6999 - 2s/epoch - 57ms/step\n",
            "Epoch 78/100\n",
            "31/31 - 2s - loss: 0.5020 - auc: 0.8091 - auc_1: 0.7013 - 2s/epoch - 57ms/step\n",
            "Epoch 79/100\n",
            "31/31 - 2s - loss: 0.5019 - auc: 0.8079 - auc_1: 0.6963 - 2s/epoch - 57ms/step\n",
            "Epoch 80/100\n",
            "31/31 - 2s - loss: 0.5015 - auc: 0.8073 - auc_1: 0.6999 - 2s/epoch - 56ms/step\n",
            "Epoch 81/100\n",
            "31/31 - 2s - loss: 0.5009 - auc: 0.8073 - auc_1: 0.6999 - 2s/epoch - 56ms/step\n",
            "Epoch 82/100\n",
            "31/31 - 2s - loss: 0.5004 - auc: 0.8116 - auc_1: 0.7033 - 2s/epoch - 57ms/step\n",
            "Epoch 83/100\n",
            "31/31 - 2s - loss: 0.5000 - auc: 0.8104 - auc_1: 0.7027 - 2s/epoch - 56ms/step\n",
            "Epoch 84/100\n",
            "31/31 - 2s - loss: 0.4996 - auc: 0.8098 - auc_1: 0.7024 - 2s/epoch - 58ms/step\n",
            "Epoch 85/100\n",
            "31/31 - 2s - loss: 0.4992 - auc: 0.8134 - auc_1: 0.7042 - 2s/epoch - 56ms/step\n",
            "Epoch 86/100\n",
            "31/31 - 2s - loss: 0.4988 - auc: 0.8134 - auc_1: 0.7042 - 2s/epoch - 57ms/step\n",
            "Epoch 87/100\n",
            "31/31 - 2s - loss: 0.4987 - auc: 0.8146 - auc_1: 0.7051 - 2s/epoch - 58ms/step\n",
            "Epoch 88/100\n",
            "31/31 - 2s - loss: 0.4980 - auc: 0.8159 - auc_1: 0.7059 - 2s/epoch - 57ms/step\n",
            "Epoch 89/100\n",
            "31/31 - 2s - loss: 0.4977 - auc: 0.8177 - auc_1: 0.7108 - 2s/epoch - 57ms/step\n",
            "Epoch 90/100\n",
            "31/31 - 2s - loss: 0.4971 - auc: 0.8201 - auc_1: 0.7142 - 2s/epoch - 58ms/step\n",
            "Epoch 91/100\n",
            "31/31 - 2s - loss: 0.4967 - auc: 0.8177 - auc_1: 0.7108 - 2s/epoch - 57ms/step\n",
            "Epoch 92/100\n",
            "31/31 - 2s - loss: 0.4964 - auc: 0.8201 - auc_1: 0.7131 - 2s/epoch - 57ms/step\n",
            "Epoch 93/100\n",
            "31/31 - 2s - loss: 0.4961 - auc: 0.8201 - auc_1: 0.7131 - 2s/epoch - 58ms/step\n",
            "Epoch 94/100\n",
            "31/31 - 2s - loss: 0.4956 - auc: 0.8213 - auc_1: 0.7150 - 2s/epoch - 57ms/step\n",
            "Epoch 95/100\n",
            "31/31 - 2s - loss: 0.4955 - auc: 0.8201 - auc_1: 0.7142 - 2s/epoch - 59ms/step\n",
            "Epoch 96/100\n",
            "31/31 - 2s - loss: 0.4947 - auc: 0.8238 - auc_1: 0.7168 - 2s/epoch - 60ms/step\n",
            "Epoch 97/100\n",
            "31/31 - 2s - loss: 0.4944 - auc: 0.8250 - auc_1: 0.7175 - 2s/epoch - 59ms/step\n",
            "Epoch 98/100\n",
            "31/31 - 2s - loss: 0.4941 - auc: 0.8250 - auc_1: 0.7175 - 2s/epoch - 57ms/step\n",
            "Epoch 99/100\n",
            "31/31 - 2s - loss: 0.4937 - auc: 0.8238 - auc_1: 0.7168 - 2s/epoch - 58ms/step\n",
            "Epoch 100/100\n",
            "31/31 - 2s - loss: 0.4933 - auc: 0.8244 - auc_1: 0.7180 - 2s/epoch - 58ms/step\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4886 - auc: 0.5741 - auc_1: 0.2623\n",
            "Epoch 1/100\n",
            "50/50 - 3s - loss: 0.3915 - auc: 0.7430 - auc_1: 0.3673 - 3s/epoch - 57ms/step\n",
            "Epoch 2/100\n",
            "50/50 - 3s - loss: 0.3819 - auc: 0.7453 - auc_1: 0.3614 - 3s/epoch - 56ms/step\n",
            "Epoch 3/100\n",
            "50/50 - 3s - loss: 0.3723 - auc: 0.7477 - auc_1: 0.3652 - 3s/epoch - 57ms/step\n",
            "Epoch 4/100\n",
            "50/50 - 3s - loss: 0.3629 - auc: 0.7516 - auc_1: 0.3658 - 3s/epoch - 57ms/step\n",
            "Epoch 5/100\n",
            "50/50 - 3s - loss: 0.3539 - auc: 0.7547 - auc_1: 0.3656 - 3s/epoch - 56ms/step\n",
            "Epoch 6/100\n",
            "50/50 - 3s - loss: 0.3451 - auc: 0.7461 - auc_1: 0.3643 - 3s/epoch - 56ms/step\n",
            "Epoch 7/100\n",
            "50/50 - 3s - loss: 0.3365 - auc: 0.7562 - auc_1: 0.3765 - 3s/epoch - 57ms/step\n",
            "Epoch 8/100\n",
            "50/50 - 3s - loss: 0.3287 - auc: 0.7539 - auc_1: 0.3758 - 3s/epoch - 57ms/step\n",
            "Epoch 9/100\n",
            "50/50 - 3s - loss: 0.3208 - auc: 0.7508 - auc_1: 0.3728 - 3s/epoch - 57ms/step\n",
            "Epoch 10/100\n",
            "50/50 - 3s - loss: 0.3136 - auc: 0.7531 - auc_1: 0.3759 - 3s/epoch - 57ms/step\n",
            "Epoch 11/100\n",
            "50/50 - 3s - loss: 0.3072 - auc: 0.7547 - auc_1: 0.3705 - 3s/epoch - 56ms/step\n",
            "Epoch 12/100\n",
            "50/50 - 3s - loss: 0.3010 - auc: 0.7601 - auc_1: 0.3727 - 3s/epoch - 56ms/step\n",
            "Epoch 13/100\n",
            "50/50 - 3s - loss: 0.2953 - auc: 0.7717 - auc_1: 0.3714 - 3s/epoch - 57ms/step\n",
            "Epoch 14/100\n",
            "50/50 - 3s - loss: 0.2902 - auc: 0.7547 - auc_1: 0.3684 - 3s/epoch - 56ms/step\n",
            "Epoch 15/100\n",
            "50/50 - 3s - loss: 0.2853 - auc: 0.7585 - auc_1: 0.3242 - 3s/epoch - 57ms/step\n",
            "Epoch 16/100\n",
            "50/50 - 3s - loss: 0.2810 - auc: 0.7694 - auc_1: 0.3273 - 3s/epoch - 56ms/step\n",
            "Epoch 17/100\n",
            "50/50 - 3s - loss: 0.2771 - auc: 0.7632 - auc_1: 0.3329 - 3s/epoch - 57ms/step\n",
            "Epoch 18/100\n",
            "50/50 - 3s - loss: 0.2735 - auc: 0.7523 - auc_1: 0.3307 - 3s/epoch - 56ms/step\n",
            "Epoch 19/100\n",
            "50/50 - 3s - loss: 0.2703 - auc: 0.7663 - auc_1: 0.3365 - 3s/epoch - 56ms/step\n",
            "Epoch 20/100\n",
            "50/50 - 3s - loss: 0.2672 - auc: 0.7663 - auc_1: 0.3313 - 3s/epoch - 56ms/step\n",
            "Epoch 21/100\n",
            "50/50 - 3s - loss: 0.2645 - auc: 0.7772 - auc_1: 0.3476 - 3s/epoch - 56ms/step\n",
            "Epoch 22/100\n",
            "50/50 - 3s - loss: 0.2624 - auc: 0.7873 - auc_1: 0.3499 - 3s/epoch - 56ms/step\n",
            "Epoch 23/100\n",
            "50/50 - 3s - loss: 0.2597 - auc: 0.7570 - auc_1: 0.3444 - 3s/epoch - 56ms/step\n",
            "Epoch 24/100\n",
            "50/50 - 3s - loss: 0.2579 - auc: 0.7562 - auc_1: 0.3439 - 3s/epoch - 56ms/step\n",
            "Epoch 25/100\n",
            "50/50 - 3s - loss: 0.2560 - auc: 0.7655 - auc_1: 0.3546 - 3s/epoch - 56ms/step\n",
            "Epoch 26/100\n",
            "50/50 - 3s - loss: 0.2544 - auc: 0.7725 - auc_1: 0.3573 - 3s/epoch - 56ms/step\n",
            "Epoch 27/100\n",
            "50/50 - 3s - loss: 0.2529 - auc: 0.7787 - auc_1: 0.3533 - 3s/epoch - 56ms/step\n",
            "Epoch 28/100\n",
            "50/50 - 3s - loss: 0.2514 - auc: 0.7803 - auc_1: 0.3576 - 3s/epoch - 56ms/step\n",
            "Epoch 29/100\n",
            "50/50 - 3s - loss: 0.2501 - auc: 0.7679 - auc_1: 0.3566 - 3s/epoch - 56ms/step\n",
            "Epoch 30/100\n",
            "50/50 - 3s - loss: 0.2489 - auc: 0.7725 - auc_1: 0.3548 - 3s/epoch - 57ms/step\n",
            "Epoch 31/100\n",
            "50/50 - 3s - loss: 0.2478 - auc: 0.7764 - auc_1: 0.3528 - 3s/epoch - 56ms/step\n",
            "Epoch 32/100\n",
            "50/50 - 3s - loss: 0.2469 - auc: 0.7787 - auc_1: 0.3545 - 3s/epoch - 57ms/step\n",
            "Epoch 33/100\n",
            "50/50 - 3s - loss: 0.2457 - auc: 0.7826 - auc_1: 0.3556 - 3s/epoch - 56ms/step\n",
            "Epoch 34/100\n",
            "50/50 - 3s - loss: 0.2449 - auc: 0.7609 - auc_1: 0.3508 - 3s/epoch - 56ms/step\n",
            "Epoch 35/100\n",
            "50/50 - 3s - loss: 0.2440 - auc: 0.7609 - auc_1: 0.3511 - 3s/epoch - 56ms/step\n",
            "Epoch 36/100\n",
            "50/50 - 3s - loss: 0.2432 - auc: 0.7679 - auc_1: 0.3537 - 3s/epoch - 57ms/step\n",
            "Epoch 37/100\n",
            "50/50 - 3s - loss: 0.2425 - auc: 0.7733 - auc_1: 0.3676 - 3s/epoch - 57ms/step\n",
            "Epoch 38/100\n",
            "50/50 - 3s - loss: 0.2419 - auc: 0.7772 - auc_1: 0.3685 - 3s/epoch - 56ms/step\n",
            "Epoch 39/100\n",
            "50/50 - 3s - loss: 0.2412 - auc: 0.7803 - auc_1: 0.3691 - 3s/epoch - 57ms/step\n",
            "Epoch 40/100\n",
            "50/50 - 3s - loss: 0.2406 - auc: 0.7585 - auc_1: 0.3210 - 3s/epoch - 56ms/step\n",
            "Epoch 41/100\n",
            "50/50 - 3s - loss: 0.2400 - auc: 0.7578 - auc_1: 0.3207 - 3s/epoch - 56ms/step\n",
            "Epoch 42/100\n",
            "50/50 - 3s - loss: 0.2394 - auc: 0.7609 - auc_1: 0.3216 - 3s/epoch - 56ms/step\n",
            "Epoch 43/100\n",
            "50/50 - 3s - loss: 0.2390 - auc: 0.7624 - auc_1: 0.3206 - 3s/epoch - 56ms/step\n",
            "Epoch 44/100\n",
            "50/50 - 3s - loss: 0.2382 - auc: 0.7640 - auc_1: 0.3209 - 3s/epoch - 56ms/step\n",
            "Epoch 45/100\n",
            "50/50 - 3s - loss: 0.2380 - auc: 0.7679 - auc_1: 0.3223 - 3s/epoch - 56ms/step\n",
            "Epoch 46/100\n",
            "50/50 - 3s - loss: 0.2374 - auc: 0.7694 - auc_1: 0.3299 - 3s/epoch - 55ms/step\n",
            "Epoch 47/100\n",
            "50/50 - 3s - loss: 0.2369 - auc: 0.7725 - auc_1: 0.3309 - 3s/epoch - 56ms/step\n",
            "Epoch 48/100\n",
            "50/50 - 3s - loss: 0.2365 - auc: 0.7655 - auc_1: 0.3438 - 3s/epoch - 56ms/step\n",
            "Epoch 49/100\n",
            "50/50 - 3s - loss: 0.2359 - auc: 0.7679 - auc_1: 0.3443 - 3s/epoch - 55ms/step\n",
            "Epoch 50/100\n",
            "50/50 - 3s - loss: 0.2356 - auc: 0.7686 - auc_1: 0.3536 - 3s/epoch - 56ms/step\n",
            "Epoch 51/100\n",
            "50/50 - 3s - loss: 0.2351 - auc: 0.7702 - auc_1: 0.3538 - 3s/epoch - 57ms/step\n",
            "Epoch 52/100\n",
            "50/50 - 3s - loss: 0.2348 - auc: 0.7710 - auc_1: 0.3518 - 3s/epoch - 56ms/step\n",
            "Epoch 53/100\n",
            "50/50 - 3s - loss: 0.2342 - auc: 0.7811 - auc_1: 0.3559 - 3s/epoch - 56ms/step\n",
            "Epoch 54/100\n",
            "50/50 - 3s - loss: 0.2337 - auc: 0.7733 - auc_1: 0.3523 - 3s/epoch - 57ms/step\n",
            "Epoch 55/100\n",
            "50/50 - 3s - loss: 0.2336 - auc: 0.7811 - auc_1: 0.3559 - 3s/epoch - 55ms/step\n",
            "Epoch 56/100\n",
            "50/50 - 3s - loss: 0.2331 - auc: 0.7741 - auc_1: 0.3526 - 3s/epoch - 56ms/step\n",
            "Epoch 57/100\n",
            "50/50 - 3s - loss: 0.2326 - auc: 0.7842 - auc_1: 0.3570 - 3s/epoch - 56ms/step\n",
            "Epoch 58/100\n",
            "50/50 - 3s - loss: 0.2324 - auc: 0.7795 - auc_1: 0.3541 - 3s/epoch - 57ms/step\n",
            "Epoch 59/100\n",
            "50/50 - 3s - loss: 0.2319 - auc: 0.7849 - auc_1: 0.3575 - 3s/epoch - 56ms/step\n",
            "Epoch 60/100\n",
            "50/50 - 3s - loss: 0.2315 - auc: 0.7865 - auc_1: 0.3578 - 3s/epoch - 55ms/step\n",
            "Epoch 61/100\n",
            "50/50 - 3s - loss: 0.2313 - auc: 0.7880 - auc_1: 0.3580 - 3s/epoch - 56ms/step\n",
            "Epoch 62/100\n",
            "50/50 - 3s - loss: 0.2310 - auc: 0.7896 - auc_1: 0.3721 - 3s/epoch - 56ms/step\n",
            "Epoch 63/100\n",
            "50/50 - 3s - loss: 0.2305 - auc: 0.7896 - auc_1: 0.3721 - 3s/epoch - 56ms/step\n",
            "Epoch 64/100\n",
            "50/50 - 3s - loss: 0.2301 - auc: 0.7834 - auc_1: 0.3680 - 3s/epoch - 56ms/step\n",
            "Epoch 65/100\n",
            "50/50 - 3s - loss: 0.2298 - auc: 0.7911 - auc_1: 0.3724 - 3s/epoch - 57ms/step\n",
            "Epoch 66/100\n",
            "50/50 - 3s - loss: 0.2294 - auc: 0.7974 - auc_1: 0.3949 - 3s/epoch - 56ms/step\n",
            "Epoch 67/100\n",
            "50/50 - 3s - loss: 0.2291 - auc: 0.7989 - auc_1: 0.3951 - 3s/epoch - 57ms/step\n",
            "Epoch 68/100\n",
            "50/50 - 3s - loss: 0.2287 - auc: 0.7997 - auc_1: 0.4273 - 3s/epoch - 57ms/step\n",
            "Epoch 69/100\n",
            "50/50 - 3s - loss: 0.2285 - auc: 0.8005 - auc_1: 0.4279 - 3s/epoch - 56ms/step\n",
            "Epoch 70/100\n",
            "50/50 - 3s - loss: 0.2281 - auc: 0.8005 - auc_1: 0.4279 - 3s/epoch - 56ms/step\n",
            "Epoch 71/100\n",
            "50/50 - 3s - loss: 0.2280 - auc: 0.8005 - auc_1: 0.4279 - 3s/epoch - 56ms/step\n",
            "Epoch 72/100\n",
            "50/50 - 3s - loss: 0.2275 - auc: 0.8012 - auc_1: 0.4285 - 3s/epoch - 57ms/step\n",
            "Epoch 73/100\n",
            "50/50 - 3s - loss: 0.2270 - auc: 0.8020 - auc_1: 0.4292 - 3s/epoch - 56ms/step\n",
            "Epoch 74/100\n",
            "50/50 - 3s - loss: 0.2267 - auc: 0.8028 - auc_1: 0.4307 - 3s/epoch - 56ms/step\n",
            "Epoch 75/100\n",
            "50/50 - 3s - loss: 0.2264 - auc: 0.8028 - auc_1: 0.4307 - 3s/epoch - 57ms/step\n",
            "Epoch 76/100\n",
            "50/50 - 3s - loss: 0.2261 - auc: 0.8036 - auc_1: 0.4284 - 3s/epoch - 57ms/step\n",
            "Epoch 77/100\n",
            "50/50 - 3s - loss: 0.2257 - auc: 0.8020 - auc_1: 0.4281 - 3s/epoch - 57ms/step\n",
            "Epoch 78/100\n",
            "50/50 - 3s - loss: 0.2252 - auc: 0.8020 - auc_1: 0.4281 - 3s/epoch - 56ms/step\n",
            "Epoch 79/100\n",
            "50/50 - 3s - loss: 0.2253 - auc: 0.8012 - auc_1: 0.4285 - 3s/epoch - 57ms/step\n",
            "Epoch 80/100\n",
            "50/50 - 3s - loss: 0.2247 - auc: 0.8043 - auc_1: 0.4290 - 3s/epoch - 57ms/step\n",
            "Epoch 81/100\n",
            "50/50 - 3s - loss: 0.2244 - auc: 0.8020 - auc_1: 0.4271 - 3s/epoch - 57ms/step\n",
            "Epoch 82/100\n",
            "50/50 - 3s - loss: 0.2241 - auc: 0.8075 - auc_1: 0.4296 - 3s/epoch - 56ms/step\n",
            "Epoch 83/100\n",
            "50/50 - 3s - loss: 0.2238 - auc: 0.8051 - auc_1: 0.4277 - 3s/epoch - 57ms/step\n",
            "Epoch 84/100\n",
            "50/50 - 3s - loss: 0.2234 - auc: 0.8082 - auc_1: 0.4302 - 3s/epoch - 56ms/step\n",
            "Epoch 85/100\n",
            "50/50 - 3s - loss: 0.2231 - auc: 0.8067 - auc_1: 0.4299 - 3s/epoch - 57ms/step\n",
            "Epoch 86/100\n",
            "50/50 - 3s - loss: 0.2228 - auc: 0.8082 - auc_1: 0.4341 - 3s/epoch - 57ms/step\n",
            "Epoch 87/100\n",
            "50/50 - 3s - loss: 0.2224 - auc: 0.8043 - auc_1: 0.4280 - 3s/epoch - 57ms/step\n",
            "Epoch 88/100\n",
            "50/50 - 3s - loss: 0.2224 - auc: 0.8106 - auc_1: 0.4321 - 3s/epoch - 57ms/step\n",
            "Epoch 89/100\n",
            "50/50 - 3s - loss: 0.2218 - auc: 0.8090 - auc_1: 0.4318 - 3s/epoch - 57ms/step\n",
            "Epoch 90/100\n",
            "50/50 - 3s - loss: 0.2215 - auc: 0.8082 - auc_1: 0.4302 - 3s/epoch - 57ms/step\n",
            "Epoch 91/100\n",
            "50/50 - 3s - loss: 0.2213 - auc: 0.8121 - auc_1: 0.4325 - 3s/epoch - 57ms/step\n",
            "Epoch 92/100\n",
            "50/50 - 3s - loss: 0.2209 - auc: 0.8144 - auc_1: 0.4365 - 3s/epoch - 56ms/step\n",
            "Epoch 93/100\n",
            "50/50 - 3s - loss: 0.2207 - auc: 0.8152 - auc_1: 0.4361 - 3s/epoch - 57ms/step\n",
            "Epoch 94/100\n",
            "50/50 - 3s - loss: 0.2202 - auc: 0.8137 - auc_1: 0.4328 - 3s/epoch - 57ms/step\n",
            "Epoch 95/100\n",
            "50/50 - 3s - loss: 0.2201 - auc: 0.8152 - auc_1: 0.4374 - 3s/epoch - 57ms/step\n",
            "Epoch 96/100\n",
            "50/50 - 3s - loss: 0.2195 - auc: 0.8144 - auc_1: 0.4344 - 3s/epoch - 56ms/step\n",
            "Epoch 97/100\n",
            "50/50 - 3s - loss: 0.2193 - auc: 0.8168 - auc_1: 0.4399 - 3s/epoch - 57ms/step\n",
            "Epoch 98/100\n",
            "50/50 - 3s - loss: 0.2189 - auc: 0.8191 - auc_1: 0.4410 - 3s/epoch - 58ms/step\n",
            "Epoch 99/100\n",
            "50/50 - 3s - loss: 0.2187 - auc: 0.8160 - auc_1: 0.4368 - 3s/epoch - 57ms/step\n",
            "Epoch 100/100\n",
            "50/50 - 3s - loss: 0.2184 - auc: 0.8175 - auc_1: 0.4372 - 3s/epoch - 58ms/step\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.4139 - auc: 0.6970 - auc_1: 0.2113\n",
            "Epoch 1/100\n",
            "99/99 - 3s - loss: 0.9638 - mean_absolute_error: 0.6769 - 3s/epoch - 33ms/step\n",
            "Epoch 2/100\n",
            "99/99 - 3s - loss: 0.9960 - mean_absolute_error: 0.6922 - 3s/epoch - 33ms/step\n",
            "Epoch 3/100\n",
            "99/99 - 3s - loss: 0.9576 - mean_absolute_error: 0.6732 - 3s/epoch - 33ms/step\n",
            "Epoch 4/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 5/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 6/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 7/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 34ms/step\n",
            "Epoch 8/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 9/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 10/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 11/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 12/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 13/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 14/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 15/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 16/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 17/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 18/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 19/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 20/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 21/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 22/100\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 32ms/step\n",
            "Epoch 23/100\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "99/99 - 3s - loss: 0.9575 - mean_absolute_error: 0.6725 - 3s/epoch - 33ms/step\n",
            "Epoch 23: early stopping\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 1.0003 - mean_absolute_error: 0.7925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3_art6AQSVBY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}