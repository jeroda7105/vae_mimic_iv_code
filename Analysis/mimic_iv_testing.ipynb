{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0DsFARgE0MOh"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "4jqZLo8J1VcH",
    "outputId": "437277b6-2f10-471d-c550-3caa5a4a36b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     0.0     0.0     1.0          0.0   \n",
       "1               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "2               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "3               92.0  ...     0.0     0.0     1.0          0.0   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     0.0                         0.0             0.0   \n",
       "1                     0.0                         0.0             0.0   \n",
       "2                     0.0                         0.0             0.0   \n",
       "3                     0.0                         0.0             0.0   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 0.0          0.0     1.0  \n",
       "1                 0.0          0.0     1.0  \n",
       "2                 0.0          0.0     1.0  \n",
       "3                 0.0          0.0     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Time Series Data\n",
    "\n",
    "# Data by the hour\n",
    "first_48_data = pd.read_csv('../../../../data/datasets/mimiciv_timeseries/mimiciv_timeseries.csv')\n",
    "\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in first_48_data.iterrows():\n",
    "        \n",
    "    # Making gcs scores nan where unobserved\n",
    "    if row['x0_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x0_0.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x0_1.0'] = np.nan\n",
    "\n",
    "    if row['x1_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x1_None'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_Spontaneously'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Speech'] = np.nan\n",
    "\n",
    "    if row['x2_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x2_Abnormal Flexion'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Abnormal extension'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Flex-withdraws'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Localizes Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_No response'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Obeys Commands'] = np.nan\n",
    "\n",
    "    if row['x3_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x3_10.0'] = np.nan \n",
    "        first_48_data.at[idx, 'x3_11.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_12.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_13.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_14.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_15.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_3.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_4.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_5.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_6.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_7.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_8.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_9.0'] = np.nan\n",
    "\n",
    "\n",
    "    if row['x4_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x4_Confused'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Inappropriate Words'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Incomprehensible sounds'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response-ETT'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Oriented'] = np.nan\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     NaN     NaN     1.0          NaN   \n",
       "1               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "2               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "3               92.0  ...     NaN     NaN     1.0          NaN   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     NaN                         NaN             NaN   \n",
       "1                     NaN                         NaN             NaN   \n",
       "2                     NaN                         NaN             NaN   \n",
       "3                     NaN                         NaN             NaN   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 NaN          NaN     1.0  \n",
       "1                 NaN          NaN     1.0  \n",
       "2                 NaN          NaN     1.0  \n",
       "3                 NaN          NaN     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18664949_episode1</td>\n",
       "      <td>18664949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.114583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19793183_episode1</td>\n",
       "      <td>19793183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.467361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15687156_episode1</td>\n",
       "      <td>15687156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14504982_episode1</td>\n",
       "      <td>14504982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  subject_id  episode_num  readmission  \\\n",
       "0           0  11432534_episode1    11432534            1          0.0   \n",
       "1           1  18664949_episode1    18664949            1          0.0   \n",
       "2           2  19793183_episode1    19793183            1          0.0   \n",
       "3           3  15687156_episode1    15687156            1          0.0   \n",
       "4           4  14504982_episode1    14504982            1          0.0   \n",
       "\n",
       "   length_of_stay  mortality  \n",
       "0        7.935417          0  \n",
       "1        5.114583          0  \n",
       "2       20.467361          0  \n",
       "3        0.098611          1  \n",
       "4        9.854167          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading label data\n",
    "\n",
    "label_data = pd.read_csv('mimic_iv_label_data.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10000980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10001217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10001725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10002013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  cluster\n",
       "0           0    10000032        1\n",
       "1           1    10000980        1\n",
       "2           2    10001217        1\n",
       "3           3    10001725        1\n",
       "4           4    10002013        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading patient clusters\n",
    "\n",
    "patient_clusters = pd.read_csv('mimic_iv_patient_clusters.csv')\n",
    "patient_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column for subject_id and episode_num\n",
    "\n",
    "subject_w_ep = first_48_data['subject']\n",
    "\n",
    "subject_ids = subject_w_ep.apply(lambda x: int(x.split('_')[0]))\n",
    "episode_nums = subject_w_ep.apply(lambda x: int(x.split('_')[1][7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_nan  x4_Confused  x4_Inappropriate Words  \\\n",
       "0                NaN  ...     1.0          NaN                     NaN   \n",
       "1               93.0  ...     1.0          NaN                     NaN   \n",
       "2               93.0  ...     1.0          NaN                     NaN   \n",
       "3               92.0  ...     1.0          NaN                     NaN   \n",
       "4               92.0  ...     0.0          1.0                     0.0   \n",
       "\n",
       "   x4_Incomprehensible sounds  x4_No Response  x4_No Response-ETT  \\\n",
       "0                         NaN             NaN                 NaN   \n",
       "1                         NaN             NaN                 NaN   \n",
       "2                         NaN             NaN                 NaN   \n",
       "3                         NaN             NaN                 NaN   \n",
       "4                         0.0             0.0                 0.0   \n",
       "\n",
       "   x4_Oriented  x4_nan  subject_id  episode_num  \n",
       "0          NaN     1.0    11432534            1  \n",
       "1          NaN     1.0    11432534            1  \n",
       "2          NaN     1.0    11432534            1  \n",
       "3          NaN     1.0    11432534            1  \n",
       "4          0.0     0.0    11432534            1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data['subject_id'] = subject_ids\n",
    "first_48_data['episode_num'] = episode_nums\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_48_data.rename(columns={\"time(hr)\": \"Hours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                      42.0   \n",
       "3             3  11432534_episode1  0.060556                      42.0   \n",
       "4             4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x4_Oriented  x4_nan  subject_id  episode_num  \\\n",
       "0                NaN  ...          NaN     1.0    11432534            1   \n",
       "1               93.0  ...          NaN     1.0    11432534            1   \n",
       "2               93.0  ...          NaN     1.0    11432534            1   \n",
       "3               92.0  ...          NaN     1.0    11432534            1   \n",
       "4               92.0  ...          0.0     0.0    11432534            1   \n",
       "\n",
       "   Unnamed: 0_y  readmission  length_of_stay  mortality  Unnamed: 0  cluster  \n",
       "0             0          0.0        7.935417          0        3710        1  \n",
       "1             0          0.0        7.935417          0        3710        1  \n",
       "2             0          0.0        7.935417          0        3710        1  \n",
       "3             0          0.0        7.935417          0        3710        1  \n",
       "4             0          0.0        7.935417          0        3710        1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging data with labels and cluster to get correct sample\n",
    "\n",
    "first_48_data = first_48_data.merge(label_data, on=['subject', 'subject_id', 'episode_num'])\n",
    "first_48_data = first_48_data.merge(patient_clusters, on='subject_id')\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "print(len(first_48_data.groupby('subject')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0_x', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'Unnamed: 0_y', 'readmission',\n",
      "       'length_of_stay', 'mortality', 'Unnamed: 0', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping 'Unnamed: 0_x' and renaming to 'original_idx' to retain original indexes\n",
    "first_48_data = first_48_data.drop(columns=['Unnamed: 0_y', 'Unnamed: 0'])\n",
    "\n",
    "first_48_data = first_48_data.rename(columns={'Unnamed: 0_x': 'original_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_idx', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'readmission', 'length_of_stay',\n",
      "       'mortality', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
      "       'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
      "       'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
      "       'pH', 'x0_0.0', 'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously',\n",
      "       'x1_To Pain', 'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns[3:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShNbUHNw1l7H",
    "outputId": "0e39d038-6219-4b65-ef1c-166836a6306c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the numerical features\n",
    "\n",
    "feature_data = first_48_data[first_48_data.columns[3:-6]]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "std_scaler.fit(feature_data)\n",
    "\n",
    "scaled_X = std_scaler.transform(feature_data)\n",
    "\n",
    "scaled_X_df = pd.DataFrame(scaled_X, columns=first_48_data.columns[3:-6])\n",
    "\n",
    "first_48_data[first_48_data.columns[3:-6]] = scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_idx</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578713</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578713</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>-0.068646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.097996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578713</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>-0.068646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.578713</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>-0.068646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192027</td>\n",
       "      <td>-0.752544</td>\n",
       "      <td>-0.962488</td>\n",
       "      <td>-0.218402</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_idx            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                 -0.068646   \n",
       "3             3  11432534_episode1  0.060556                 -0.068646   \n",
       "4             4  11432534_episode1  0.143889                 -0.068646   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN   -0.097996     NaN                  NaN   \n",
       "2                       NaN      NaN   -0.097996     NaN            -0.013262   \n",
       "3                       NaN      NaN   -0.005599     NaN            -0.013262   \n",
       "4                       NaN      NaN   -0.005599     NaN            -0.013262   \n",
       "\n",
       "   Oxygen saturation  ...  x4_No Response  x4_No Response-ETT  x4_Oriented  \\\n",
       "0                NaN  ...             NaN                 NaN          NaN   \n",
       "1          -0.004615  ...             NaN                 NaN          NaN   \n",
       "2          -0.004615  ...             NaN                 NaN          NaN   \n",
       "3          -0.005586  ...             NaN                 NaN          NaN   \n",
       "4          -0.005586  ...       -0.192027           -0.752544    -0.962488   \n",
       "\n",
       "     x4_nan  subject_id  episode_num  readmission  length_of_stay  mortality  \\\n",
       "0  4.578713    11432534            1          0.0        7.935417          0   \n",
       "1  4.578713    11432534            1          0.0        7.935417          0   \n",
       "2  4.578713    11432534            1          0.0        7.935417          0   \n",
       "3  4.578713    11432534            1          0.0        7.935417          0   \n",
       "4 -0.218402    11432534            1          0.0        7.935417          0   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx7GR50X1onC",
    "outputId": "6acc984c-8335-4a2f-b716-ce2e977ae03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "# Grouping by admission\n",
    "\n",
    "data = first_48_data.groupby('subject')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  \n",
    "\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "\n",
    "for group_idx, group_rows in data:  \n",
    "    \n",
    "    subjects.append(group_idx)\n",
    "    subject_idx.append(i)\n",
    "    \n",
    "    readm_label.append(group_rows['readmission'].values[0])\n",
    "    mortality_label.append(group_rows['mortality'].values[0])\n",
    "    los_label.append(group_rows['length_of_stay'].values[0])\n",
    "    cluster.append(group_rows['cluster'].values[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # stores totals for variables\n",
    "    cur_matrix = np.empty([48, 48])\n",
    "    cur_matrix[:] = np.nan\n",
    "\n",
    "    # stores counts for variables\n",
    "    cur_counts = np.empty([48, 48])\n",
    "    cur_counts[:] = np.nan\n",
    "\n",
    "    cur_columns = group_rows.columns.values.tolist()\n",
    "    feature_columns = cur_columns[3:-6]\n",
    "\n",
    "    j = 0\n",
    "    for idx, row in group_rows.iterrows():\n",
    "        \n",
    "            \n",
    "        # Modifying cur_data to have data by the hour for 48 hours\n",
    "        if row['Hours'] < j+1 and j < 48:\n",
    "            for k in range(len(feature_columns)):\n",
    "                if not (np.isnan(group_rows.loc[idx, feature_columns[k]])):\n",
    "                    if np.isnan(cur_matrix[j, k]):\n",
    "                        cur_matrix[j, k] = group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] = 1\n",
    "                    else:\n",
    "                        cur_matrix[j, k] += group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] += 1\n",
    "                        \n",
    "        else:\n",
    "            if j >= 48:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "    # Getting time series data\n",
    "\n",
    "    X_element = np.divide(cur_matrix, cur_counts)\n",
    "\n",
    "    if i == 0:\n",
    "\n",
    "        # Holds all of the multivariate time series\n",
    "        X = np.array([X_element])\n",
    "\n",
    "    else:\n",
    "        X = np.concatenate((X, np.array([X_element])))\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7LiqNzaB5TU",
    "outputId": "e82a9180-0104-426d-841c-cdccbbd97574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>readmission</th>\n",
       "      <th>mortality</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032_episode1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980_episode1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.806944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001217_episode1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.794444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001217_episode2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.914583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001725_episode1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject  subject_idx  readmission  mortality  length_of_stay  \\\n",
       "0  10000032_episode1            0          0.0          0        2.222222   \n",
       "1  10000980_episode1            1          0.0          0        5.806944   \n",
       "2  10001217_episode1            2          1.0          0        6.794444   \n",
       "3  10001217_episode2            3          NaN          0        5.914583   \n",
       "4  10001725_episode1            4          0.0          0        2.994444   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'subject':subjects, 'subject_idx':subject_idx, 'readmission':readm_label, 'mortality':mortality_label,\n",
    "                  'length_of_stay':los_label, 'cluster':cluster})\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "T2z9KMmI1tVF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 33\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.3060744631479621, 0.007567215395415256, 0.0008653313120167058, 0.007567215395415256, -0.05479307122666779, 0.007567215395415256, 0.007567215395415256, -0.05588963840616957, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256, 0.007567215395415256]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "all_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_2d = np.reshape(X, (X.shape[0]*X.shape[1], X.shape[2]))\n",
    "\n",
    "\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "mean_imputer.fit(X_2d)\n",
    "X_2d = mean_imputer.transform(X_2d)\n",
    "\n",
    "\n",
    "for i in range(X_2d.shape[1]):\n",
    "    all_feature_means.append(np.mean(X_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(all_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwJDX3Ai2GnQ",
    "outputId": "52f717ae-3504-4811-f20a-cc84764a72d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.39810436700991453, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.4425443928801518, 0.4342651064359167, 0.03556237063306282, 0.024835874975762746, 0.014501163097385842, 0.008820589033867258, 0.008820589033867258, -0.06190716849036998, 0.008820589033867258, -0.05769569347251342, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, -0.06534735371282874, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, -0.09508031002088357, -0.0986887377685534, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, 0.008820589033867258, -0.05294622502459456, 0.008820589033867258, -0.06530292164973293, -0.08664731650038145, -0.09025342041675294, 0.008820589033867258, -0.08742073805816876, 0.008820589033867258, -0.08896722079308134]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "train_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_train_2d = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "\n",
    "train_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_mean_imputer.fit(X_train_2d)\n",
    "X_train_2d = train_mean_imputer.transform(X_train_2d)\n",
    "\n",
    "\n",
    "for i in range(X_train_2d.shape[1]):\n",
    "    train_feature_means.append(np.mean(X_train_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q12dIA8z2hsx",
    "outputId": "a7fe45b7-0b1e-4eed-c627-2699bcb41292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.40411800679055293, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, 0.4564980208994606, 0.40242200575879844, -0.008237552110877858, -0.039772654599848946, -0.037416228389272055, -0.046264907258210926, -0.006527734970879569, 0.00601029100481439, 0.004135912202925344, 0.0017643057420728935, -0.04821027157513963, -0.04485331837192022, -0.04079129553285062, -0.04109349106100015, 0.0017643057420728935, -0.035831718809609905, -0.036674242758362306, 0.0017643057420728935, 0.0017643057420728935, 0.1266341701897206, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, -0.06844706161712381, -0.06534186336045254, -0.06811419853258685, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, -0.08431911542354469, 0.0017643057420728935, -0.07999053198232446, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, -0.08411775876004057, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, 0.0017643057420728935, -0.08463983512261795, -0.08106817016696753, 0.0017643057420728935]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "test_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_test_2d = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "\n",
    "test_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "test_mean_imputer.fit(X_test_2d)\n",
    "X_test_2d = test_mean_imputer.transform(X_test_2d)\n",
    "\n",
    "\n",
    "for i in range(X_test_2d.shape[1]):\n",
    "    test_feature_means.append(np.mean(X_test_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(test_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6Q53xXLP2lnd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a random mask for evaluation of imputation \n",
    "\n",
    "def mean_imputation_eval(X, train_feature_means):\n",
    "    iter = 100\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "    \n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4SbKzJc21E7",
    "outputId": "2f997abd-7a40-41f0-f71b-97d38a04fdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:\n",
      "0.5776177830281686\n",
      "0.015483739134975714 \n",
      "\n",
      "mae:\n",
      "0.3979626500626157\n",
      "0.0006590698783683776 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputation_eval(X, all_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8qPYEc7B3GNQ"
   },
   "outputs": [],
   "source": [
    "def create_mean_imputed_data(X_train, X_test, train_feature_means, test_feature_means):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = train_feature_means[k]\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = train_feature_means[k]\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "\n",
    "    return X_train_imputed, X_test_imputed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iComzTNR4cbF"
   },
   "outputs": [],
   "source": [
    "X_train_mean_imputed, X_test_mean_imputed = create_mean_imputed_data(X_train, X_test, train_feature_means, test_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "d9GnUNeC40Em"
   },
   "outputs": [],
   "source": [
    "def vae_preprocessing(X_train, X_test):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = impute_value\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = impute_value\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "                    \n",
    "    return X_train_imputed, X_test_imputed, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HPBch8O_5uFF"
   },
   "outputs": [],
   "source": [
    "processed_X_train, processed_X_test, train_mask, test_mask = vae_preprocessing(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Co301rq5CDqP"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class vae_model(ABC):\n",
    "\n",
    "    def __init__(self, n_filters, kernel_size, learning_rate,\n",
    "               sequence_length, n_features):\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.latent_dim = 2\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "    \n",
    "\n",
    "        if self.kernel_size == 3:\n",
    "            self.nn_dim = 21\n",
    "        elif self.kernel_size == 5:\n",
    "            self.nn_dim = 18\n",
    "        else:\n",
    "            self.kernel_size = 3\n",
    "            self.nn_dim = 21\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "    \n",
    "        tf.random.set_seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def sampling(self, args):\n",
    "      \n",
    "        latent_dim = 2\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1)\n",
    "\n",
    "        return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "\n",
    "    def vae_loss(self, inp, mask, out, z_log_sigma, z_mean):\n",
    "        masked_input = tf.math.multiply(inp, mask)\n",
    "        masked_output = tf.math.multiply(out, mask)\n",
    "\n",
    "        #mse = np.sum(np.square(np.subtract(masked_output, masked_input))) / np.sum(mask)\n",
    "        mse = K.sum(K.square(masked_output - masked_input)) / K.sum(mask)\n",
    "\n",
    "        reconstruction = mse * self.sequence_length\n",
    "        kl = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "\n",
    "        return reconstruction + kl\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ev9NJEg-58HO"
   },
   "outputs": [],
   "source": [
    "class cnn_vae(vae_model):\n",
    "\n",
    "    def get_model(self):\n",
    "  \n",
    "\n",
    "        self.set_seed(random_seed)\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        inp = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "        mask = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "\n",
    "\n",
    "        conv = tf.keras.layers.Conv1D(filters = self.n_filters, kernel_size = self.kernel_size, activation='relu')(inp)\n",
    "        print(conv.shape)\n",
    "\n",
    "        max_pool = tf.keras.layers.MaxPool1D(pool_size = 2)(conv) \n",
    "\n",
    "        conv = tf.keras.layers.Conv1D(filters = self.n_filters/2, kernel_size = self.kernel_size, activation='relu')(max_pool)\n",
    "        print(conv.shape)\n",
    "\n",
    "        enc = tf.keras.layers.Flatten()(conv)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*8, activation=\"relu\")(enc)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*4, activation=\"relu\")(enc)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*2, activation=\"relu\")(enc)\n",
    "\n",
    "        z = tf.keras.layers.Dense(self.nn_dim, activation=\"relu\")(enc)\n",
    "\n",
    "        z_mean = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "        z_log_sigma = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "\n",
    "        encoder = tf.keras.Model([inp], [z_mean, z_log_sigma])\n",
    "\n",
    "        # decoder\n",
    "\n",
    "        inp_z = tf.keras.Input(shape=(self.latent_dim,))\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim)(inp_z)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*2)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*4)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*8)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Reshape((self.nn_dim, 8))(dec)\n",
    "\n",
    "        deconv = tf.keras.layers.Conv1DTranspose(filters=self.n_filters/2, kernel_size=self.kernel_size)(dec)\n",
    "        print(deconv.shape)\n",
    "\n",
    "        upsample = tf.keras.layers.UpSampling1D(2)(deconv)\n",
    "\n",
    "        deconv = tf.keras.layers.Conv1DTranspose(filters=self.n_features, kernel_size=self.kernel_size)(upsample)\n",
    "        print(deconv.shape)\n",
    "\n",
    "\n",
    "        out = deconv\n",
    "\n",
    "\n",
    "        decoder = tf.keras.Model([inp_z], out) \n",
    "\n",
    "        # encoder and decoder \n",
    "\n",
    "        z_mean, z_log_sigma = encoder([inp])\n",
    "        z = tf.keras.layers.Lambda(self.sampling)([z_mean, z_log_sigma])\n",
    "        pred = decoder([z])\n",
    "\n",
    "        vae = tf.keras.Model([inp,  mask], pred)\n",
    "        vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
    "        vae.compile(loss=None, optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "\n",
    "        return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pwKhQRmD8sWn"
   },
   "outputs": [],
   "source": [
    "def train_eval_vae_model(model, processed_X_train, processed_X_test, train_mask, test_mask, batch_size):\n",
    "  \n",
    "    es = EarlyStopping(patience=2, verbose=1, min_delta=0.001, monitor='loss', mode='auto', restore_best_weights=True)\n",
    "    model.fit([processed_X_train, train_mask], batch_size=batch_size, epochs=15, shuffle=False, callbacks=[es])\n",
    "\n",
    "\n",
    "    vae = tf.keras.Model(model.input, model.output)\n",
    "\n",
    "    reconstruc_train = vae.predict([processed_X_train,  train_mask])\n",
    "    reconstruc_test = vae.predict([processed_X_test, test_mask])\n",
    "\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    #print(mask_X_test_imputed[1])\n",
    "    masked_reconstruction = tf.math.multiply(reconstruc_test, test_mask)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(processed_X_test.shape[0]):\n",
    "        mse += np.sum(np.square(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "        mae += np.sum(np.absolute(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "\n",
    "\n",
    "    print(\"test mse: \", mse / processed_X_test.shape[0])\n",
    "    print(\"test mae: \", mae / processed_X_test.shape[0], \"\\n\")\n",
    "\n",
    "    return model, reconstruc_train, reconstruc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TxadxrVYByDt"
   },
   "outputs": [],
   "source": [
    "def vae_masked_eval(X, vae, batch_size):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "        rand_X_imputed = imputated_data\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        rand_X_imputed = np.where(rand_mask==0, rand_X_imputed, 0)\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            # mse += np.mean(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            # mae += np.mean(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")\n",
    "\n",
    "    return np.mean(mse_list), np.mean(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_vae_mean_imp_eval(X, vae, batch_size, train_feature_means):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    vae_mse_list = []\n",
    "    vae_mae_list = []\n",
    "    \n",
    "    mean_mse_list = []\n",
    "    mean_mae_list = []\n",
    "    \n",
    "    diff_mse_list = []\n",
    "    diff_mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        vae_mse = 0\n",
    "        vae_mae = 0\n",
    "        \n",
    "        mean_mse = 0\n",
    "        mean_mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        \n",
    "        # Performing and evaluating vae imputation\n",
    "        vae_imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        vae_imputated_data = np.where(rand_mask==0, vae_imputated_data, 0)\n",
    "        vae_imputated_data = np.where(np.isnan(X), 0, vae_imputated_data)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            vae_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "            vae_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        vae_mse_list.append(vae_mse / n_samples)\n",
    "        vae_mae_list.append(vae_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Performing and evaluating mean imputation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "        \n",
    "        \n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mean_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mean_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mean_mse_list.append(mean_mse / n_samples)\n",
    "        mean_mae_list.append(mean_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Adding the differences of the mean errors\n",
    "        diff_mse_list.append((vae_mse / n_samples) - (mean_mse / n_samples))\n",
    "        \n",
    "        diff_mae_list.append((vae_mae / n_samples) - (mean_mae / n_samples))\n",
    "        \n",
    "\n",
    "\n",
    "    print(\"vae imputation mse:\")\n",
    "    print(\"mean: \", np.mean(vae_mse_list))\n",
    "    print(\"std dev: \", np.std(vae_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"vae imputation mae:\")\n",
    "    print(\"mean: \", np.mean(vae_mae_list))\n",
    "    print(\"std dev: \", np.std(vae_mae_list), \"\\n\\n\")\n",
    "\n",
    "    \n",
    "    print(\"mean inputation mse:\")\n",
    "    print(\"mean: \", np.mean(mean_mse_list))\n",
    "    print(\"std dev: \", np.std(mean_mse_list), \"\\n\")\n",
    "    \n",
    "    print(\"mean imputation mae:\")\n",
    "    print(\"mean: \", np.mean(mean_mae_list))\n",
    "    print(\"std dev: \", np.std(mean_mae_list), \"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"mean difference in mse:\")\n",
    "    print(\"mean: \", np.mean(diff_mse_list))\n",
    "    print(\"std dev: \", np.std(diff_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"mean difference in mae:\")\n",
    "    print(\"mean: \", np.mean(diff_mae_list))\n",
    "    print(\"std dev: \", np.std(diff_mae_list), \"\\n\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhSubm4Lfm4J",
    "outputId": "6ec47709-e89b-49a3-919b-0ccab91bc5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 44, 32)\n",
      "(None, 18, 16)\n",
      "(None, 22, 16)\n",
      "(None, 48, 48)\n",
      "Epoch 1/15\n",
      "25191/25191 [==============================] - 197s 8ms/step - loss: 36.9781\n",
      "Epoch 2/15\n",
      "25191/25191 [==============================] - 194s 8ms/step - loss: 34.8378\n",
      "Epoch 3/15\n",
      "25191/25191 [==============================] - 198s 8ms/step - loss: 34.6079\n",
      "Epoch 4/15\n",
      "25191/25191 [==============================] - 192s 8ms/step - loss: 34.5127\n",
      "Epoch 5/15\n",
      "25191/25191 [==============================] - 196s 8ms/step - loss: 34.4588\n",
      "Epoch 6/15\n",
      "25191/25191 [==============================] - 198s 8ms/step - loss: 34.4315\n",
      "Epoch 7/15\n",
      "25191/25191 [==============================] - 195s 8ms/step - loss: 34.4084\n",
      "Epoch 8/15\n",
      "25191/25191 [==============================] - 193s 8ms/step - loss: 34.3928\n",
      "Epoch 9/15\n",
      "25191/25191 [==============================] - 195s 8ms/step - loss: 34.3839\n",
      "Epoch 10/15\n",
      "25191/25191 [==============================] - 194s 8ms/step - loss: 34.3696\n",
      "Epoch 11/15\n",
      "25191/25191 [==============================] - 196s 8ms/step - loss: 34.3602\n",
      "Epoch 12/15\n",
      "25191/25191 [==============================] - 196s 8ms/step - loss: 34.3551\n",
      "Epoch 13/15\n",
      "25191/25191 [==============================] - 193s 8ms/step - loss: 34.3459\n",
      "Epoch 14/15\n",
      "25191/25191 [==============================] - 197s 8ms/step - loss: 34.3408\n",
      "Epoch 15/15\n",
      "25191/25191 [==============================] - 195s 8ms/step - loss: 34.3364\n",
      "test mse:  0.551538788195477\n",
      "test mae:  0.3119496610234714 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_vae_instance = cnn_vae(n_filters=32, kernel_size=5, learning_rate=1e-4, \n",
    "                                    sequence_length=48, n_features=48)\n",
    "\n",
    "\n",
    "cnn_vae_model = cnn_vae_instance.get_model()\n",
    "\n",
    "trained_cnn_vae_model, cnn_reconstruc_train, cnn_reconstruc_test = train_eval_vae_model(cnn_vae_model, \n",
    "                                                processed_X_train, processed_X_test, train_mask, test_mask, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae imputation mse:\n",
      "mean:  0.35522188689552586\n",
      "std dev:  0.01788074479380156 \n",
      "\n",
      "vae imputation mae:\n",
      "mean:  0.1666561357788322\n",
      "std dev:  0.00018026073739490223 \n",
      "\n",
      "\n",
      "mean inputation mse:\n",
      "mean:  0.4570872314033485\n",
      "std dev:  0.017777349727852113 \n",
      "\n",
      "mean imputation mae:\n",
      "mean:  0.2206128515931186\n",
      "std dev:  0.00013725610117293054 \n",
      "\n",
      "\n",
      "mean difference in mse:\n",
      "mean:  -0.10186534450782266\n",
      "std dev:  0.0003710734526107327 \n",
      "\n",
      "mean difference in mae:\n",
      "mean:  -0.05395671581428644\n",
      "std dev:  0.00012041794305020245 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paired_vae_mean_imp_eval(X, trained_cnn_vae_model, 1, all_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "ZZ7l1FCGkn69",
    "outputId": "0b8153bc-076a-4620-b57a-9f9a14d6e76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6f9ba05d30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(cnn_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
    "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-dvIbnsBCkG6"
   },
   "outputs": [],
   "source": [
    "def imputed_vae_data(X_train, X_test, reconstruc_train, reconstruc_test):\n",
    "  \n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    # Impute original with reconstruction\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = reconstruc_train[i,j,k]\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = reconstruc_test[i,j,k]\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "\n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_X_train_imputed, cnn_X_test_imputed = imputed_vae_data(X_train, X_test, cnn_reconstruc_train, cnn_reconstruc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "fE44FC8KFaL2"
   },
   "outputs": [],
   "source": [
    "def readm_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    readm_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    readm_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                readm_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                readm_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    readm_y_train = y_train['readmission']\n",
    "    readm_y_test = y_test['readmission']\n",
    "\n",
    "\n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(readm_X_train.shape[0]):\n",
    "        if np.isnan(y_train['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(readm_X_test.shape[0]):\n",
    "        if np.isnan(y_test['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    readm_X_train = np.delete(readm_X_train, rm_idx_train, 0)\n",
    "    readm_y_train = np.delete(np.array(readm_y_train), rm_idx_train, 0)\n",
    "\n",
    "    readm_X_test = np.delete(readm_X_test, rm_idx_test, 0)\n",
    "    readm_y_test = np.delete(np.array(readm_y_test), rm_idx_test, 0)\n",
    "\n",
    "    #print(readm_X_train.shape)\n",
    "    #print(readm_y_train.shape)\n",
    "\n",
    "    #print(readm_X_test.shape)\n",
    "    #print(readm_y_test.shape)\n",
    "\n",
    "    #print(np.where(readm_y_train == 1))\n",
    "    #print(np.where(readm_y_test == 1))  \n",
    "    return readm_X_train, readm_X_test, readm_y_train, readm_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "e9Nk7yYjFk_n"
   },
   "outputs": [],
   "source": [
    "def mortality_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Mortality\n",
    "    mortality_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    mortality_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                mortality_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                mortality_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "    mortality_y_train = y_train['mortality']\n",
    "    mortality_y_test = y_test['mortality']\n",
    "\n",
    "\n",
    "    #print(np.where(mortality_y_train == 1))\n",
    "    #print(np.where(mortality_y_test == 1))\n",
    "    return mortality_X_train, mortality_X_test, mortality_y_train, mortality_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "GNeU2yqMFlHo"
   },
   "outputs": [],
   "source": [
    "def los_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Length of Stay\n",
    "    los_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    los_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                los_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                los_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "                \n",
    "    los_y_train = y_train['length_of_stay']\n",
    "    los_y_test = y_test['length_of_stay']\n",
    "    \n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(los_X_train.shape[0]):\n",
    "        if los_y_train.values[i] < 0:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(los_X_test.shape[0]):\n",
    "        if los_y_test.values[i] < 0:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    los_X_train = np.delete(los_X_train, rm_idx_train, 0)\n",
    "    los_y_train = np.delete(np.array(los_y_train), rm_idx_train, 0)\n",
    "\n",
    "    los_X_test = np.delete(los_X_test, rm_idx_test, 0)\n",
    "    los_y_test = np.delete(np.array(los_y_test), rm_idx_test, 0)\n",
    "    \n",
    "          \n",
    "    los_y_train = (los_y_train - np.full(len(los_y_train), np.mean(los_y_train))) / np.std(los_y_train)\n",
    "    \n",
    "    los_y_test = (los_y_test - np.full(len(los_y_test), np.mean(los_y_test))) / np.std(los_y_test)\n",
    "  \n",
    "\n",
    "    return los_X_train, los_X_test, los_y_train, los_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BmHqSFHGzPk",
    "outputId": "071a96e0-8ffb-4bd6-dbe9-dd8f96ef0342"
   },
   "outputs": [],
   "source": [
    "# Readmission data for each method\n",
    "readm_mean_X_train, readm_mean_X_test, readm_mean_y_train, readm_mean_y_test = readm_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "readm_cnn_X_train, readm_cnn_X_test, readm_cnn_y_train, readm_cnn_y_test = readm_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mortality data for each method\n",
    "mortality_mean_X_train, mortality_mean_X_test, mortality_mean_y_train, mortality_mean_y_test = mortality_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "mortality_cnn_X_train, mortality_cnn_X_test, mortality_cnn_y_train, mortality_cnn_y_test = mortality_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Length of stay data for each method\n",
    "los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test = los_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test = los_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "OPgncEK1QFNV"
   },
   "outputs": [],
   "source": [
    "# LSTM Classification Model\n",
    "\n",
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.0001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "\n",
    "class_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "\n",
    "class_model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.AUC(curve='PR'), \n",
    "                      tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "dfNt7NW2QRXj"
   },
   "outputs": [],
   "source": [
    "# LSTM Regression Model\n",
    "\n",
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.0001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "\n",
    "reg_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='relu'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "reg_model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "_e1K1e2zQWwZ"
   },
   "outputs": [],
   "source": [
    "def train_eval_pred_model(model, batch_size, epochs, X_train, X_test, y_train, y_test):\n",
    "    hist = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[es])\n",
    "    \n",
    "    predictions = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix3RpjX9Q7f5",
    "outputId": "c4ede1ab-8f31-4527-e129-6fe08bb9cc54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7197/7197 - 146s - loss: 0.4583 - auc_4: 0.4890 - auc_5: 0.1590 - precision_2: 0.2058 - recall_2: 0.0220 - val_loss: 0.4297 - val_auc_4: 0.4872 - val_auc_5: 0.1482 - val_precision_2: 0.1667 - val_recall_2: 0.0134 - 146s/epoch - 20ms/step\n",
      "Epoch 2/200\n",
      "7197/7197 - 142s - loss: 0.4480 - auc_4: 0.4942 - auc_5: 0.1602 - precision_2: 0.1453 - recall_2: 0.0075 - val_loss: 0.4256 - val_auc_4: 0.4952 - val_auc_5: 0.1497 - val_precision_2: 0.1500 - val_recall_2: 0.0057 - 142s/epoch - 20ms/step\n",
      "Epoch 3/200\n",
      "7197/7197 - 139s - loss: 0.4439 - auc_4: 0.5031 - auc_5: 0.1620 - precision_2: 0.1538 - recall_2: 0.0035 - val_loss: 0.4225 - val_auc_4: 0.5037 - val_auc_5: 0.1510 - val_precision_2: 0.2857 - val_recall_2: 0.0038 - 139s/epoch - 19ms/step\n",
      "Epoch 4/200\n",
      "7197/7197 - 144s - loss: 0.4412 - auc_4: 0.5121 - auc_5: 0.1642 - precision_2: 0.1600 - recall_2: 0.0018 - val_loss: 0.4206 - val_auc_4: 0.5114 - val_auc_5: 0.1523 - val_precision_2: 0.5000 - val_recall_2: 0.0038 - 144s/epoch - 20ms/step\n",
      "Epoch 5/200\n",
      "7197/7197 - 142s - loss: 0.4394 - auc_4: 0.5215 - auc_5: 0.1673 - precision_2: 0.2000 - recall_2: 0.0013 - val_loss: 0.4189 - val_auc_4: 0.5202 - val_auc_5: 0.1541 - val_precision_2: 0.6667 - val_recall_2: 0.0038 - 142s/epoch - 20ms/step\n",
      "Epoch 6/200\n",
      "7197/7197 - 142s - loss: 0.4380 - auc_4: 0.5298 - auc_5: 0.1702 - precision_2: 0.2000 - recall_2: 8.8106e-04 - val_loss: 0.4184 - val_auc_4: 0.5268 - val_auc_5: 0.1556 - val_precision_2: 1.0000 - val_recall_2: 0.0038 - 142s/epoch - 20ms/step\n",
      "Epoch 7/200\n",
      "7197/7197 - 144s - loss: 0.4371 - auc_4: 0.5357 - auc_5: 0.1724 - precision_2: 0.2500 - recall_2: 8.8106e-04 - val_loss: 0.4175 - val_auc_4: 0.5219 - val_auc_5: 0.1551 - val_precision_2: 1.0000 - val_recall_2: 0.0038 - 144s/epoch - 20ms/step\n",
      "Epoch 8/200\n",
      "7197/7197 - 142s - loss: 0.4363 - auc_4: 0.5409 - auc_5: 0.1747 - precision_2: 0.1667 - recall_2: 4.4053e-04 - val_loss: 0.4169 - val_auc_4: 0.5253 - val_auc_5: 0.1562 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 142s/epoch - 20ms/step\n",
      "Epoch 9/200\n",
      "7197/7197 - 140s - loss: 0.4357 - auc_4: 0.5460 - auc_5: 0.1771 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4163 - val_auc_4: 0.5274 - val_auc_5: 0.1572 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 140s/epoch - 19ms/step\n",
      "Epoch 10/200\n",
      "7197/7197 - 143s - loss: 0.4352 - auc_4: 0.5509 - auc_5: 0.1793 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4162 - val_auc_4: 0.5279 - val_auc_5: 0.1582 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 143s/epoch - 20ms/step\n",
      "Epoch 11/200\n",
      "7197/7197 - 142s - loss: 0.4348 - auc_4: 0.5533 - auc_5: 0.1810 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4157 - val_auc_4: 0.5319 - val_auc_5: 0.1596 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 142s/epoch - 20ms/step\n",
      "Epoch 12/200\n",
      "7197/7197 - 144s - loss: 0.4344 - auc_4: 0.5575 - auc_5: 0.1830 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4154 - val_auc_4: 0.5324 - val_auc_5: 0.1591 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 144s/epoch - 20ms/step\n",
      "Epoch 13/200\n",
      "7197/7197 - 142s - loss: 0.4341 - auc_4: 0.5584 - auc_5: 0.1842 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4151 - val_auc_4: 0.5343 - val_auc_5: 0.1598 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 142s/epoch - 20ms/step\n",
      "Epoch 14/200\n",
      "7197/7197 - 143s - loss: 0.4338 - auc_4: 0.5608 - auc_5: 0.1854 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4150 - val_auc_4: 0.5331 - val_auc_5: 0.1599 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 143s/epoch - 20ms/step\n",
      "Epoch 15/200\n",
      "7197/7197 - 143s - loss: 0.4336 - auc_4: 0.5641 - auc_5: 0.1874 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4149 - val_auc_4: 0.5332 - val_auc_5: 0.1606 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 143s/epoch - 20ms/step\n",
      "Epoch 16/200\n",
      "7197/7197 - 143s - loss: 0.4333 - auc_4: 0.5650 - auc_5: 0.1880 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4149 - val_auc_4: 0.5361 - val_auc_5: 0.1617 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 143s/epoch - 20ms/step\n",
      "Epoch 17/200\n",
      "7197/7197 - 143s - loss: 0.4332 - auc_4: 0.5644 - auc_5: 0.1885 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4148 - val_auc_4: 0.5342 - val_auc_5: 0.1618 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 143s/epoch - 20ms/step\n",
      "Epoch 18/200\n",
      "7197/7197 - 143s - loss: 0.4330 - auc_4: 0.5656 - auc_5: 0.1895 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4146 - val_auc_4: 0.5364 - val_auc_5: 0.1628 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 19/200\n",
      "7197/7197 - 144s - loss: 0.4328 - auc_4: 0.5681 - auc_5: 0.1908 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4144 - val_auc_4: 0.5367 - val_auc_5: 0.1630 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 20/200\n",
      "7197/7197 - 143s - loss: 0.4327 - auc_4: 0.5692 - auc_5: 0.1914 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4145 - val_auc_4: 0.5375 - val_auc_5: 0.1637 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 21/200\n",
      "7197/7197 - 144s - loss: 0.4325 - auc_4: 0.5692 - auc_5: 0.1921 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4143 - val_auc_4: 0.5408 - val_auc_5: 0.1646 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 22/200\n",
      "7197/7197 - 143s - loss: 0.4324 - auc_4: 0.5684 - auc_5: 0.1923 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4144 - val_auc_4: 0.5371 - val_auc_5: 0.1641 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 23/200\n",
      "7197/7197 - 144s - loss: 0.4323 - auc_4: 0.5710 - auc_5: 0.1936 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4140 - val_auc_4: 0.5369 - val_auc_5: 0.1637 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 24/200\n",
      "7197/7197 - 144s - loss: 0.4322 - auc_4: 0.5702 - auc_5: 0.1937 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4140 - val_auc_4: 0.5381 - val_auc_5: 0.1642 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 25/200\n",
      "7197/7197 - 144s - loss: 0.4321 - auc_4: 0.5720 - auc_5: 0.1948 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4140 - val_auc_4: 0.5410 - val_auc_5: 0.1656 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 26/200\n",
      "7197/7197 - 142s - loss: 0.4319 - auc_4: 0.5717 - auc_5: 0.1950 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4141 - val_auc_4: 0.5423 - val_auc_5: 0.1660 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 27/200\n",
      "7197/7197 - 144s - loss: 0.4318 - auc_4: 0.5729 - auc_5: 0.1959 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4137 - val_auc_4: 0.5428 - val_auc_5: 0.1664 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 28/200\n",
      "7197/7197 - 142s - loss: 0.4317 - auc_4: 0.5738 - auc_5: 0.1962 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4137 - val_auc_4: 0.5415 - val_auc_5: 0.1656 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 29/200\n",
      "7197/7197 - 144s - loss: 0.4316 - auc_4: 0.5752 - auc_5: 0.1970 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4136 - val_auc_4: 0.5417 - val_auc_5: 0.1661 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 30/200\n",
      "7197/7197 - 142s - loss: 0.4315 - auc_4: 0.5740 - auc_5: 0.1969 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4137 - val_auc_4: 0.5440 - val_auc_5: 0.1670 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 31/200\n",
      "7197/7197 - 143s - loss: 0.4314 - auc_4: 0.5763 - auc_5: 0.1980 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4139 - val_auc_4: 0.5418 - val_auc_5: 0.1661 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 32/200\n",
      "7197/7197 - 142s - loss: 0.4313 - auc_4: 0.5776 - auc_5: 0.1986 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4137 - val_auc_4: 0.5425 - val_auc_5: 0.1665 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 33/200\n",
      "7197/7197 - 143s - loss: 0.4311 - auc_4: 0.5788 - auc_5: 0.1989 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4133 - val_auc_4: 0.5423 - val_auc_5: 0.1664 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 34/200\n",
      "7197/7197 - 137s - loss: 0.4311 - auc_4: 0.5783 - auc_5: 0.1993 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4136 - val_auc_4: 0.5427 - val_auc_5: 0.1668 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 35/200\n",
      "7197/7197 - 136s - loss: 0.4310 - auc_4: 0.5778 - auc_5: 0.1996 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4135 - val_auc_4: 0.5422 - val_auc_5: 0.1665 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 36/200\n",
      "7197/7197 - 135s - loss: 0.4308 - auc_4: 0.5797 - auc_5: 0.2005 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4133 - val_auc_4: 0.5475 - val_auc_5: 0.1677 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 37/200\n",
      "7197/7197 - 136s - loss: 0.4307 - auc_4: 0.5781 - auc_5: 0.2006 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4134 - val_auc_4: 0.5443 - val_auc_5: 0.1672 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 38/200\n",
      "7197/7197 - 135s - loss: 0.4306 - auc_4: 0.5809 - auc_5: 0.2011 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4132 - val_auc_4: 0.5508 - val_auc_5: 0.1689 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 39/200\n",
      "7197/7197 - 137s - loss: 0.4305 - auc_4: 0.5809 - auc_5: 0.2019 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4132 - val_auc_4: 0.5467 - val_auc_5: 0.1681 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 40/200\n",
      "7197/7197 - 136s - loss: 0.4304 - auc_4: 0.5838 - auc_5: 0.2027 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4131 - val_auc_4: 0.5492 - val_auc_5: 0.1687 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 41/200\n",
      "7197/7197 - 138s - loss: 0.4302 - auc_4: 0.5840 - auc_5: 0.2030 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4129 - val_auc_4: 0.5473 - val_auc_5: 0.1681 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 138s/epoch - 19ms/step\n",
      "Epoch 42/200\n",
      "7197/7197 - 141s - loss: 0.4302 - auc_4: 0.5835 - auc_5: 0.2032 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4132 - val_auc_4: 0.5491 - val_auc_5: 0.1692 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 141s/epoch - 20ms/step\n",
      "Epoch 43/200\n",
      "7197/7197 - 135s - loss: 0.4301 - auc_4: 0.5858 - auc_5: 0.2037 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4133 - val_auc_4: 0.5482 - val_auc_5: 0.1689 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 44/200\n",
      "7197/7197 - 139s - loss: 0.4299 - auc_4: 0.5855 - auc_5: 0.2043 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4131 - val_auc_4: 0.5501 - val_auc_5: 0.1694 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 139s/epoch - 19ms/step\n",
      "Epoch 45/200\n",
      "7197/7197 - 139s - loss: 0.4298 - auc_4: 0.5861 - auc_5: 0.2050 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4127 - val_auc_4: 0.5512 - val_auc_5: 0.1698 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 139s/epoch - 19ms/step\n",
      "Epoch 46/200\n",
      "7197/7197 - 140s - loss: 0.4296 - auc_4: 0.5869 - auc_5: 0.2054 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4132 - val_auc_4: 0.5495 - val_auc_5: 0.1698 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 140s/epoch - 19ms/step\n",
      "Epoch 47/200\n",
      "7197/7197 - 145s - loss: 0.4296 - auc_4: 0.5859 - auc_5: 0.2052 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4128 - val_auc_4: 0.5509 - val_auc_5: 0.1696 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 48/200\n",
      "7197/7197 - 139s - loss: 0.4294 - auc_4: 0.5883 - auc_5: 0.2062 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4127 - val_auc_4: 0.5503 - val_auc_5: 0.1697 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 139s/epoch - 19ms/step\n",
      "Epoch 49/200\n",
      "7197/7197 - 141s - loss: 0.4293 - auc_4: 0.5894 - auc_5: 0.2071 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4129 - val_auc_4: 0.5525 - val_auc_5: 0.1703 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 141s/epoch - 20ms/step\n",
      "Epoch 50/200\n",
      "7197/7197 - 138s - loss: 0.4292 - auc_4: 0.5903 - auc_5: 0.2078 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4126 - val_auc_4: 0.5508 - val_auc_5: 0.1700 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 138s/epoch - 19ms/step\n",
      "Epoch 51/200\n",
      "7197/7197 - 137s - loss: 0.4290 - auc_4: 0.5906 - auc_5: 0.2081 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4128 - val_auc_4: 0.5527 - val_auc_5: 0.1710 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 52/200\n",
      "7197/7197 - 137s - loss: 0.4289 - auc_4: 0.5927 - auc_5: 0.2086 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4123 - val_auc_4: 0.5542 - val_auc_5: 0.1709 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 53/200\n",
      "7197/7197 - 137s - loss: 0.4288 - auc_4: 0.5921 - auc_5: 0.2089 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4121 - val_auc_4: 0.5519 - val_auc_5: 0.1699 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 54/200\n",
      "7197/7197 - 137s - loss: 0.4286 - auc_4: 0.5933 - auc_5: 0.2094 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4124 - val_auc_4: 0.5527 - val_auc_5: 0.1706 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 55/200\n",
      "7197/7197 - 142s - loss: 0.4285 - auc_4: 0.5952 - auc_5: 0.2102 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4122 - val_auc_4: 0.5542 - val_auc_5: 0.1711 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 56/200\n",
      "7197/7197 - 143s - loss: 0.4284 - auc_4: 0.5938 - auc_5: 0.2104 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4123 - val_auc_4: 0.5555 - val_auc_5: 0.1719 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 57/200\n",
      "7197/7197 - 137s - loss: 0.4282 - auc_4: 0.5971 - auc_5: 0.2115 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4123 - val_auc_4: 0.5553 - val_auc_5: 0.1716 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 58/200\n",
      "7197/7197 - 135s - loss: 0.4281 - auc_4: 0.5955 - auc_5: 0.2115 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4121 - val_auc_4: 0.5550 - val_auc_5: 0.1716 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 59/200\n",
      "7197/7197 - 139s - loss: 0.4280 - auc_4: 0.5969 - auc_5: 0.2125 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4118 - val_auc_4: 0.5554 - val_auc_5: 0.1716 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 139s/epoch - 19ms/step\n",
      "Epoch 60/200\n",
      "7197/7197 - 136s - loss: 0.4278 - auc_4: 0.5983 - auc_5: 0.2131 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4116 - val_auc_4: 0.5575 - val_auc_5: 0.1719 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 61/200\n",
      "7197/7197 - 137s - loss: 0.4277 - auc_4: 0.5999 - auc_5: 0.2132 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4123 - val_auc_4: 0.5547 - val_auc_5: 0.1719 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 62/200\n",
      "7197/7197 - 144s - loss: 0.4276 - auc_4: 0.5992 - auc_5: 0.2135 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4118 - val_auc_4: 0.5562 - val_auc_5: 0.1724 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 63/200\n",
      "7197/7197 - 136s - loss: 0.4274 - auc_4: 0.6004 - auc_5: 0.2138 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4121 - val_auc_4: 0.5571 - val_auc_5: 0.1728 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 64/200\n",
      "7197/7197 - 135s - loss: 0.4273 - auc_4: 0.6010 - auc_5: 0.2144 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4116 - val_auc_4: 0.5574 - val_auc_5: 0.1723 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 65/200\n",
      "7197/7197 - 136s - loss: 0.4271 - auc_4: 0.6028 - auc_5: 0.2151 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4122 - val_auc_4: 0.5572 - val_auc_5: 0.1729 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 136s/epoch - 19ms/step\n",
      "Epoch 66/200\n",
      "7197/7197 - 135s - loss: 0.4270 - auc_4: 0.6022 - auc_5: 0.2149 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4120 - val_auc_4: 0.5568 - val_auc_5: 0.1726 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 135s/epoch - 19ms/step\n",
      "Epoch 67/200\n",
      "7197/7197 - 138s - loss: 0.4269 - auc_4: 0.6026 - auc_5: 0.2154 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4118 - val_auc_4: 0.5573 - val_auc_5: 0.1732 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 138s/epoch - 19ms/step\n",
      "Epoch 68/200\n",
      "7197/7197 - 138s - loss: 0.4267 - auc_4: 0.6034 - auc_5: 0.2159 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4118 - val_auc_4: 0.5572 - val_auc_5: 0.1734 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 138s/epoch - 19ms/step\n",
      "Epoch 69/200\n",
      "7197/7197 - 137s - loss: 0.4266 - auc_4: 0.6044 - auc_5: 0.2165 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4116 - val_auc_4: 0.5595 - val_auc_5: 0.1736 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 137s/epoch - 19ms/step\n",
      "Epoch 70/200\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "7197/7197 - 138s - loss: 0.4265 - auc_4: 0.6053 - auc_5: 0.2172 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.4117 - val_auc_4: 0.5593 - val_auc_5: 0.1738 - val_precision_2: 1.0000 - val_recall_2: 0.0019 - 138s/epoch - 19ms/step\n",
      "Epoch 70: early stopping\n",
      "2253/2253 [==============================] - 26s 11ms/step - loss: 0.4084 - auc_4: 0.5902 - auc_5: 0.1828 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Mean Imputation\n",
    "mean_readm_model, mean_readm_preds = train_eval_pred_model(class_model, 2, 200, readm_mean_X_train, readm_mean_X_test,\n",
    "                                                      readm_mean_y_train, readm_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75982242 0.0954495 ]\n",
      " [0.11942286 0.02530522]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(readm_mean_y_test, np.where(mean_readm_preds < 0.2, 0, 1)) / len(readm_mean_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10076/10076 - 183s - loss: 0.2963 - auc_4: 0.6805 - auc_5: 0.2028 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 0.2899 - val_auc_4: 0.7555 - val_auc_5: 0.2741 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - 183s/epoch - 18ms/step\n",
      "Epoch 2/200\n",
      "10076/10076 - 182s - loss: 0.2760 - auc_4: 0.7880 - auc_5: 0.2863 - precision_2: 0.4068 - recall_2: 0.0125 - val_loss: 0.2794 - val_auc_4: 0.7907 - val_auc_5: 0.3084 - val_precision_2: 0.7241 - val_recall_2: 0.0424 - 182s/epoch - 18ms/step\n",
      "Epoch 3/200\n",
      "10076/10076 - 183s - loss: 0.2674 - auc_4: 0.8016 - auc_5: 0.3089 - precision_2: 0.4921 - recall_2: 0.0490 - val_loss: 0.2732 - val_auc_4: 0.7977 - val_auc_5: 0.3239 - val_precision_2: 0.5833 - val_recall_2: 0.0707 - 183s/epoch - 18ms/step\n",
      "Epoch 4/200\n",
      "10076/10076 - 183s - loss: 0.2615 - auc_4: 0.8071 - auc_5: 0.3223 - precision_2: 0.4915 - recall_2: 0.0751 - val_loss: 0.2683 - val_auc_4: 0.8026 - val_auc_5: 0.3355 - val_precision_2: 0.5455 - val_recall_2: 0.0848 - 183s/epoch - 18ms/step\n",
      "Epoch 5/200\n",
      "10076/10076 - 182s - loss: 0.2567 - auc_4: 0.8124 - auc_5: 0.3358 - precision_2: 0.5000 - recall_2: 0.0907 - val_loss: 0.2641 - val_auc_4: 0.8065 - val_auc_5: 0.3459 - val_precision_2: 0.5213 - val_recall_2: 0.0990 - 182s/epoch - 18ms/step\n",
      "Epoch 6/200\n",
      "10076/10076 - 182s - loss: 0.2526 - auc_4: 0.8162 - auc_5: 0.3470 - precision_2: 0.5258 - recall_2: 0.1116 - val_loss: 0.2607 - val_auc_4: 0.8091 - val_auc_5: 0.3556 - val_precision_2: 0.5243 - val_recall_2: 0.1091 - 182s/epoch - 18ms/step\n",
      "Epoch 7/200\n",
      "10076/10076 - 182s - loss: 0.2492 - auc_4: 0.8185 - auc_5: 0.3573 - precision_2: 0.5381 - recall_2: 0.1288 - val_loss: 0.2576 - val_auc_4: 0.8122 - val_auc_5: 0.3649 - val_precision_2: 0.5234 - val_recall_2: 0.1131 - 182s/epoch - 18ms/step\n",
      "Epoch 8/200\n",
      "10076/10076 - 182s - loss: 0.2464 - auc_4: 0.8220 - auc_5: 0.3675 - precision_2: 0.5401 - recall_2: 0.1335 - val_loss: 0.2549 - val_auc_4: 0.8144 - val_auc_5: 0.3740 - val_precision_2: 0.5221 - val_recall_2: 0.1192 - 182s/epoch - 18ms/step\n",
      "Epoch 9/200\n",
      "10076/10076 - 182s - loss: 0.2440 - auc_4: 0.8250 - auc_5: 0.3777 - precision_2: 0.5545 - recall_2: 0.1460 - val_loss: 0.2528 - val_auc_4: 0.8165 - val_auc_5: 0.3826 - val_precision_2: 0.5217 - val_recall_2: 0.1212 - 182s/epoch - 18ms/step\n",
      "Epoch 10/200\n",
      "10076/10076 - 182s - loss: 0.2421 - auc_4: 0.8271 - auc_5: 0.3879 - precision_2: 0.5536 - recall_2: 0.1455 - val_loss: 0.2510 - val_auc_4: 0.8182 - val_auc_5: 0.3875 - val_precision_2: 0.5126 - val_recall_2: 0.1232 - 182s/epoch - 18ms/step\n",
      "Epoch 11/200\n",
      "10076/10076 - 182s - loss: 0.2406 - auc_4: 0.8293 - auc_5: 0.3952 - precision_2: 0.5584 - recall_2: 0.1569 - val_loss: 0.2496 - val_auc_4: 0.8205 - val_auc_5: 0.3946 - val_precision_2: 0.5440 - val_recall_2: 0.1374 - 182s/epoch - 18ms/step\n",
      "Epoch 12/200\n",
      "10076/10076 - 182s - loss: 0.2392 - auc_4: 0.8313 - auc_5: 0.4025 - precision_2: 0.5671 - recall_2: 0.1564 - val_loss: 0.2481 - val_auc_4: 0.8219 - val_auc_5: 0.4007 - val_precision_2: 0.5344 - val_recall_2: 0.1414 - 182s/epoch - 18ms/step\n",
      "Epoch 13/200\n",
      "10076/10076 - 182s - loss: 0.2380 - auc_4: 0.8329 - auc_5: 0.4083 - precision_2: 0.5668 - recall_2: 0.1637 - val_loss: 0.2469 - val_auc_4: 0.8233 - val_auc_5: 0.4080 - val_precision_2: 0.5481 - val_recall_2: 0.1495 - 182s/epoch - 18ms/step\n",
      "Epoch 14/200\n",
      "10076/10076 - 183s - loss: 0.2370 - auc_4: 0.8341 - auc_5: 0.4151 - precision_2: 0.5740 - recall_2: 0.1679 - val_loss: 0.2458 - val_auc_4: 0.8241 - val_auc_5: 0.4121 - val_precision_2: 0.5522 - val_recall_2: 0.1495 - 183s/epoch - 18ms/step\n",
      "Epoch 15/200\n",
      "10076/10076 - 180s - loss: 0.2361 - auc_4: 0.8351 - auc_5: 0.4198 - precision_2: 0.5858 - recall_2: 0.1726 - val_loss: 0.2448 - val_auc_4: 0.8257 - val_auc_5: 0.4168 - val_precision_2: 0.5597 - val_recall_2: 0.1515 - 180s/epoch - 18ms/step\n",
      "Epoch 16/200\n",
      "10076/10076 - 180s - loss: 0.2352 - auc_4: 0.8370 - auc_5: 0.4246 - precision_2: 0.5936 - recall_2: 0.1752 - val_loss: 0.2438 - val_auc_4: 0.8260 - val_auc_5: 0.4205 - val_precision_2: 0.5564 - val_recall_2: 0.1495 - 180s/epoch - 18ms/step\n",
      "Epoch 17/200\n",
      "10076/10076 - 182s - loss: 0.2345 - auc_4: 0.8371 - auc_5: 0.4291 - precision_2: 0.5997 - recall_2: 0.1804 - val_loss: 0.2430 - val_auc_4: 0.8274 - val_auc_5: 0.4244 - val_precision_2: 0.5662 - val_recall_2: 0.1556 - 182s/epoch - 18ms/step\n",
      "Epoch 18/200\n",
      "10076/10076 - 181s - loss: 0.2336 - auc_4: 0.8382 - auc_5: 0.4336 - precision_2: 0.5955 - recall_2: 0.1919 - val_loss: 0.2424 - val_auc_4: 0.8286 - val_auc_5: 0.4272 - val_precision_2: 0.5865 - val_recall_2: 0.1576 - 181s/epoch - 18ms/step\n",
      "Epoch 19/200\n",
      "10076/10076 - 183s - loss: 0.2330 - auc_4: 0.8392 - auc_5: 0.4376 - precision_2: 0.5974 - recall_2: 0.1887 - val_loss: 0.2414 - val_auc_4: 0.8305 - val_auc_5: 0.4323 - val_precision_2: 0.5797 - val_recall_2: 0.1616 - 183s/epoch - 18ms/step\n",
      "Epoch 20/200\n",
      "10076/10076 - 182s - loss: 0.2323 - auc_4: 0.8404 - auc_5: 0.4419 - precision_2: 0.6089 - recall_2: 0.1997 - val_loss: 0.2407 - val_auc_4: 0.8307 - val_auc_5: 0.4367 - val_precision_2: 0.6143 - val_recall_2: 0.1737 - 182s/epoch - 18ms/step\n",
      "Epoch 21/200\n",
      "10076/10076 - 181s - loss: 0.2315 - auc_4: 0.8428 - auc_5: 0.4463 - precision_2: 0.6127 - recall_2: 0.2013 - val_loss: 0.2401 - val_auc_4: 0.8320 - val_auc_5: 0.4386 - val_precision_2: 0.6143 - val_recall_2: 0.1737 - 181s/epoch - 18ms/step\n",
      "Epoch 22/200\n",
      "10076/10076 - 180s - loss: 0.2309 - auc_4: 0.8444 - auc_5: 0.4509 - precision_2: 0.6176 - recall_2: 0.2122 - val_loss: 0.2395 - val_auc_4: 0.8344 - val_auc_5: 0.4421 - val_precision_2: 0.6197 - val_recall_2: 0.1778 - 180s/epoch - 18ms/step\n",
      "Epoch 23/200\n",
      "10076/10076 - 181s - loss: 0.2303 - auc_4: 0.8445 - auc_5: 0.4542 - precision_2: 0.6270 - recall_2: 0.2278 - val_loss: 0.2387 - val_auc_4: 0.8344 - val_auc_5: 0.4468 - val_precision_2: 0.6181 - val_recall_2: 0.1798 - 181s/epoch - 18ms/step\n",
      "Epoch 24/200\n",
      "10076/10076 - 182s - loss: 0.2297 - auc_4: 0.8455 - auc_5: 0.4587 - precision_2: 0.6327 - recall_2: 0.2263 - val_loss: 0.2380 - val_auc_4: 0.8354 - val_auc_5: 0.4515 - val_precision_2: 0.6291 - val_recall_2: 0.1919 - 182s/epoch - 18ms/step\n",
      "Epoch 25/200\n",
      "10076/10076 - 182s - loss: 0.2290 - auc_4: 0.8472 - auc_5: 0.4624 - precision_2: 0.6437 - recall_2: 0.2336 - val_loss: 0.2373 - val_auc_4: 0.8358 - val_auc_5: 0.4569 - val_precision_2: 0.6266 - val_recall_2: 0.2000 - 182s/epoch - 18ms/step\n",
      "Epoch 26/200\n",
      "10076/10076 - 182s - loss: 0.2284 - auc_4: 0.8479 - auc_5: 0.4673 - precision_2: 0.6448 - recall_2: 0.2508 - val_loss: 0.2366 - val_auc_4: 0.8369 - val_auc_5: 0.4605 - val_precision_2: 0.6258 - val_recall_2: 0.1960 - 182s/epoch - 18ms/step\n",
      "Epoch 27/200\n",
      "10076/10076 - 182s - loss: 0.2277 - auc_4: 0.8485 - auc_5: 0.4706 - precision_2: 0.6499 - recall_2: 0.2487 - val_loss: 0.2360 - val_auc_4: 0.8387 - val_auc_5: 0.4641 - val_precision_2: 0.6266 - val_recall_2: 0.2000 - 182s/epoch - 18ms/step\n",
      "Epoch 28/200\n",
      "10076/10076 - 183s - loss: 0.2271 - auc_4: 0.8500 - auc_5: 0.4750 - precision_2: 0.6538 - recall_2: 0.2560 - val_loss: 0.2353 - val_auc_4: 0.8403 - val_auc_5: 0.4680 - val_precision_2: 0.6266 - val_recall_2: 0.2000 - 183s/epoch - 18ms/step\n",
      "Epoch 29/200\n",
      "10076/10076 - 183s - loss: 0.2263 - auc_4: 0.8509 - auc_5: 0.4796 - precision_2: 0.6598 - recall_2: 0.2680 - val_loss: 0.2350 - val_auc_4: 0.8426 - val_auc_5: 0.4702 - val_precision_2: 0.6346 - val_recall_2: 0.2000 - 183s/epoch - 18ms/step\n",
      "Epoch 30/200\n",
      "10076/10076 - 183s - loss: 0.2258 - auc_4: 0.8520 - auc_5: 0.4831 - precision_2: 0.6693 - recall_2: 0.2628 - val_loss: 0.2341 - val_auc_4: 0.8436 - val_auc_5: 0.4753 - val_precision_2: 0.6429 - val_recall_2: 0.2182 - 183s/epoch - 18ms/step\n",
      "Epoch 31/200\n",
      "10076/10076 - 181s - loss: 0.2251 - auc_4: 0.8534 - auc_5: 0.4869 - precision_2: 0.6654 - recall_2: 0.2727 - val_loss: 0.2334 - val_auc_4: 0.8451 - val_auc_5: 0.4799 - val_precision_2: 0.6592 - val_recall_2: 0.2384 - 181s/epoch - 18ms/step\n",
      "Epoch 32/200\n",
      "10076/10076 - 182s - loss: 0.2244 - auc_4: 0.8554 - auc_5: 0.4907 - precision_2: 0.6671 - recall_2: 0.2779 - val_loss: 0.2328 - val_auc_4: 0.8454 - val_auc_5: 0.4838 - val_precision_2: 0.6543 - val_recall_2: 0.2485 - 182s/epoch - 18ms/step\n",
      "Epoch 33/200\n",
      "10076/10076 - 183s - loss: 0.2237 - auc_4: 0.8562 - auc_5: 0.4960 - precision_2: 0.6614 - recall_2: 0.2842 - val_loss: 0.2321 - val_auc_4: 0.8468 - val_auc_5: 0.4871 - val_precision_2: 0.6703 - val_recall_2: 0.2505 - 183s/epoch - 18ms/step\n",
      "Epoch 34/200\n",
      "10076/10076 - 182s - loss: 0.2230 - auc_4: 0.8569 - auc_5: 0.4990 - precision_2: 0.6735 - recall_2: 0.2914 - val_loss: 0.2314 - val_auc_4: 0.8495 - val_auc_5: 0.4910 - val_precision_2: 0.6774 - val_recall_2: 0.2545 - 182s/epoch - 18ms/step\n",
      "Epoch 35/200\n",
      "10076/10076 - 182s - loss: 0.2223 - auc_4: 0.8590 - auc_5: 0.5032 - precision_2: 0.6742 - recall_2: 0.2946 - val_loss: 0.2310 - val_auc_4: 0.8505 - val_auc_5: 0.4936 - val_precision_2: 0.6865 - val_recall_2: 0.2566 - 182s/epoch - 18ms/step\n",
      "Epoch 36/200\n",
      "10076/10076 - 181s - loss: 0.2216 - auc_4: 0.8600 - auc_5: 0.5063 - precision_2: 0.6778 - recall_2: 0.2972 - val_loss: 0.2303 - val_auc_4: 0.8504 - val_auc_5: 0.4977 - val_precision_2: 0.6915 - val_recall_2: 0.2626 - 181s/epoch - 18ms/step\n",
      "Epoch 37/200\n",
      "10076/10076 - 182s - loss: 0.2207 - auc_4: 0.8610 - auc_5: 0.5109 - precision_2: 0.6779 - recall_2: 0.3029 - val_loss: 0.2294 - val_auc_4: 0.8519 - val_auc_5: 0.5044 - val_precision_2: 0.6857 - val_recall_2: 0.2909 - 182s/epoch - 18ms/step\n",
      "Epoch 38/200\n",
      "10076/10076 - 182s - loss: 0.2201 - auc_4: 0.8629 - auc_5: 0.5150 - precision_2: 0.6742 - recall_2: 0.3128 - val_loss: 0.2289 - val_auc_4: 0.8532 - val_auc_5: 0.5053 - val_precision_2: 0.6872 - val_recall_2: 0.2707 - 182s/epoch - 18ms/step\n",
      "Epoch 39/200\n",
      "10076/10076 - 182s - loss: 0.2194 - auc_4: 0.8631 - auc_5: 0.5177 - precision_2: 0.6874 - recall_2: 0.3107 - val_loss: 0.2281 - val_auc_4: 0.8545 - val_auc_5: 0.5102 - val_precision_2: 0.6930 - val_recall_2: 0.3010 - 182s/epoch - 18ms/step\n",
      "Epoch 40/200\n",
      "10076/10076 - 182s - loss: 0.2187 - auc_4: 0.8646 - auc_5: 0.5203 - precision_2: 0.6860 - recall_2: 0.3201 - val_loss: 0.2274 - val_auc_4: 0.8566 - val_auc_5: 0.5153 - val_precision_2: 0.6991 - val_recall_2: 0.3051 - 182s/epoch - 18ms/step\n",
      "Epoch 41/200\n",
      "10076/10076 - 181s - loss: 0.2180 - auc_4: 0.8658 - auc_5: 0.5247 - precision_2: 0.6847 - recall_2: 0.3227 - val_loss: 0.2267 - val_auc_4: 0.8577 - val_auc_5: 0.5186 - val_precision_2: 0.7032 - val_recall_2: 0.3111 - 181s/epoch - 18ms/step\n",
      "Epoch 42/200\n",
      "10076/10076 - 183s - loss: 0.2172 - auc_4: 0.8674 - auc_5: 0.5278 - precision_2: 0.6954 - recall_2: 0.3238 - val_loss: 0.2261 - val_auc_4: 0.8586 - val_auc_5: 0.5233 - val_precision_2: 0.6923 - val_recall_2: 0.3273 - 183s/epoch - 18ms/step\n",
      "Epoch 43/200\n",
      "10076/10076 - 183s - loss: 0.2164 - auc_4: 0.8680 - auc_5: 0.5312 - precision_2: 0.6968 - recall_2: 0.3295 - val_loss: 0.2253 - val_auc_4: 0.8599 - val_auc_5: 0.5256 - val_precision_2: 0.6822 - val_recall_2: 0.3253 - 183s/epoch - 18ms/step\n",
      "Epoch 44/200\n",
      "10076/10076 - 183s - loss: 0.2157 - auc_4: 0.8700 - auc_5: 0.5344 - precision_2: 0.6886 - recall_2: 0.3389 - val_loss: 0.2249 - val_auc_4: 0.8615 - val_auc_5: 0.5264 - val_precision_2: 0.7023 - val_recall_2: 0.3051 - 183s/epoch - 18ms/step\n",
      "Epoch 45/200\n",
      "10076/10076 - 182s - loss: 0.2150 - auc_4: 0.8708 - auc_5: 0.5372 - precision_2: 0.7056 - recall_2: 0.3337 - val_loss: 0.2240 - val_auc_4: 0.8615 - val_auc_5: 0.5320 - val_precision_2: 0.6907 - val_recall_2: 0.3293 - 182s/epoch - 18ms/step\n",
      "Epoch 46/200\n",
      "10076/10076 - 184s - loss: 0.2142 - auc_4: 0.8721 - auc_5: 0.5414 - precision_2: 0.7026 - recall_2: 0.3399 - val_loss: 0.2236 - val_auc_4: 0.8634 - val_auc_5: 0.5356 - val_precision_2: 0.6877 - val_recall_2: 0.3515 - 184s/epoch - 18ms/step\n",
      "Epoch 47/200\n",
      "10076/10076 - 183s - loss: 0.2135 - auc_4: 0.8733 - auc_5: 0.5437 - precision_2: 0.6921 - recall_2: 0.3457 - val_loss: 0.2227 - val_auc_4: 0.8656 - val_auc_5: 0.5364 - val_precision_2: 0.6957 - val_recall_2: 0.3232 - 183s/epoch - 18ms/step\n",
      "Epoch 48/200\n",
      "10076/10076 - 183s - loss: 0.2127 - auc_4: 0.8742 - auc_5: 0.5469 - precision_2: 0.6968 - recall_2: 0.3415 - val_loss: 0.2220 - val_auc_4: 0.8651 - val_auc_5: 0.5397 - val_precision_2: 0.6971 - val_recall_2: 0.3394 - 183s/epoch - 18ms/step\n",
      "Epoch 49/200\n",
      "10076/10076 - 183s - loss: 0.2121 - auc_4: 0.8758 - auc_5: 0.5504 - precision_2: 0.7020 - recall_2: 0.3452 - val_loss: 0.2214 - val_auc_4: 0.8666 - val_auc_5: 0.5418 - val_precision_2: 0.6949 - val_recall_2: 0.3313 - 183s/epoch - 18ms/step\n",
      "Epoch 50/200\n",
      "10076/10076 - 184s - loss: 0.2114 - auc_4: 0.8761 - auc_5: 0.5518 - precision_2: 0.7061 - recall_2: 0.3457 - val_loss: 0.2208 - val_auc_4: 0.8668 - val_auc_5: 0.5463 - val_precision_2: 0.6923 - val_recall_2: 0.3455 - 184s/epoch - 18ms/step\n",
      "Epoch 51/200\n",
      "10076/10076 - 183s - loss: 0.2108 - auc_4: 0.8768 - auc_5: 0.5550 - precision_2: 0.7020 - recall_2: 0.3525 - val_loss: 0.2204 - val_auc_4: 0.8691 - val_auc_5: 0.5464 - val_precision_2: 0.7009 - val_recall_2: 0.3313 - 183s/epoch - 18ms/step\n",
      "Epoch 52/200\n",
      "10076/10076 - 185s - loss: 0.2101 - auc_4: 0.8779 - auc_5: 0.5580 - precision_2: 0.7080 - recall_2: 0.3452 - val_loss: 0.2196 - val_auc_4: 0.8699 - val_auc_5: 0.5488 - val_precision_2: 0.6929 - val_recall_2: 0.3374 - 185s/epoch - 18ms/step\n",
      "Epoch 53/200\n",
      "10076/10076 - 185s - loss: 0.2095 - auc_4: 0.8787 - auc_5: 0.5600 - precision_2: 0.7086 - recall_2: 0.3498 - val_loss: 0.2190 - val_auc_4: 0.8698 - val_auc_5: 0.5529 - val_precision_2: 0.6964 - val_recall_2: 0.3475 - 185s/epoch - 18ms/step\n",
      "Epoch 54/200\n",
      "10076/10076 - 184s - loss: 0.2088 - auc_4: 0.8798 - auc_5: 0.5639 - precision_2: 0.7088 - recall_2: 0.3592 - val_loss: 0.2184 - val_auc_4: 0.8699 - val_auc_5: 0.5546 - val_precision_2: 0.7113 - val_recall_2: 0.3434 - 184s/epoch - 18ms/step\n",
      "Epoch 55/200\n",
      "10076/10076 - 183s - loss: 0.2083 - auc_4: 0.8802 - auc_5: 0.5646 - precision_2: 0.7129 - recall_2: 0.3509 - val_loss: 0.2178 - val_auc_4: 0.8706 - val_auc_5: 0.5571 - val_precision_2: 0.7095 - val_recall_2: 0.3455 - 183s/epoch - 18ms/step\n",
      "Epoch 56/200\n",
      "10076/10076 - 182s - loss: 0.2077 - auc_4: 0.8813 - auc_5: 0.5678 - precision_2: 0.7082 - recall_2: 0.3530 - val_loss: 0.2173 - val_auc_4: 0.8713 - val_auc_5: 0.5587 - val_precision_2: 0.7066 - val_recall_2: 0.3455 - 182s/epoch - 18ms/step\n",
      "Epoch 57/200\n",
      "10076/10076 - 183s - loss: 0.2071 - auc_4: 0.8820 - auc_5: 0.5705 - precision_2: 0.7150 - recall_2: 0.3545 - val_loss: 0.2169 - val_auc_4: 0.8716 - val_auc_5: 0.5615 - val_precision_2: 0.6943 - val_recall_2: 0.3717 - 183s/epoch - 18ms/step\n",
      "Epoch 58/200\n",
      "10076/10076 - 181s - loss: 0.2066 - auc_4: 0.8824 - auc_5: 0.5724 - precision_2: 0.7140 - recall_2: 0.3540 - val_loss: 0.2165 - val_auc_4: 0.8716 - val_auc_5: 0.5632 - val_precision_2: 0.6866 - val_recall_2: 0.3717 - 181s/epoch - 18ms/step\n",
      "Epoch 59/200\n",
      "10076/10076 - 181s - loss: 0.2060 - auc_4: 0.8831 - auc_5: 0.5745 - precision_2: 0.7072 - recall_2: 0.3577 - val_loss: 0.2158 - val_auc_4: 0.8728 - val_auc_5: 0.5657 - val_precision_2: 0.7061 - val_recall_2: 0.3495 - 181s/epoch - 18ms/step\n",
      "Epoch 60/200\n"
     ]
    }
   ],
   "source": [
    "mean_mort_model, mean_mort_preds = train_eval_pred_model(class_model, 2, 200, mortality_mean_X_train, mortality_mean_X_test,\n",
    "                                                          mortality_mean_y_train, mortality_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(mortality_mean_y_test, np.where(mean_mort_preds < 0.5, 0, 1)) / len(mortality_mean_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_los_model, mean_los_preds  = train_eval_pred_model(reg_model, 1, 200, los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(los_mean_y_test, mean_los_preds, s=25, zorder=10)\n",
    "\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7hBaf-KwOBc9",
    "outputId": "b2773897-6b07-480a-9561-02fa4079d950"
   },
   "outputs": [],
   "source": [
    "# cnn-vae\n",
    "cnn_readm_model, cnn_readm_preds  = train_eval_pred_model(class_model, 2, 200, readm_cnn_X_train, readm_cnn_X_test,\n",
    "                                        readm_cnn_y_train, readm_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mort_model, cnn_mort_preds  = train_eval_pred_model(class_model, 2, 200, mortality_cnn_X_train, mortality_cnn_X_test,\n",
    "                                       mortality_cnn_y_train, mortality_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_art6AQSVBY"
   },
   "outputs": [],
   "source": [
    "cnn_los_model, cnn_los_preds = train_eval_pred_model(reg_model, 1, 200, los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mimic_iv_omop_modeling_unified_cnn_vae_testing_diff_error_calc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
