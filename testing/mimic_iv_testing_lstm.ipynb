{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0DsFARgE0MOh"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "4jqZLo8J1VcH",
    "outputId": "437277b6-2f10-471d-c550-3caa5a4a36b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     0.0     0.0     1.0          0.0   \n",
       "1               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "2               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "3               92.0  ...     0.0     0.0     1.0          0.0   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     0.0                         0.0             0.0   \n",
       "1                     0.0                         0.0             0.0   \n",
       "2                     0.0                         0.0             0.0   \n",
       "3                     0.0                         0.0             0.0   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 0.0          0.0     1.0  \n",
       "1                 0.0          0.0     1.0  \n",
       "2                 0.0          0.0     1.0  \n",
       "3                 0.0          0.0     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Time Series Data\n",
    "\n",
    "# Data by the hour\n",
    "first_48_data = pd.read_csv('../../../../data/datasets/mimiciv_timeseries/mimiciv_timeseries.csv')\n",
    "\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in first_48_data.iterrows():\n",
    "        \n",
    "    # Making gcs scores nan where unobserved\n",
    "    if row['x0_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x0_0.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x0_1.0'] = np.nan\n",
    "\n",
    "    if row['x1_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x1_None'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_Spontaneously'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Speech'] = np.nan\n",
    "\n",
    "    if row['x2_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x2_Abnormal Flexion'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Abnormal extension'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Flex-withdraws'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Localizes Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_No response'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Obeys Commands'] = np.nan\n",
    "\n",
    "    if row['x3_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x3_10.0'] = np.nan \n",
    "        first_48_data.at[idx, 'x3_11.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_12.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_13.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_14.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_15.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_3.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_4.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_5.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_6.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_7.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_8.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_9.0'] = np.nan\n",
    "\n",
    "\n",
    "    if row['x4_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x4_Confused'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Inappropriate Words'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Incomprehensible sounds'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response-ETT'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Oriented'] = np.nan\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     NaN     NaN     1.0          NaN   \n",
       "1               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "2               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "3               92.0  ...     NaN     NaN     1.0          NaN   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     NaN                         NaN             NaN   \n",
       "1                     NaN                         NaN             NaN   \n",
       "2                     NaN                         NaN             NaN   \n",
       "3                     NaN                         NaN             NaN   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 NaN          NaN     1.0  \n",
       "1                 NaN          NaN     1.0  \n",
       "2                 NaN          NaN     1.0  \n",
       "3                 NaN          NaN     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18664949_episode1</td>\n",
       "      <td>18664949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.114583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19793183_episode1</td>\n",
       "      <td>19793183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.467361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15687156_episode1</td>\n",
       "      <td>15687156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14504982_episode1</td>\n",
       "      <td>14504982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  subject_id  episode_num  readmission  \\\n",
       "0           0  11432534_episode1    11432534            1          0.0   \n",
       "1           1  18664949_episode1    18664949            1          0.0   \n",
       "2           2  19793183_episode1    19793183            1          0.0   \n",
       "3           3  15687156_episode1    15687156            1          0.0   \n",
       "4           4  14504982_episode1    14504982            1          0.0   \n",
       "\n",
       "   length_of_stay  mortality  \n",
       "0        7.935417          0  \n",
       "1        5.114583          0  \n",
       "2       20.467361          0  \n",
       "3        0.098611          1  \n",
       "4        9.854167          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading label data\n",
    "\n",
    "label_data = pd.read_csv('mimic_iv_label_data.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10000980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10001217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10001725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10002013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  cluster\n",
       "0           0    10000032        1\n",
       "1           1    10000980        1\n",
       "2           2    10001217        1\n",
       "3           3    10001725        1\n",
       "4           4    10002013        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading patient clusters\n",
    "\n",
    "patient_clusters = pd.read_csv('mimic_iv_patient_clusters.csv')\n",
    "patient_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column for subject_id and episode_num\n",
    "\n",
    "subject_w_ep = first_48_data['subject']\n",
    "\n",
    "subject_ids = subject_w_ep.apply(lambda x: int(x.split('_')[0]))\n",
    "episode_nums = subject_w_ep.apply(lambda x: int(x.split('_')[1][7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_nan  x4_Confused  x4_Inappropriate Words  \\\n",
       "0                NaN  ...     1.0          NaN                     NaN   \n",
       "1               93.0  ...     1.0          NaN                     NaN   \n",
       "2               93.0  ...     1.0          NaN                     NaN   \n",
       "3               92.0  ...     1.0          NaN                     NaN   \n",
       "4               92.0  ...     0.0          1.0                     0.0   \n",
       "\n",
       "   x4_Incomprehensible sounds  x4_No Response  x4_No Response-ETT  \\\n",
       "0                         NaN             NaN                 NaN   \n",
       "1                         NaN             NaN                 NaN   \n",
       "2                         NaN             NaN                 NaN   \n",
       "3                         NaN             NaN                 NaN   \n",
       "4                         0.0             0.0                 0.0   \n",
       "\n",
       "   x4_Oriented  x4_nan  subject_id  episode_num  \n",
       "0          NaN     1.0    11432534            1  \n",
       "1          NaN     1.0    11432534            1  \n",
       "2          NaN     1.0    11432534            1  \n",
       "3          NaN     1.0    11432534            1  \n",
       "4          0.0     0.0    11432534            1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data['subject_id'] = subject_ids\n",
    "first_48_data['episode_num'] = episode_nums\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_48_data.rename(columns={\"time(hr)\": \"Hours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                      42.0   \n",
       "3             3  11432534_episode1  0.060556                      42.0   \n",
       "4             4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x4_Oriented  x4_nan  subject_id  episode_num  \\\n",
       "0                NaN  ...          NaN     1.0    11432534            1   \n",
       "1               93.0  ...          NaN     1.0    11432534            1   \n",
       "2               93.0  ...          NaN     1.0    11432534            1   \n",
       "3               92.0  ...          NaN     1.0    11432534            1   \n",
       "4               92.0  ...          0.0     0.0    11432534            1   \n",
       "\n",
       "   Unnamed: 0_y  readmission  length_of_stay  mortality  Unnamed: 0  cluster  \n",
       "0             0          0.0        7.935417          0        3710        1  \n",
       "1             0          0.0        7.935417          0        3710        1  \n",
       "2             0          0.0        7.935417          0        3710        1  \n",
       "3             0          0.0        7.935417          0        3710        1  \n",
       "4             0          0.0        7.935417          0        3710        1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging data with labels and cluster to get correct sample\n",
    "\n",
    "first_48_data = first_48_data.merge(label_data, on=['subject', 'subject_id', 'episode_num'])\n",
    "first_48_data = first_48_data.merge(patient_clusters, on='subject_id')\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "print(len(first_48_data.groupby('subject')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0_x', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'Unnamed: 0_y', 'readmission',\n",
      "       'length_of_stay', 'mortality', 'Unnamed: 0', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping 'Unnamed: 0_x' and renaming to 'original_idx' to retain original indexes\n",
    "first_48_data = first_48_data.drop(columns=['Unnamed: 0_y', 'Unnamed: 0'])\n",
    "\n",
    "first_48_data = first_48_data.rename(columns={'Unnamed: 0_x': 'original_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_idx', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'readmission', 'length_of_stay',\n",
      "       'mortality', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
      "       'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
      "       'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
      "       'pH', 'x0_0.0', 'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously',\n",
      "       'x1_To Pain', 'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns[3:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_idx</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_idx            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                      42.0   \n",
       "3             3  11432534_episode1  0.060556                      42.0   \n",
       "4             4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x4_No Response  x4_No Response-ETT  x4_Oriented  \\\n",
       "0                NaN  ...             NaN                 NaN          NaN   \n",
       "1               93.0  ...             NaN                 NaN          NaN   \n",
       "2               93.0  ...             NaN                 NaN          NaN   \n",
       "3               92.0  ...             NaN                 NaN          NaN   \n",
       "4               92.0  ...             0.0                 0.0          0.0   \n",
       "\n",
       "   x4_nan  subject_id  episode_num  readmission  length_of_stay  mortality  \\\n",
       "0     1.0    11432534            1          0.0        7.935417          0   \n",
       "1     1.0    11432534            1          0.0        7.935417          0   \n",
       "2     1.0    11432534            1          0.0        7.935417          0   \n",
       "3     1.0    11432534            1          0.0        7.935417          0   \n",
       "4     0.0    11432534            1          0.0        7.935417          0   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx7GR50X1onC",
    "outputId": "6acc984c-8335-4a2f-b716-ce2e977ae03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "# Grouping by admission\n",
    "\n",
    "data = first_48_data.groupby('subject')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  \n",
    "\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "\n",
    "for group_idx, group_rows in data:  \n",
    "    \n",
    "    subjects.append(group_idx)\n",
    "    subject_idx.append(i)\n",
    "    \n",
    "    readm_label.append(group_rows['readmission'].values[0])\n",
    "    mortality_label.append(group_rows['mortality'].values[0])\n",
    "    los_label.append(group_rows['length_of_stay'].values[0])\n",
    "    cluster.append(group_rows['cluster'].values[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # stores totals for variables\n",
    "    cur_matrix = np.empty([48, 48])\n",
    "    cur_matrix[:] = np.nan\n",
    "\n",
    "    # stores counts for variables\n",
    "    cur_counts = np.empty([48, 48])\n",
    "    cur_counts[:] = np.nan\n",
    "\n",
    "    cur_columns = group_rows.columns.values.tolist()\n",
    "    feature_columns = cur_columns[3:-6]\n",
    "\n",
    "    j = 0\n",
    "    for idx, row in group_rows.iterrows():\n",
    "        \n",
    "            \n",
    "        # Modifying cur_data to have data by the hour for 48 hours\n",
    "        if row['Hours'] < j+1 and j < 48:\n",
    "            for k in range(len(feature_columns)):\n",
    "                if not (np.isnan(group_rows.loc[idx, feature_columns[k]])):\n",
    "                    if np.isnan(cur_matrix[j, k]):\n",
    "                        cur_matrix[j, k] = group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] = 1\n",
    "                    else:\n",
    "                        cur_matrix[j, k] += group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] += 1\n",
    "                        \n",
    "        else:\n",
    "            if j >= 48:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "    # Getting time series data\n",
    "\n",
    "    X_element = np.divide(cur_matrix, cur_counts)\n",
    "\n",
    "    if i == 0:\n",
    "\n",
    "        # Holds all of the multivariate time series\n",
    "        X = np.array([X_element])\n",
    "\n",
    "    else:\n",
    "        X = np.concatenate((X, np.array([X_element])))\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7LiqNzaB5TU",
    "outputId": "e82a9180-0104-426d-841c-cdccbbd97574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>readmission</th>\n",
       "      <th>mortality</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032_episode1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980_episode1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.806944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001217_episode1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.794444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001217_episode2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.914583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001725_episode1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject  subject_idx  readmission  mortality  length_of_stay  \\\n",
       "0  10000032_episode1            0          0.0          0        2.222222   \n",
       "1  10000980_episode1            1          0.0          0        5.806944   \n",
       "2  10001217_episode1            2          1.0          0        6.794444   \n",
       "3  10001217_episode2            3          NaN          0        5.914583   \n",
       "4  10001725_episode1            4          0.0          0        2.994444   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'subject':subjects, 'subject_idx':subject_idx, 'readmission':readm_label, 'mortality':mortality_label,\n",
    "                  'length_of_stay':los_label, 'cluster':cluster})\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "T2z9KMmI1tVF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 33\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Standardizing the data\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = preprocessing.StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i]) \n",
    "\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i]) \n",
    "\n",
    "for i in range(X.shape[2]):\n",
    "    X[:, :, i] = scalers[i].transform(X[:, :, i]) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.20036582976204423, 0.17775456930207437, 0.12269121668293394, 0.17775456930207437, 0.019168285216680847, 0.17775456930207437, 0.17775456930207437, 0.08130735198117317, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "all_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_2d = np.reshape(X, (X.shape[0]*X.shape[1], X.shape[2]))\n",
    "\n",
    "\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "mean_imputer.fit(X_2d)\n",
    "X_2d = mean_imputer.transform(X_2d)\n",
    "\n",
    "\n",
    "for i in range(X_2d.shape[1]):\n",
    "    all_feature_means.append(np.mean(X_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(all_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwJDX3Ai2GnQ",
    "outputId": "52f717ae-3504-4811-f20a-cc84764a72d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.09987920279910383, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, 0.3625940492800348, 0.4566171176093376, -0.026951689326147627, -0.11808901157400302, -0.07199669000259247, -5.561317025005966e-16, -5.561317025005966e-16, -0.027816122495181478, -5.561317025005966e-16, -0.03771542601618285, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.0517255267568309, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.05797858027354016, -0.037948085096949545, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.0373495700991753, -5.561317025005966e-16, 0.0011522622218144013, -0.1193126492824123, -0.00621006890979503, -5.561317025005966e-16, -0.1122734378452095, -5.561317025005966e-16, -0.098805219260766]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "train_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_train_2d = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "\n",
    "train_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_mean_imputer.fit(X_train_2d)\n",
    "X_train_2d = train_mean_imputer.transform(X_train_2d)\n",
    "\n",
    "\n",
    "for i in range(X_train_2d.shape[1]):\n",
    "    train_feature_means.append(np.mean(X_train_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q12dIA8z2hsx",
    "outputId": "a7fe45b7-0b1e-4eed-c627-2699bcb41292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.1030028290570371, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.24883296789872858, 0.36238176622895285, -0.12539406351832436, -0.10990306785139915, -0.10842122798852537, -0.07174711163129376, 0.016609368340701185, 0.0654413884834812, 0.053703900653218097, 0.8772903210129748, -0.032617594906144014, 0.011494253958953267, 0.014764003867121742, -0.01673144230310153, 0.8772903210129748, -0.025311304149835765, -0.006946143768683178, 0.8772903210129748, 0.8772903210129748, 0.1387755349024727, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.061612438423388184, -0.07264972143415817, -0.08039203564601172, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.06493351645073649, 0.8772903210129748, -0.013698942651471474, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.07014096988932718, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.0797538903150036, -0.05625997397447844, 0.8772903210129748]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "test_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_test_2d = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "\n",
    "test_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "test_mean_imputer.fit(X_test_2d)\n",
    "X_test_2d = test_mean_imputer.transform(X_test_2d)\n",
    "\n",
    "\n",
    "for i in range(X_test_2d.shape[1]):\n",
    "    test_feature_means.append(np.mean(X_test_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(test_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6Q53xXLP2lnd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a random mask for evaluation of imputation \n",
    "\n",
    "def mean_imputation_eval(X, train_feature_means):\n",
    "    iter = 100\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "    \n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4SbKzJc21E7",
    "outputId": "2f997abd-7a40-41f0-f71b-97d38a04fdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:\n",
      "0.5776177830281686\n",
      "0.015483739134975714 \n",
      "\n",
      "mae:\n",
      "0.3979626500626157\n",
      "0.0006590698783683776 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputation_eval(X, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8qPYEc7B3GNQ"
   },
   "outputs": [],
   "source": [
    "def create_mean_imputed_data(X_train, X_test, train_feature_means, test_feature_means):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = train_feature_means[k]\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = train_feature_means[k]\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "\n",
    "    return X_train_imputed, X_test_imputed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "iComzTNR4cbF"
   },
   "outputs": [],
   "source": [
    "X_train_mean_imputed, X_test_mean_imputed = create_mean_imputed_data(X_train, X_test, train_feature_means, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d9GnUNeC40Em"
   },
   "outputs": [],
   "source": [
    "def vae_preprocessing(X_train, X_test):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = impute_value\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = impute_value\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "                    \n",
    "    return X_train_imputed, X_test_imputed, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HPBch8O_5uFF"
   },
   "outputs": [],
   "source": [
    "processed_X_train, processed_X_test, train_mask, test_mask = vae_preprocessing(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Co301rq5CDqP"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class vae_model(ABC):\n",
    "\n",
    "    def __init__(self, n_filters, kernel_size, learning_rate,\n",
    "               sequence_length, n_features):\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.latent_dim = 2\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "    \n",
    "\n",
    "        if self.kernel_size == 3:\n",
    "            self.nn_dim = 21\n",
    "        elif self.kernel_size == 5:\n",
    "            self.nn_dim = 18\n",
    "        else:\n",
    "            self.kernel_size = None\n",
    "            self.nn_dim = None\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "    \n",
    "        tf.random.set_seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def sampling(self, args):\n",
    "      \n",
    "        latent_dim = 2\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1)\n",
    "\n",
    "        return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "\n",
    "    def vae_loss(self, inp, mask, out, z_log_sigma, z_mean):\n",
    "        masked_input = tf.math.multiply(inp, mask)\n",
    "        masked_output = tf.math.multiply(out, mask)\n",
    "\n",
    "        #mse = np.sum(np.square(np.subtract(masked_output, masked_input))) / np.sum(mask)\n",
    "        mse = K.sum(K.square(masked_output - masked_input)) / K.sum(mask)\n",
    "\n",
    "        reconstruction = mse * self.sequence_length\n",
    "        kl = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "\n",
    "        return reconstruction + kl\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ev9NJEg-58HO"
   },
   "outputs": [],
   "source": [
    "class lstm_vae(vae_model):\n",
    "    \n",
    "    def get_model(self):\n",
    "      \n",
    "        self.set_seed(random_seed)\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        inp = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "        mask = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "\n",
    "\n",
    "        enc = tf.keras.layers.LSTM(192, input_shape=(self.sequence_length, self.n_features))(inp)\n",
    "\n",
    "        z = tf.keras.layers.Dense(96, activation=\"relu\")(enc)\n",
    "\n",
    "        z_mean = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "        z_log_sigma = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "\n",
    "        encoder = tf.keras.Model([inp], [z_mean, z_log_sigma])\n",
    "\n",
    "        # decoder\n",
    "\n",
    "        inp_z = tf.keras.Input(shape=(self.latent_dim,))\n",
    "\n",
    "        dec = tf.keras.layers.RepeatVector(self.sequence_length)(inp_z)\n",
    "\n",
    "        dec = tf.keras.layers.LSTM(192, input_shape=(self.sequence_length, self.n_features), return_sequences=True)(dec)\n",
    "\n",
    "        out = tf.keras.layers.TimeDistributed(Dense(self.n_features))(dec)\n",
    "\n",
    "        decoder = tf.keras.Model([inp_z], out) \n",
    "\n",
    "        # encoder and decoder \n",
    "\n",
    "        z_mean, z_log_sigma = encoder([inp])\n",
    "        z = tf.keras.layers.Lambda(self.sampling)([z_mean, z_log_sigma])\n",
    "        pred = decoder([z])\n",
    "\n",
    "        vae = tf.keras.Model([inp,  mask], pred)\n",
    "        vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
    "        vae.compile(loss=None, optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "\n",
    "        return vae\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "pwKhQRmD8sWn"
   },
   "outputs": [],
   "source": [
    "def train_eval_vae_model(model, processed_X_train, processed_X_test, train_mask, test_mask, batch_size):\n",
    "  \n",
    "    es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "    model.fit([processed_X_train, train_mask], batch_size=batch_size, validation_split=0.2, epochs=100, shuffle=False, callbacks=[es])\n",
    "\n",
    "\n",
    "    vae = tf.keras.Model(model.input, model.output)\n",
    "\n",
    "    reconstruc_train = vae.predict([processed_X_train,  train_mask])\n",
    "    reconstruc_test = vae.predict([processed_X_test, test_mask])\n",
    "\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    #print(mask_X_test_imputed[1])\n",
    "    masked_reconstruction = tf.math.multiply(reconstruc_test, test_mask)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(processed_X_test.shape[0]):\n",
    "        mse += np.sum(np.square(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "        mae += np.sum(np.absolute(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "\n",
    "\n",
    "    print(\"test mse: \", mse / processed_X_test.shape[0])\n",
    "    print(\"test mae: \", mae / processed_X_test.shape[0], \"\\n\")\n",
    "\n",
    "    return model, reconstruc_train, reconstruc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "TxadxrVYByDt"
   },
   "outputs": [],
   "source": [
    "def vae_masked_eval(X, vae, batch_size):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "        rand_X_imputed = imputated_data\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        rand_X_imputed = np.where(rand_mask==0, rand_X_imputed, 0)\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            # mse += np.mean(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            # mae += np.mean(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")\n",
    "\n",
    "    return np.mean(mse_list), np.mean(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_vae_mean_imp_eval(X, vae, batch_size, train_feature_means):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    vae_mse_list = []\n",
    "    vae_mae_list = []\n",
    "    \n",
    "    mean_mse_list = []\n",
    "    mean_mae_list = []\n",
    "    \n",
    "    diff_mse_list = []\n",
    "    diff_mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        vae_mse = 0\n",
    "        vae_mae = 0\n",
    "        \n",
    "        mean_mse = 0\n",
    "        mean_mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        \n",
    "        # Performing and evaluating vae imputation\n",
    "        vae_imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        vae_imputated_data = np.where(rand_mask==0, vae_imputated_data, 0)\n",
    "        vae_imputated_data = np.where(np.isnan(X), 0, vae_imputated_data)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            vae_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "            vae_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        vae_mse_list.append(vae_mse / n_samples)\n",
    "        vae_mae_list.append(vae_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Performing and evaluating mean imputation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "        \n",
    "        \n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mean_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mean_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mean_mse_list.append(mean_mse / n_samples)\n",
    "        mean_mae_list.append(mean_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Adding the differences of the mean errors\n",
    "        diff_mse_list.append((vae_mse / n_samples) - (mean_mse / n_samples))\n",
    "        \n",
    "        diff_mae_list.append((vae_mae / n_samples) - (mean_mae / n_samples))\n",
    "        \n",
    "\n",
    "\n",
    "    print(\"vae imputation mse:\")\n",
    "    print(\"mean: \", np.mean(vae_mse_list))\n",
    "    print(\"std dev: \", np.std(vae_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"vae imputation mae:\")\n",
    "    print(\"mean: \", np.mean(vae_mae_list))\n",
    "    print(\"std dev: \", np.std(vae_mae_list), \"\\n\\n\")\n",
    "\n",
    "    \n",
    "    print(\"mean inputation mse:\")\n",
    "    print(\"mean: \", np.mean(mean_mse_list))\n",
    "    print(\"std dev: \", np.std(mean_mse_list), \"\\n\")\n",
    "    \n",
    "    print(\"mean imputation mae:\")\n",
    "    print(\"mean: \", np.mean(mean_mae_list))\n",
    "    print(\"std dev: \", np.std(mean_mae_list), \"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"mean difference in mse:\")\n",
    "    print(\"mean: \", np.mean(diff_mse_list))\n",
    "    print(\"std dev: \", np.std(diff_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"mean difference in mae:\")\n",
    "    print(\"mean: \", np.mean(diff_mae_list))\n",
    "    print(\"std dev: \", np.std(diff_mae_list), \"\\n\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhSubm4Lfm4J",
    "outputId": "6ec47709-e89b-49a3-919b-0ccab91bc5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20152/20152 [==============================] - 277s 13ms/step - loss: 40.9429 - val_loss: 40.5687\n",
      "Epoch 2/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 38.6794 - val_loss: 38.5958\n",
      "Epoch 3/100\n",
      "20152/20152 [==============================] - 266s 13ms/step - loss: 37.3189 - val_loss: 39.3344\n",
      "Epoch 4/100\n",
      "20152/20152 [==============================] - 274s 14ms/step - loss: 36.6738 - val_loss: 37.1579\n",
      "Epoch 5/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 36.0890 - val_loss: 37.7040\n",
      "Epoch 6/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 35.7143 - val_loss: 36.5133\n",
      "Epoch 7/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 35.2406 - val_loss: 35.7176\n",
      "Epoch 8/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 34.9939 - val_loss: 35.5609\n",
      "Epoch 9/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 34.5391 - val_loss: 35.2868\n",
      "Epoch 10/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 34.4878 - val_loss: 35.2533\n",
      "Epoch 11/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 34.3373 - val_loss: 35.5544\n",
      "Epoch 12/100\n",
      "20152/20152 [==============================] - 271s 13ms/step - loss: 34.1669 - val_loss: 35.3535\n",
      "Epoch 13/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 34.0091 - val_loss: 35.5069\n",
      "Epoch 14/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 33.8380 - val_loss: 34.4359\n",
      "Epoch 15/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 33.8787 - val_loss: 34.3003\n",
      "Epoch 16/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 33.5051 - val_loss: 34.6748\n",
      "Epoch 17/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 33.4867 - val_loss: 34.2403\n",
      "Epoch 18/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 33.2352 - val_loss: 34.9269\n",
      "Epoch 19/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 33.1823 - val_loss: 35.0924\n",
      "Epoch 20/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 33.0916 - val_loss: 34.1220\n",
      "Epoch 21/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 33.1418 - val_loss: 34.5297\n",
      "Epoch 22/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 32.8242 - val_loss: 34.1545\n",
      "Epoch 23/100\n",
      "20152/20152 [==============================] - 271s 13ms/step - loss: 32.7197 - val_loss: 34.1293\n",
      "Epoch 24/100\n",
      "20152/20152 [==============================] - 274s 14ms/step - loss: 32.7912 - val_loss: 34.0764\n",
      "Epoch 25/100\n",
      "20152/20152 [==============================] - 271s 13ms/step - loss: 32.6131 - val_loss: 33.7140\n",
      "Epoch 26/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 32.6246 - val_loss: 35.2399\n",
      "Epoch 27/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 32.9194 - val_loss: 34.1948\n",
      "Epoch 28/100\n",
      "20152/20152 [==============================] - 266s 13ms/step - loss: 32.5498 - val_loss: 33.6497\n",
      "Epoch 29/100\n",
      "20152/20152 [==============================] - 265s 13ms/step - loss: 32.4423 - val_loss: 33.9382\n",
      "Epoch 30/100\n",
      "20152/20152 [==============================] - 266s 13ms/step - loss: 32.2421 - val_loss: 34.0163\n",
      "Epoch 31/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 32.2363 - val_loss: 35.1744\n",
      "Epoch 32/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 32.1313 - val_loss: 33.8988\n",
      "Epoch 33/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 32.2054 - val_loss: 33.7793\n",
      "Epoch 34/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 31.9699 - val_loss: 33.7818\n",
      "Epoch 35/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 32.0633 - val_loss: 33.8195\n",
      "Epoch 36/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.8583 - val_loss: 34.0543\n",
      "Epoch 37/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 32.0384 - val_loss: 33.4544\n",
      "Epoch 38/100\n",
      "20152/20152 [==============================] - 266s 13ms/step - loss: 31.6703 - val_loss: 33.3749\n",
      "Epoch 39/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.7380 - val_loss: 33.4117\n",
      "Epoch 40/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.6040 - val_loss: 33.3760\n",
      "Epoch 41/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.5399 - val_loss: 33.4736\n",
      "Epoch 42/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.4823 - val_loss: 33.2346\n",
      "Epoch 43/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 31.3633 - val_loss: 33.6656\n",
      "Epoch 44/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 31.4444 - val_loss: 33.3415\n",
      "Epoch 45/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 31.2430 - val_loss: 33.8769\n",
      "Epoch 46/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.3572 - val_loss: 33.7812\n",
      "Epoch 47/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.2740 - val_loss: 33.7717\n",
      "Epoch 48/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 31.1832 - val_loss: 34.0364\n",
      "Epoch 49/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.1417 - val_loss: 32.9612\n",
      "Epoch 50/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.1429 - val_loss: 33.3788\n",
      "Epoch 51/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.2767 - val_loss: 34.0096\n",
      "Epoch 52/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.1830 - val_loss: 33.3213\n",
      "Epoch 53/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 31.0308 - val_loss: 32.9788\n",
      "Epoch 54/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.0278 - val_loss: 32.9029\n",
      "Epoch 55/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 31.2743 - val_loss: 33.1000\n",
      "Epoch 56/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 30.8501 - val_loss: 32.9563\n",
      "Epoch 57/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.8634 - val_loss: 33.1604\n",
      "Epoch 58/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 30.7398 - val_loss: 33.7390\n",
      "Epoch 59/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 30.7383 - val_loss: 32.8090\n",
      "Epoch 60/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.9873 - val_loss: 33.3172\n",
      "Epoch 61/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 30.5065 - val_loss: 33.1007\n",
      "Epoch 62/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 30.7053 - val_loss: 33.2183\n",
      "Epoch 63/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 30.6471 - val_loss: 32.9517\n",
      "Epoch 64/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.6119 - val_loss: 32.8788\n",
      "Epoch 65/100\n",
      "20152/20152 [==============================] - 270s 13ms/step - loss: 30.5777 - val_loss: 34.1964\n",
      "Epoch 66/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 31.0892 - val_loss: 33.3716\n",
      "Epoch 67/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 30.7163 - val_loss: 33.9237\n",
      "Epoch 68/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.6041 - val_loss: 32.7495\n",
      "Epoch 69/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.7228 - val_loss: 32.9824\n",
      "Epoch 70/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 30.4350 - val_loss: 33.2006\n",
      "Epoch 71/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.5274 - val_loss: 34.6946\n",
      "Epoch 72/100\n",
      "20152/20152 [==============================] - 267s 13ms/step - loss: 30.4545 - val_loss: 33.4149\n",
      "Epoch 73/100\n",
      "20152/20152 [==============================] - 269s 13ms/step - loss: 30.6704 - val_loss: 33.0281\n",
      "Epoch 74/100\n",
      "20152/20152 [==============================] - 268s 13ms/step - loss: 30.3614 - val_loss: 32.6045\n",
      "Epoch 75/100\n",
      "20152/20152 [==============================] - 271s 13ms/step - loss: 30.2890 - val_loss: 32.5112\n",
      "Epoch 76/100\n",
      "20152/20152 [==============================] - 275s 14ms/step - loss: 30.2729 - val_loss: 33.2525\n",
      "Epoch 77/100\n",
      "20152/20152 [==============================] - 271s 13ms/step - loss: 30.2791 - val_loss: 32.6522\n",
      "Epoch 78/100\n",
      "20152/20152 [==============================] - 274s 14ms/step - loss: 30.1999 - val_loss: 33.5581\n",
      "Epoch 79/100\n",
      "20152/20152 [==============================] - 274s 14ms/step - loss: 30.1199 - val_loss: 32.5294\n",
      "Epoch 80/100\n",
      "20152/20152 [==============================] - 275s 14ms/step - loss: 30.1303 - val_loss: 32.9483\n",
      "Epoch 81/100\n",
      "20152/20152 [==============================] - 275s 14ms/step - loss: 30.0368 - val_loss: 33.0257\n",
      "Epoch 82/100\n",
      "20152/20152 [==============================] - 273s 14ms/step - loss: 30.0458 - val_loss: 32.5392\n",
      "Epoch 83/100\n",
      "20152/20152 [==============================] - 257s 13ms/step - loss: 29.9017 - val_loss: 32.6746\n",
      "Epoch 84/100\n",
      "20152/20152 [==============================] - 256s 13ms/step - loss: 29.9850 - val_loss: 32.8389\n",
      "Epoch 85/100\n",
      "20151/20152 [============================>.] - ETA: 0s - loss: 30.0037Restoring model weights from the end of the best epoch: 75.\n",
      "20152/20152 [==============================] - 257s 13ms/step - loss: 30.0025 - val_loss: 32.9716\n",
      "Epoch 85: early stopping\n",
      "test mse:  983109.5071730962\n",
      "test mae:  1.0411565817996808 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_vae_instance = lstm_vae(n_filters=32, kernel_size=5, learning_rate=1e-4, \n",
    "                                    sequence_length=48, n_features=48)\n",
    "\n",
    "\n",
    "lstm_vae_model = lstm_vae_instance.get_model()\n",
    "\n",
    "trained_lstm_vae_model, lstm_reconstruc_train, lstm_reconstruc_test = train_eval_vae_model(lstm_vae_model, \n",
    "                                                processed_X_train, processed_X_test, train_mask, test_mask, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae imputation mse:\n",
      "mean:  95051.41289817599\n",
      "std dev:  78310.15685831934 \n",
      "\n",
      "vae imputation mae:\n",
      "mean:  0.2302483642951013\n",
      "std dev:  0.055719869611359066 \n",
      "\n",
      "\n",
      "mean inputation mse:\n",
      "mean:  95051.58628074202\n",
      "std dev:  78310.18506906966 \n",
      "\n",
      "mean imputation mae:\n",
      "mean:  0.3099202340213587\n",
      "std dev:  0.055768204414526054 \n",
      "\n",
      "\n",
      "mean difference in mse:\n",
      "mean:  -0.1733825660415151\n",
      "std dev:  0.030444128127180965 \n",
      "\n",
      "mean difference in mae:\n",
      "mean:  -0.07967186972625745\n",
      "std dev:  0.00013386692054023766 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paired_vae_mean_imp_eval(X, trained_lstm_vae_model, 1, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae imputation mse:\n",
      "mean:  380175.3653563518\n",
      "std dev:  384625.28608938976 \n",
      "\n",
      "vae imputation mae:\n",
      "mean:  0.44872496612125107\n",
      "std dev:  0.2757353763113207 \n",
      "\n",
      "\n",
      "mean inputation mse:\n",
      "mean:  380175.6362112643\n",
      "std dev:  384625.43060244416 \n",
      "\n",
      "mean imputation mae:\n",
      "mean:  0.5267369054767376\n",
      "std dev:  0.2757144415386849 \n",
      "\n",
      "\n",
      "mean difference in mse:\n",
      "mean:  -0.27085491249960847\n",
      "std dev:  0.14738293843145595 \n",
      "\n",
      "mean difference in mae:\n",
      "mean:  -0.07801193935548642\n",
      "std dev:  0.0002830235084772442 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paired eval on the test set\n",
    "\n",
    "paired_vae_mean_imp_eval(X_test, trained_lstm_vae_model, 1, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "ZZ7l1FCGkn69",
    "outputId": "0b8153bc-076a-4620-b57a-9f9a14d6e76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97cc050310>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(lstm_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
    "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "-dvIbnsBCkG6"
   },
   "outputs": [],
   "source": [
    "def imputed_vae_data(X_train, X_test, reconstruc_train, reconstruc_test):\n",
    "  \n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    # Impute original with reconstruction\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = reconstruc_train[i,j,k]\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = reconstruc_test[i,j,k]\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "\n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_X_train_imputed, lstm_X_test_imputed = imputed_vae_data(X_train, X_test, lstm_reconstruc_train, lstm_reconstruc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "fE44FC8KFaL2"
   },
   "outputs": [],
   "source": [
    "def readm_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    readm_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    readm_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                readm_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                readm_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    readm_y_train = y_train['readmission']\n",
    "    readm_y_test = y_test['readmission']\n",
    "\n",
    "\n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(readm_X_train.shape[0]):\n",
    "        if np.isnan(y_train['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(readm_X_test.shape[0]):\n",
    "        if np.isnan(y_test['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    readm_X_train = np.delete(readm_X_train, rm_idx_train, 0)\n",
    "    readm_y_train = np.delete(np.array(readm_y_train), rm_idx_train, 0)\n",
    "\n",
    "    readm_X_test = np.delete(readm_X_test, rm_idx_test, 0)\n",
    "    readm_y_test = np.delete(np.array(readm_y_test), rm_idx_test, 0)\n",
    "\n",
    "    #print(readm_X_train.shape)\n",
    "    #print(readm_y_train.shape)\n",
    "\n",
    "    #print(readm_X_test.shape)\n",
    "    #print(readm_y_test.shape)\n",
    "\n",
    "    #print(np.where(readm_y_train == 1))\n",
    "    #print(np.where(readm_y_test == 1))  \n",
    "    return readm_X_train, readm_X_test, readm_y_train, readm_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "e9Nk7yYjFk_n"
   },
   "outputs": [],
   "source": [
    "def mortality_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Mortality\n",
    "    mortality_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    mortality_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                mortality_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                mortality_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "    mortality_y_train = y_train['mortality']\n",
    "    mortality_y_test = y_test['mortality']\n",
    "\n",
    "\n",
    "    #print(np.where(mortality_y_train == 1))\n",
    "    #print(np.where(mortality_y_test == 1))\n",
    "    return mortality_X_train, mortality_X_test, mortality_y_train, mortality_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "GNeU2yqMFlHo"
   },
   "outputs": [],
   "source": [
    "def los_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Length of Stay\n",
    "    los_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    los_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                los_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                los_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "                \n",
    "    los_y_train = y_train['length_of_stay']\n",
    "    los_y_test = y_test['length_of_stay']\n",
    "    \n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(los_X_train.shape[0]):\n",
    "        if los_y_train.values[i] < 0:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(los_X_test.shape[0]):\n",
    "        if los_y_test.values[i] < 0:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    los_X_train = np.delete(los_X_train, rm_idx_train, 0)\n",
    "    los_y_train = np.delete(np.array(los_y_train), rm_idx_train, 0)\n",
    "\n",
    "    los_X_test = np.delete(los_X_test, rm_idx_test, 0)\n",
    "    los_y_test = np.delete(np.array(los_y_test), rm_idx_test, 0)\n",
    "    \n",
    "          \n",
    "    los_y_train = (los_y_train - np.full(len(los_y_train), np.mean(los_y_train))) / np.std(los_y_train)\n",
    "    \n",
    "    los_y_test = (los_y_test - np.full(len(los_y_test), np.mean(los_y_test))) / np.std(los_y_test)\n",
    "  \n",
    "\n",
    "    return los_X_train, los_X_test, los_y_train, los_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BmHqSFHGzPk",
    "outputId": "071a96e0-8ffb-4bd6-dbe9-dd8f96ef0342"
   },
   "outputs": [],
   "source": [
    "# Readmission data for each method\n",
    "readm_mean_X_train, readm_mean_X_test, readm_mean_y_train, readm_mean_y_test = readm_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "readm_lstm_X_train, readm_lstm_X_test, readm_lstm_y_train, readm_lstm_y_test = readm_preprocessing(lstm_X_train_imputed, \n",
    "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mortality data for each method\n",
    "mortality_mean_X_train, mortality_mean_X_test, mortality_mean_y_train, mortality_mean_y_test = mortality_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "mortality_lstm_X_train, mortality_lstm_X_test, mortality_lstm_y_train, mortality_lstm_y_test = mortality_preprocessing(lstm_X_train_imputed, \n",
    "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Length of stay data for each method\n",
    "los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test = los_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "los_lstm_X_train, los_lstm_X_test, los_lstm_y_train, los_lstm_y_test = los_preprocessing(lstm_X_train_imputed, \n",
    "                                                                           lstm_X_test_imputed, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OPgncEK1QFNV"
   },
   "outputs": [],
   "source": [
    "# LSTM Classification Model\n",
    "\n",
    "es = EarlyStopping(patience=20, verbose=1, min_delta=0.0001, monitor='val_auc', mode='auto', restore_best_weights=True)\n",
    "\n",
    "class_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "\n",
    "class_model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.AUC(curve='PR'), \n",
    "                      tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "dfNt7NW2QRXj"
   },
   "outputs": [],
   "source": [
    "# LSTM Regression Model\n",
    "\n",
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.0001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "\n",
    "reg_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='relu'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "reg_model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_pred_model(model, batch_size, epochs, X_train, X_test, y_train, y_test):\n",
    "    hist = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[es])\n",
    "    \n",
    "    predictions = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix3RpjX9Q7f5",
    "outputId": "c4ede1ab-8f31-4527-e129-6fe08bb9cc54"
   },
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "mean_readm_model, mean_readm_preds = train_eval_pred_model(class_model, 2, 200, readm_mean_X_train, readm_mean_X_test,\n",
    "                                                      readm_mean_y_train, readm_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(readm_mean_y_test, np.where(mean_readm_preds < 0.2, 0, 1)) / len(readm_mean_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mort_model, mean_mort_preds = train_eval_pred_model(class_model, 2, 200, mortality_mean_X_train, mortality_mean_X_test,\n",
    "                                                          mortality_mean_y_train, mortality_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(mortality_mean_y_test, np.where(mean_mort_preds < 0.5, 0, 1)) / len(mortality_mean_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_los_model, mean_los_preds  = train_eval_pred_model(reg_model, 1, 200, los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "los_mean_y_test_std = np.subtract(los_mean_y_test, np.repeat(np.mean(los_mean_y_test), len(los_mean_y_test))) / np.std(los_mean_y_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(los_mean_y_test_std, mean_los_preds, s=25, zorder=10)\n",
    "\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7hBaf-KwOBc9",
    "outputId": "b2773897-6b07-480a-9561-02fa4079d950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7197/7197 - 142s - loss: 0.4602 - auc: 0.5791 - auc_1: 0.1956 - precision: 0.1509 - recall: 0.0070 - val_loss: 0.4310 - val_auc: 0.5623 - val_auc_1: 0.1670 - val_precision: 0.0385 - val_recall: 0.0019 - 142s/epoch - 20ms/step\n",
      "Epoch 2/200\n",
      "7197/7197 - 139s - loss: 0.4407 - auc: 0.5863 - auc_1: 0.1973 - precision: 0.1452 - recall: 0.0040 - val_loss: 0.4239 - val_auc: 0.5683 - val_auc_1: 0.1690 - val_precision: 0.0588 - val_recall: 0.0019 - 139s/epoch - 19ms/step\n",
      "Epoch 3/200\n",
      "7197/7197 - 138s - loss: 0.4366 - auc: 0.5890 - auc_1: 0.1989 - precision: 0.1667 - recall: 0.0035 - val_loss: 0.4206 - val_auc: 0.5694 - val_auc_1: 0.1693 - val_precision: 0.0625 - val_recall: 0.0019 - 138s/epoch - 19ms/step\n",
      "Epoch 4/200\n",
      "7197/7197 - 140s - loss: 0.4344 - auc: 0.5906 - auc_1: 0.2000 - precision: 0.2051 - recall: 0.0035 - val_loss: 0.4179 - val_auc: 0.5740 - val_auc_1: 0.1709 - val_precision: 0.0714 - val_recall: 0.0019 - 140s/epoch - 19ms/step\n",
      "Epoch 5/200\n",
      "7197/7197 - 139s - loss: 0.4329 - auc: 0.5922 - auc_1: 0.2015 - precision: 0.2162 - recall: 0.0035 - val_loss: 0.4161 - val_auc: 0.5753 - val_auc_1: 0.1714 - val_precision: 0.0909 - val_recall: 0.0019 - 139s/epoch - 19ms/step\n",
      "Epoch 6/200\n",
      "7197/7197 - 140s - loss: 0.4319 - auc: 0.5937 - auc_1: 0.2027 - precision: 0.2424 - recall: 0.0035 - val_loss: 0.4162 - val_auc: 0.5752 - val_auc_1: 0.1718 - val_precision: 0.1250 - val_recall: 0.0019 - 140s/epoch - 19ms/step\n",
      "Epoch 7/200\n",
      "7197/7197 - 142s - loss: 0.4311 - auc: 0.5948 - auc_1: 0.2035 - precision: 0.2414 - recall: 0.0031 - val_loss: 0.4145 - val_auc: 0.5776 - val_auc_1: 0.1726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 8/200\n",
      "7197/7197 - 147s - loss: 0.4304 - auc: 0.5962 - auc_1: 0.2045 - precision: 0.2593 - recall: 0.0031 - val_loss: 0.4143 - val_auc: 0.5788 - val_auc_1: 0.1734 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 147s/epoch - 20ms/step\n",
      "Epoch 9/200\n",
      "7197/7197 - 146s - loss: 0.4299 - auc: 0.5971 - auc_1: 0.2051 - precision: 0.2400 - recall: 0.0026 - val_loss: 0.4133 - val_auc: 0.5788 - val_auc_1: 0.1733 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 146s/epoch - 20ms/step\n",
      "Epoch 10/200\n",
      "7197/7197 - 143s - loss: 0.4293 - auc: 0.5989 - auc_1: 0.2069 - precision: 0.2727 - recall: 0.0026 - val_loss: 0.4137 - val_auc: 0.5785 - val_auc_1: 0.1734 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 11/200\n",
      "7197/7197 - 143s - loss: 0.4290 - auc: 0.5993 - auc_1: 0.2075 - precision: 0.2857 - recall: 0.0026 - val_loss: 0.4126 - val_auc: 0.5800 - val_auc_1: 0.1738 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 12/200\n",
      "7197/7197 - 144s - loss: 0.4286 - auc: 0.6006 - auc_1: 0.2079 - precision: 0.3000 - recall: 0.0026 - val_loss: 0.4124 - val_auc: 0.5801 - val_auc_1: 0.1743 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 13/200\n",
      "7197/7197 - 143s - loss: 0.4281 - auc: 0.6021 - auc_1: 0.2098 - precision: 0.2778 - recall: 0.0022 - val_loss: 0.4127 - val_auc: 0.5805 - val_auc_1: 0.1744 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 14/200\n",
      "7197/7197 - 143s - loss: 0.4279 - auc: 0.6025 - auc_1: 0.2099 - precision: 0.2941 - recall: 0.0022 - val_loss: 0.4117 - val_auc: 0.5806 - val_auc_1: 0.1745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 15/200\n",
      "7197/7197 - 142s - loss: 0.4275 - auc: 0.6032 - auc_1: 0.2106 - precision: 0.3333 - recall: 0.0026 - val_loss: 0.4117 - val_auc: 0.5814 - val_auc_1: 0.1749 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 16/200\n",
      "7197/7197 - 144s - loss: 0.4271 - auc: 0.6040 - auc_1: 0.2119 - precision: 0.2941 - recall: 0.0022 - val_loss: 0.4120 - val_auc: 0.5816 - val_auc_1: 0.1755 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 17/200\n",
      "7197/7197 - 141s - loss: 0.4270 - auc: 0.6053 - auc_1: 0.2127 - precision: 0.3333 - recall: 0.0026 - val_loss: 0.4121 - val_auc: 0.5816 - val_auc_1: 0.1754 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 141s/epoch - 20ms/step\n",
      "Epoch 18/200\n",
      "7197/7197 - 142s - loss: 0.4268 - auc: 0.6066 - auc_1: 0.2130 - precision: 0.3125 - recall: 0.0022 - val_loss: 0.4113 - val_auc: 0.5825 - val_auc_1: 0.1761 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 19/200\n",
      "7197/7197 - 140s - loss: 0.4265 - auc: 0.6067 - auc_1: 0.2132 - precision: 0.2857 - recall: 0.0018 - val_loss: 0.4110 - val_auc: 0.5835 - val_auc_1: 0.1764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 140s/epoch - 19ms/step\n",
      "Epoch 20/200\n",
      "7197/7197 - 140s - loss: 0.4264 - auc: 0.6080 - auc_1: 0.2136 - precision: 0.2857 - recall: 0.0018 - val_loss: 0.4113 - val_auc: 0.5832 - val_auc_1: 0.1768 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 140s/epoch - 19ms/step\n",
      "Epoch 21/200\n",
      "7197/7197 - 140s - loss: 0.4261 - auc: 0.6085 - auc_1: 0.2140 - precision: 0.2857 - recall: 0.0018 - val_loss: 0.4108 - val_auc: 0.5838 - val_auc_1: 0.1769 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 140s/epoch - 19ms/step\n",
      "Epoch 22/200\n",
      "7197/7197 - 140s - loss: 0.4260 - auc: 0.6091 - auc_1: 0.2149 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4111 - val_auc: 0.5830 - val_auc_1: 0.1767 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 140s/epoch - 20ms/step\n",
      "Epoch 23/200\n",
      "7197/7197 - 145s - loss: 0.4258 - auc: 0.6095 - auc_1: 0.2153 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4103 - val_auc: 0.5849 - val_auc_1: 0.1776 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 24/200\n",
      "7197/7197 - 151s - loss: 0.4256 - auc: 0.6095 - auc_1: 0.2162 - precision: 0.3077 - recall: 0.0018 - val_loss: 0.4104 - val_auc: 0.5842 - val_auc_1: 0.1774 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 151s/epoch - 21ms/step\n",
      "Epoch 25/200\n",
      "7197/7197 - 149s - loss: 0.4255 - auc: 0.6105 - auc_1: 0.2162 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4104 - val_auc: 0.5846 - val_auc_1: 0.1778 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 149s/epoch - 21ms/step\n",
      "Epoch 26/200\n",
      "7197/7197 - 142s - loss: 0.4252 - auc: 0.6111 - auc_1: 0.2168 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4106 - val_auc: 0.5840 - val_auc_1: 0.1778 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 27/200\n",
      "7197/7197 - 146s - loss: 0.4251 - auc: 0.6120 - auc_1: 0.2177 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4103 - val_auc: 0.5840 - val_auc_1: 0.1779 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 146s/epoch - 20ms/step\n",
      "Epoch 28/200\n",
      "7197/7197 - 150s - loss: 0.4250 - auc: 0.6127 - auc_1: 0.2178 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4102 - val_auc: 0.5846 - val_auc_1: 0.1781 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 150s/epoch - 21ms/step\n",
      "Epoch 29/200\n",
      "7197/7197 - 148s - loss: 0.4248 - auc: 0.6132 - auc_1: 0.2184 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4099 - val_auc: 0.5845 - val_auc_1: 0.1784 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 148s/epoch - 21ms/step\n",
      "Epoch 30/200\n",
      "7197/7197 - 146s - loss: 0.4247 - auc: 0.6136 - auc_1: 0.2189 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4101 - val_auc: 0.5837 - val_auc_1: 0.1779 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 146s/epoch - 20ms/step\n",
      "Epoch 31/200\n",
      "7197/7197 - 161s - loss: 0.4246 - auc: 0.6140 - auc_1: 0.2193 - precision: 0.3636 - recall: 0.0018 - val_loss: 0.4104 - val_auc: 0.5843 - val_auc_1: 0.1787 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 161s/epoch - 22ms/step\n",
      "Epoch 32/200\n",
      "7197/7197 - 142s - loss: 0.4244 - auc: 0.6148 - auc_1: 0.2191 - precision: 0.3846 - recall: 0.0022 - val_loss: 0.4104 - val_auc: 0.5841 - val_auc_1: 0.1788 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 33/200\n",
      "7197/7197 - 144s - loss: 0.4243 - auc: 0.6154 - auc_1: 0.2198 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4099 - val_auc: 0.5847 - val_auc_1: 0.1789 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 34/200\n",
      "7197/7197 - 147s - loss: 0.4243 - auc: 0.6148 - auc_1: 0.2199 - precision: 0.3333 - recall: 0.0018 - val_loss: 0.4101 - val_auc: 0.5845 - val_auc_1: 0.1788 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 147s/epoch - 20ms/step\n",
      "Epoch 35/200\n",
      "7197/7197 - 146s - loss: 0.4241 - auc: 0.6158 - auc_1: 0.2208 - precision: 0.3636 - recall: 0.0018 - val_loss: 0.4098 - val_auc: 0.5851 - val_auc_1: 0.1793 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 146s/epoch - 20ms/step\n",
      "Epoch 36/200\n",
      "7197/7197 - 143s - loss: 0.4240 - auc: 0.6163 - auc_1: 0.2210 - precision: 0.3846 - recall: 0.0022 - val_loss: 0.4097 - val_auc: 0.5855 - val_auc_1: 0.1795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 37/200\n",
      "7197/7197 - 145s - loss: 0.4239 - auc: 0.6165 - auc_1: 0.2214 - precision: 0.4167 - recall: 0.0022 - val_loss: 0.4100 - val_auc: 0.5853 - val_auc_1: 0.1796 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 38/200\n",
      "7197/7197 - 145s - loss: 0.4238 - auc: 0.6172 - auc_1: 0.2215 - precision: 0.4545 - recall: 0.0022 - val_loss: 0.4095 - val_auc: 0.5854 - val_auc_1: 0.1798 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 39/200\n",
      "7197/7197 - 145s - loss: 0.4238 - auc: 0.6170 - auc_1: 0.2222 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4100 - val_auc: 0.5852 - val_auc_1: 0.1795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 40/200\n",
      "7197/7197 - 144s - loss: 0.4236 - auc: 0.6177 - auc_1: 0.2220 - precision: 0.4545 - recall: 0.0022 - val_loss: 0.4096 - val_auc: 0.5854 - val_auc_1: 0.1802 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 41/200\n",
      "7197/7197 - 144s - loss: 0.4234 - auc: 0.6185 - auc_1: 0.2230 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4095 - val_auc: 0.5860 - val_auc_1: 0.1799 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 42/200\n",
      "7197/7197 - 141s - loss: 0.4234 - auc: 0.6186 - auc_1: 0.2227 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4101 - val_auc: 0.5849 - val_auc_1: 0.1796 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 141s/epoch - 20ms/step\n",
      "Epoch 43/200\n",
      "7197/7197 - 142s - loss: 0.4233 - auc: 0.6199 - auc_1: 0.2227 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4108 - val_auc: 0.5846 - val_auc_1: 0.1800 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 142s/epoch - 20ms/step\n",
      "Epoch 44/200\n",
      "7197/7197 - 148s - loss: 0.4233 - auc: 0.6191 - auc_1: 0.2233 - precision: 0.4545 - recall: 0.0022 - val_loss: 0.4100 - val_auc: 0.5859 - val_auc_1: 0.1803 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 148s/epoch - 21ms/step\n",
      "Epoch 45/200\n",
      "7197/7197 - 148s - loss: 0.4231 - auc: 0.6196 - auc_1: 0.2243 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4093 - val_auc: 0.5860 - val_auc_1: 0.1802 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 148s/epoch - 21ms/step\n",
      "Epoch 46/200\n",
      "7197/7197 - 145s - loss: 0.4230 - auc: 0.6202 - auc_1: 0.2243 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4103 - val_auc: 0.5855 - val_auc_1: 0.1804 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 47/200\n",
      "7197/7197 - 144s - loss: 0.4230 - auc: 0.6202 - auc_1: 0.2249 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4095 - val_auc: 0.5855 - val_auc_1: 0.1805 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 48/200\n",
      "7197/7197 - 144s - loss: 0.4229 - auc: 0.6205 - auc_1: 0.2241 - precision: 0.4545 - recall: 0.0022 - val_loss: 0.4095 - val_auc: 0.5857 - val_auc_1: 0.1807 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 49/200\n",
      "7197/7197 - 150s - loss: 0.4228 - auc: 0.6218 - auc_1: 0.2247 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4100 - val_auc: 0.5853 - val_auc_1: 0.1805 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 150s/epoch - 21ms/step\n",
      "Epoch 50/200\n",
      "7197/7197 - 145s - loss: 0.4227 - auc: 0.6222 - auc_1: 0.2260 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4099 - val_auc: 0.5850 - val_auc_1: 0.1806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 51/200\n",
      "7197/7197 - 143s - loss: 0.4227 - auc: 0.6213 - auc_1: 0.2254 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4099 - val_auc: 0.5854 - val_auc_1: 0.1809 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 52/200\n",
      "7197/7197 - 144s - loss: 0.4226 - auc: 0.6222 - auc_1: 0.2261 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4095 - val_auc: 0.5857 - val_auc_1: 0.1810 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 144s/epoch - 20ms/step\n",
      "Epoch 53/200\n",
      "7197/7197 - 145s - loss: 0.4224 - auc: 0.6230 - auc_1: 0.2265 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4092 - val_auc: 0.5857 - val_auc_1: 0.1806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 145s/epoch - 20ms/step\n",
      "Epoch 54/200\n",
      "7197/7197 - 146s - loss: 0.4224 - auc: 0.6228 - auc_1: 0.2261 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4096 - val_auc: 0.5852 - val_auc_1: 0.1807 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 146s/epoch - 20ms/step\n",
      "Epoch 55/200\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "7197/7197 - 143s - loss: 0.4223 - auc: 0.6235 - auc_1: 0.2273 - precision: 0.5000 - recall: 0.0022 - val_loss: 0.4097 - val_auc: 0.5862 - val_auc_1: 0.1813 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 143s/epoch - 20ms/step\n",
      "Epoch 55: early stopping\n",
      "2253/2253 [==============================] - 26s 12ms/step - loss: 0.4180 - auc: 0.5618 - auc_1: 0.1620 - precision: 0.1111 - recall: 0.0031\n"
     ]
    }
   ],
   "source": [
    "# lstm-vae\n",
    "lstm_readm_model, lstm_readm_preds  = train_eval_pred_model(class_model, 2, 200, readm_lstm_X_train, readm_lstm_X_test,\n",
    "                                        readm_lstm_y_train, readm_lstm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10076/10076 - 214s - loss: 0.2230 - auc: 0.8616 - auc_1: 0.5531 - precision: 0.8898 - recall: 0.1726 - val_loss: 0.2245 - val_auc: 0.8630 - val_auc_1: 0.5312 - val_precision: 0.7443 - val_recall: 0.2646 - 214s/epoch - 21ms/step\n",
      "Epoch 2/200\n",
      "10076/10076 - 205s - loss: 0.2064 - auc: 0.8792 - auc_1: 0.5885 - precision: 0.8082 - recall: 0.3097 - val_loss: 0.2212 - val_auc: 0.8686 - val_auc_1: 0.5397 - val_precision: 0.7083 - val_recall: 0.3091 - 205s/epoch - 20ms/step\n",
      "Epoch 3/200\n",
      "10076/10076 - 205s - loss: 0.2030 - auc: 0.8840 - auc_1: 0.5971 - precision: 0.7951 - recall: 0.3217 - val_loss: 0.2198 - val_auc: 0.8729 - val_auc_1: 0.5446 - val_precision: 0.7048 - val_recall: 0.3232 - 205s/epoch - 20ms/step\n",
      "Epoch 4/200\n",
      "10076/10076 - 204s - loss: 0.2009 - auc: 0.8862 - auc_1: 0.6023 - precision: 0.7908 - recall: 0.3389 - val_loss: 0.2183 - val_auc: 0.8729 - val_auc_1: 0.5472 - val_precision: 0.7474 - val_recall: 0.2929 - 204s/epoch - 20ms/step\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lstm_mort_model, lstm_mort_preds  \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_eval_pred_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmortality_lstm_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmortality_lstm_X_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmortality_lstm_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmortality_lstm_y_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mtrain_eval_pred_model\u001b[0;34m(model, batch_size, epochs, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_eval_pred_model\u001b[39m(model, batch_size, epochs, X_train, X_test, y_train, y_test):\n\u001b[0;32m----> 2\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      6\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_mort_model, lstm_mort_preds  = train_eval_pred_model(class_model, 2, 200, mortality_lstm_X_train, mortality_lstm_X_test,\n",
    "                                       mortality_lstm_y_train, mortality_lstm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_art6AQSVBY"
   },
   "outputs": [],
   "source": [
    "lstm_los_model, lstm_los_preds = train_eval_pred_model(reg_model, 1, 200, los_lstm_X_train, los_lstm_X_test, los_lstm_y_train, los_lstm_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "los_lstm_y_test_std = np.subtract(los_lstm_y_test, np.repeat(np.mean(los_lstm_y_test), len(los_lstm_y_test))) / np.std(los_lstm_y_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(los_lstm_y_test_std, lstm_los_preds, s=25, zorder=10)\n",
    "\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Logistic Regression Model\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "\n",
    "# Implementing Logistic Regression Model\n",
    "def train_test_lr_model(X_train, X_test, y_train, y_test): \n",
    "    \n",
    "    lr_model = LogisticRegression(random_state=random_seed, max_iter=10e6)\n",
    "    \n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lr_model.predict_proba(X_test)\n",
    "    \n",
    "    auroc = metrics.roc_auc_score(y_test, preds[:,1])\n",
    "    print(\"auroc: \", auroc, \"\\n\")\n",
    "    \n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, preds[:,1])\n",
    "    \n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    print(\"auprc: \", auprc, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "\n",
    "# Implementing Linear Regression Model with L1 regularization\n",
    "def train_test_linear_model(X_train, X_test, y_train, y_test): \n",
    "    \n",
    "    lr_model = Lasso(random_state=random_seed, max_iter=10e6)\n",
    "    \n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lr_model.predict(X_test)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_test, preds)\n",
    "    print(\"mse: \", mse, \"\\n\")\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, preds)\n",
    "\n",
    "    print(\"mae: \", mae, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.560997804276486 \n",
      "\n",
      "auprc:  0.16098736920044343 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR lstm readmission\n",
    "\n",
    "\n",
    "readm_lstm_X_train_2d = readm_lstm_X_train.reshape((readm_lstm_X_train.shape[0], readm_lstm_X_train.shape[1]*readm_lstm_X_train.shape[2]))\n",
    "\n",
    "readm_lstm_X_test_2d = readm_lstm_X_test.reshape((readm_lstm_X_test.shape[0], readm_lstm_X_test.shape[1]*readm_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_lr_model(readm_lstm_X_train_2d, readm_lstm_X_test_2d, readm_lstm_y_train, readm_lstm_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.8027163995801716 \n",
      "\n",
      "auprc:  0.39884463204882636 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR lstm ihm\n",
    "\n",
    "\n",
    "\n",
    "mortality_lstm_X_train_2d = mortality_lstm_X_train.reshape((mortality_lstm_X_train.shape[0],\n",
    "                                                          mortality_lstm_X_train.shape[1]*mortality_lstm_X_train.shape[2]))\n",
    "\n",
    "mortality_lstm_X_test_2d = mortality_lstm_X_test.reshape((mortality_lstm_X_test.shape[0],\n",
    "                                                     mortality_lstm_X_test.shape[1]*mortality_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_lr_model(mortality_lstm_X_train_2d, mortality_lstm_X_test_2d, mortality_lstm_y_train, mortality_lstm_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  1.0 \n",
      "\n",
      "mae:  0.6456541924088668 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear regression lstm los\n",
    "\n",
    "\n",
    "los_lstm_X_train_2d = los_lstm_X_train.reshape((los_lstm_X_train.shape[0], los_lstm_X_train.shape[1]*los_lstm_X_train.shape[2]))\n",
    "\n",
    "los_lstm_X_test_2d = los_lstm_X_test.reshape((los_lstm_X_test.shape[0], los_lstm_X_test.shape[1]*los_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_linear_model(los_lstm_X_train_2d, los_lstm_X_test_2d, los_lstm_y_train, los_lstm_y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Implementing XGBoost model\n",
    "def train_test_XGBoost_class(X_train, X_test, y_train, y_test):\n",
    "    xg_class = xgb.XGBClassifier(objective ='binary:logistic', nthread=1, learning_rate = 0.2,\n",
    "                    max_depth = 12, alpha = 12, n_estimators = 35, use_label_encoder = False, eval_metric='logloss')\n",
    "    \n",
    "    xg_class.fit(X_train,y_train)\n",
    "\n",
    "    preds = xg_class.predict_proba(X_test)\n",
    "    \n",
    "    auroc = metrics.roc_auc_score(y_test, preds[:,1])\n",
    "    print(\"auroc: \", auroc, \"\\n\")\n",
    "    \n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, preds[:,1])\n",
    "    \n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    print(\"auprc: \", auprc, \"\\n\")\n",
    "    \n",
    "\n",
    "     \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_XGBoost_reg(X_train, X_test, y_train, y_test):\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', nthread=1, learning_rate = 0.15,\n",
    "                    max_depth = 12, alpha = 12, n_estimators = 30)\n",
    "    \n",
    "    xg_reg.fit(X_train,y_train)\n",
    "\n",
    "    preds = xg_reg.predict(X_test)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_test, preds)\n",
    "    print(\"mse: \", mse, \"\\n\")\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, preds)\n",
    "    print(\"mae: \", mae, \"\\n\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.5612784397147311 \n",
      "\n",
      "auprc:  0.1737035514565878 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB lstm readmission\n",
    "\n",
    "\n",
    "readm_lstm_X_train_2d = readm_lstm_X_train.reshape((readm_lstm_X_train.shape[0], readm_lstm_X_train.shape[1]*readm_lstm_X_train.shape[2]))\n",
    "\n",
    "readm_lstm_X_test_2d = readm_lstm_X_test.reshape((readm_lstm_X_test.shape[0], readm_lstm_X_test.shape[1]*readm_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_class(readm_lstm_X_train_2d, readm_lstm_X_test_2d, readm_lstm_y_train, readm_lstm_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.8858862485900475 \n",
      "\n",
      "auprc:  0.5702378249529821 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR lstm ihm\n",
    "\n",
    "\n",
    "\n",
    "mortality_lstm_X_train_2d = mortality_lstm_X_train.reshape((mortality_lstm_X_train.shape[0],\n",
    "                                                          mortality_lstm_X_train.shape[1]*mortality_lstm_X_train.shape[2]))\n",
    "\n",
    "mortality_lstm_X_test_2d = mortality_lstm_X_test.reshape((mortality_lstm_X_test.shape[0],\n",
    "                                                     mortality_lstm_X_test.shape[1]*mortality_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_class(mortality_lstm_X_train_2d, mortality_lstm_X_test_2d, mortality_lstm_y_train, mortality_lstm_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  0.8700617730395375 \n",
      "\n",
      "mae:  0.5728182847154878 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear regression lstm los\n",
    "\n",
    "\n",
    "los_lstm_X_train_2d = los_lstm_X_train.reshape((los_lstm_X_train.shape[0], los_lstm_X_train.shape[1]*los_lstm_X_train.shape[2]))\n",
    "\n",
    "los_lstm_X_test_2d = los_lstm_X_test.reshape((los_lstm_X_test.shape[0], los_lstm_X_test.shape[1]*los_lstm_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_reg(los_lstm_X_train_2d, los_lstm_X_test_2d, los_lstm_y_train, los_lstm_y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "los_mean_X_train_2d = los_mean_X_train.reshape((los_mean_X_train.shape[0], los_mean_X_train.shape[1]*los_mean_X_train.shape[2]))\n",
    "\n",
    "los_mean_X_test_2d = los_mean_X_test.reshape((los_mean_X_test.shape[0], los_mean_X_test.shape[1]*los_mean_X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mse: 0.8739469989495194 \n",
      "\n",
      "depth: 12 \n",
      "\n",
      "n_est: 30 \n",
      "\n",
      "learning rate:  0.1 \n",
      "\n",
      "alpha:  12 \n",
      "\n",
      "Best mae: 0.4943113124019164 \n",
      "\n",
      "depth: 10 \n",
      "\n",
      "n_est: 30 \n",
      "\n",
      "learning rate:  0.2 \n",
      "\n",
      "alpha:  12 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross-validation xgb regression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Grid search for XGB\n",
    "depths = [12, 15]\n",
    "n_ests = [30, 35]\n",
    "lrs = [0.1, 0.2]\n",
    "alphas = [12, 14]\n",
    "\n",
    "\n",
    "mse_dict = {}\n",
    "mae_dict = {}\n",
    "\n",
    "for depth in depths:\n",
    "    for n_est in n_ests:\n",
    "        for lr in lrs:\n",
    "            for alpha in alphas:\n",
    "\n",
    "                mse_dict[(depth, n_est, lr, alpha)] = 0\n",
    "                mae_dict[(depth, n_est, lr, alpha)] = 0\n",
    "\n",
    "k = 4\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "for train_index, test_index in kf.split(los_mean_X_train_2d, los_mean_y_train):\n",
    "    X_train_kf, X_test_kf = los_mean_X_train_2d[train_index], los_mean_X_train_2d[test_index]\n",
    "    y_train_kf, y_test_kf = los_mean_y_train[train_index], los_mean_y_train[test_index]\n",
    "  \n",
    "\n",
    "    for depth in depths:\n",
    "        for n_est in n_ests:\n",
    "            for lr in lrs:\n",
    "                for alpha in alphas:\n",
    "                    \n",
    "                    \n",
    "                    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', nthread=1, learning_rate = lr,\n",
    "                    max_depth = depth, alpha = alpha, n_estimators = n_est)\n",
    "    \n",
    "                    xg_reg.fit(X_train_kf,y_train_kf)\n",
    "\n",
    "                    preds = xg_reg.predict(X_test_kf)\n",
    "\n",
    "                    cur_mse = metrics.mean_squared_error(y_test_kf, preds)\n",
    "\n",
    "\n",
    "                    cur_mae = metrics.mean_absolute_error(y_test_kf, preds)\n",
    "\n",
    "                    mse_dict[(depth, n_est, lr, alpha)] += cur_mse / k \n",
    "                    mae_dict[(depth, n_est, lr, alpha)] += cur_mae / k\n",
    "\n",
    "\n",
    "best_mse = 100\n",
    "best_mae = 100\n",
    "\n",
    "for key, model_mse in mse_dict.items():\n",
    "    if model_mse < best_mse:\n",
    "        best_mse = model_mse\n",
    "        best_depth = key[0]\n",
    "        best_n_est = key[1]\n",
    "        best_learning_rate = key[2]\n",
    "        best_alpha = key[3]\n",
    "\n",
    "\n",
    "# Finding the best parameters n for mse\n",
    "print('Best mse:', best_mse, '\\n')\n",
    "print('depth:', best_depth, '\\n')\n",
    "print('n_est:', best_n_est, '\\n')\n",
    "print('learning rate: ', best_learning_rate, '\\n')\n",
    "print('alpha: ', best_alpha, '\\n')\n",
    "\n",
    "for key, model_mae in mae_dict.items():\n",
    "    if model_mae < best_mae:\n",
    "        best_mae = model_mae\n",
    "        best_depth = key[0]\n",
    "        best_n_est = key[1]\n",
    "        best_learning_rate = key[2]\n",
    "        best_alpha = key[3]\n",
    "  \n",
    " # Finding the best parameters n for mae\n",
    "print('Best mae:', best_mae, '\\n')\n",
    "print('depth:', best_depth, '\\n')\n",
    "print('n_est:', best_n_est, '\\n')\n",
    "print('learning rate: ', best_learning_rate, '\\n')\n",
    "print('alpha: ', best_alpha, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mimic_iv_omop_modeling_unified_cnn_vae_testing_diff_error_calc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
