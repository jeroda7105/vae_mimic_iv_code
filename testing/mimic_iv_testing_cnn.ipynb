{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0DsFARgE0MOh"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438.0
    },
    "id": "4jqZLo8J1VcH",
    "outputId": "437277b6-2f10-471d-c550-3caa5a4a36b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     0.0     0.0     1.0          0.0   \n",
       "1               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "2               93.0  ...     0.0     0.0     1.0          0.0   \n",
       "3               92.0  ...     0.0     0.0     1.0          0.0   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     0.0                         0.0             0.0   \n",
       "1                     0.0                         0.0             0.0   \n",
       "2                     0.0                         0.0             0.0   \n",
       "3                     0.0                         0.0             0.0   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 0.0          0.0     1.0  \n",
       "1                 0.0          0.0     1.0  \n",
       "2                 0.0          0.0     1.0  \n",
       "3                 0.0          0.0     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Time Series Data\n",
    "\n",
    "# Data by the hour\n",
    "first_48_data = pd.read_csv('../../../../data/datasets/mimiciv_timeseries/mimiciv_timeseries.csv')\n",
    "\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in first_48_data.iterrows():\n",
    "        \n",
    "    # Making gcs scores nan where unobserved\n",
    "    if row['x0_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x0_0.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x0_1.0'] = np.nan\n",
    "\n",
    "    if row['x1_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x1_None'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_Spontaneously'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x1_To Speech'] = np.nan\n",
    "\n",
    "    if row['x2_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x2_Abnormal Flexion'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Abnormal extension'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Flex-withdraws'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Localizes Pain'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_No response'] = np.nan\n",
    "        first_48_data.at[idx, 'x2_Obeys Commands'] = np.nan\n",
    "\n",
    "    if row['x3_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x3_10.0'] = np.nan \n",
    "        first_48_data.at[idx, 'x3_11.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_12.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_13.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_14.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_15.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_3.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_4.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_5.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_6.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_7.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_8.0'] = np.nan\n",
    "        first_48_data.at[idx, 'x3_9.0'] = np.nan\n",
    "\n",
    "\n",
    "    if row['x4_nan'] == 1:\n",
    "        first_48_data.at[idx, 'x4_Confused'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Inappropriate Words'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Incomprehensible sounds'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_No Response-ETT'] = np.nan\n",
    "        first_48_data.at[idx, 'x4_Oriented'] = np.nan\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_8.0</th>\n",
       "      <th>x3_9.0</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_8.0  x3_9.0  x3_nan  x4_Confused  \\\n",
       "0                NaN  ...     NaN     NaN     1.0          NaN   \n",
       "1               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "2               93.0  ...     NaN     NaN     1.0          NaN   \n",
       "3               92.0  ...     NaN     NaN     1.0          NaN   \n",
       "4               92.0  ...     0.0     0.0     0.0          1.0   \n",
       "\n",
       "   x4_Inappropriate Words  x4_Incomprehensible sounds  x4_No Response  \\\n",
       "0                     NaN                         NaN             NaN   \n",
       "1                     NaN                         NaN             NaN   \n",
       "2                     NaN                         NaN             NaN   \n",
       "3                     NaN                         NaN             NaN   \n",
       "4                     0.0                         0.0             0.0   \n",
       "\n",
       "   x4_No Response-ETT  x4_Oriented  x4_nan  \n",
       "0                 NaN          NaN     1.0  \n",
       "1                 NaN          NaN     1.0  \n",
       "2                 NaN          NaN     1.0  \n",
       "3                 NaN          NaN     1.0  \n",
       "4                 0.0          0.0     0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18664949_episode1</td>\n",
       "      <td>18664949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.114583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19793183_episode1</td>\n",
       "      <td>19793183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.467361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15687156_episode1</td>\n",
       "      <td>15687156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14504982_episode1</td>\n",
       "      <td>14504982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  subject_id  episode_num  readmission  \\\n",
       "0           0  11432534_episode1    11432534            1          0.0   \n",
       "1           1  18664949_episode1    18664949            1          0.0   \n",
       "2           2  19793183_episode1    19793183            1          0.0   \n",
       "3           3  15687156_episode1    15687156            1          0.0   \n",
       "4           4  14504982_episode1    14504982            1          0.0   \n",
       "\n",
       "   length_of_stay  mortality  \n",
       "0        7.935417          0  \n",
       "1        5.114583          0  \n",
       "2       20.467361          0  \n",
       "3        0.098611          1  \n",
       "4        9.854167          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading label data\n",
    "\n",
    "label_data = pd.read_csv('mimic_iv_label_data.csv')\n",
    "label_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10000980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10001217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10001725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10002013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  cluster\n",
       "0           0    10000032        1\n",
       "1           1    10000980        1\n",
       "2           2    10001217        1\n",
       "3           3    10001725        1\n",
       "4           4    10002013        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading patient clusters\n",
    "\n",
    "patient_clusters = pd.read_csv('mimic_iv_patient_clusters.csv')\n",
    "patient_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column for subject_id and episode_num\n",
    "\n",
    "subject_w_ep = first_48_data['subject']\n",
    "\n",
    "subject_ids = subject_w_ep.apply(lambda x: int(x.split('_')[0]))\n",
    "episode_nums = subject_w_ep.apply(lambda x: int(x.split('_')[1][7:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>time(hr)</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x3_nan</th>\n",
       "      <th>x4_Confused</th>\n",
       "      <th>x4_Inappropriate Words</th>\n",
       "      <th>x4_Incomprehensible sounds</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            subject  time(hr)  Diastolic blood pressure  \\\n",
       "0           0  11432534_episode1  0.000000                       NaN   \n",
       "1           1  11432534_episode1  0.010556                       NaN   \n",
       "2           2  11432534_episode1  0.027222                      42.0   \n",
       "3           3  11432534_episode1  0.060556                      42.0   \n",
       "4           4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x3_nan  x4_Confused  x4_Inappropriate Words  \\\n",
       "0                NaN  ...     1.0          NaN                     NaN   \n",
       "1               93.0  ...     1.0          NaN                     NaN   \n",
       "2               93.0  ...     1.0          NaN                     NaN   \n",
       "3               92.0  ...     1.0          NaN                     NaN   \n",
       "4               92.0  ...     0.0          1.0                     0.0   \n",
       "\n",
       "   x4_Incomprehensible sounds  x4_No Response  x4_No Response-ETT  \\\n",
       "0                         NaN             NaN                 NaN   \n",
       "1                         NaN             NaN                 NaN   \n",
       "2                         NaN             NaN                 NaN   \n",
       "3                         NaN             NaN                 NaN   \n",
       "4                         0.0             0.0                 0.0   \n",
       "\n",
       "   x4_Oriented  x4_nan  subject_id  episode_num  \n",
       "0          NaN     1.0    11432534            1  \n",
       "1          NaN     1.0    11432534            1  \n",
       "2          NaN     1.0    11432534            1  \n",
       "3          NaN     1.0    11432534            1  \n",
       "4          0.0     0.0    11432534            1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data['subject_id'] = subject_ids\n",
    "first_48_data['episode_num'] = episode_nums\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_48_data.rename(columns={\"time(hr)\": \"Hours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>3710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                      42.0   \n",
       "3             3  11432534_episode1  0.060556                      42.0   \n",
       "4             4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x4_Oriented  x4_nan  subject_id  episode_num  \\\n",
       "0                NaN  ...          NaN     1.0    11432534            1   \n",
       "1               93.0  ...          NaN     1.0    11432534            1   \n",
       "2               93.0  ...          NaN     1.0    11432534            1   \n",
       "3               92.0  ...          NaN     1.0    11432534            1   \n",
       "4               92.0  ...          0.0     0.0    11432534            1   \n",
       "\n",
       "   Unnamed: 0_y  readmission  length_of_stay  mortality  Unnamed: 0  cluster  \n",
       "0             0          0.0        7.935417          0        3710        1  \n",
       "1             0          0.0        7.935417          0        3710        1  \n",
       "2             0          0.0        7.935417          0        3710        1  \n",
       "3             0          0.0        7.935417          0        3710        1  \n",
       "4             0          0.0        7.935417          0        3710        1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging data with labels and cluster to get correct sample\n",
    "\n",
    "first_48_data = first_48_data.merge(label_data, on=['subject', 'subject_id', 'episode_num'])\n",
    "first_48_data = first_48_data.merge(patient_clusters, on='subject_id')\n",
    "\n",
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "print(len(first_48_data.groupby('subject')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0_x', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'Unnamed: 0_y', 'readmission',\n",
      "       'length_of_stay', 'mortality', 'Unnamed: 0', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping 'Unnamed: 0_x' and renaming to 'original_idx' to retain original indexes\n",
    "first_48_data = first_48_data.drop(columns=['Unnamed: 0_y', 'Unnamed: 0'])\n",
    "\n",
    "first_48_data = first_48_data.rename(columns={'Unnamed: 0_x': 'original_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_idx', 'subject', 'Hours', 'Diastolic blood pressure',\n",
      "       'Fraction inspired oxygen', 'Glucose', 'Heart Rate', 'Height',\n",
      "       'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate',\n",
      "       'Systolic blood pressure', 'Temperature', 'Weight', 'pH', 'x0_0.0',\n",
      "       'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously', 'x1_To Pain',\n",
      "       'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan',\n",
      "       'subject_id', 'episode_num', 'readmission', 'length_of_stay',\n",
      "       'mortality', 'cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Diastolic blood pressure', 'Fraction inspired oxygen', 'Glucose',\n",
      "       'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation',\n",
      "       'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight',\n",
      "       'pH', 'x0_0.0', 'x0_1.0', 'x0_nan', 'x1_None', 'x1_Spontaneously',\n",
      "       'x1_To Pain', 'x1_To Speech', 'x1_nan', 'x2_Abnormal Flexion',\n",
      "       'x2_Abnormal extension', 'x2_Flex-withdraws', 'x2_Localizes Pain',\n",
      "       'x2_No response', 'x2_Obeys Commands', 'x2_nan', 'x3_10.0', 'x3_11.0',\n",
      "       'x3_12.0', 'x3_13.0', 'x3_14.0', 'x3_15.0', 'x3_3.0', 'x3_4.0',\n",
      "       'x3_5.0', 'x3_6.0', 'x3_7.0', 'x3_8.0', 'x3_9.0', 'x3_nan',\n",
      "       'x4_Confused', 'x4_Inappropriate Words', 'x4_Incomprehensible sounds',\n",
      "       'x4_No Response', 'x4_No Response-ETT', 'x4_Oriented', 'x4_nan'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(first_48_data.columns[3:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_idx</th>\n",
       "      <th>subject</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Fraction inspired oxygen</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Height</th>\n",
       "      <th>Mean blood pressure</th>\n",
       "      <th>Oxygen saturation</th>\n",
       "      <th>...</th>\n",
       "      <th>x4_No Response</th>\n",
       "      <th>x4_No Response-ETT</th>\n",
       "      <th>x4_Oriented</th>\n",
       "      <th>x4_nan</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>episode_num</th>\n",
       "      <th>readmission</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>mortality</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.027222</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.060556</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11432534_episode1</td>\n",
       "      <td>0.143889</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11432534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.935417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_idx            subject     Hours  Diastolic blood pressure  \\\n",
       "0             0  11432534_episode1  0.000000                       NaN   \n",
       "1             1  11432534_episode1  0.010556                       NaN   \n",
       "2             2  11432534_episode1  0.027222                      42.0   \n",
       "3             3  11432534_episode1  0.060556                      42.0   \n",
       "4             4  11432534_episode1  0.143889                      42.0   \n",
       "\n",
       "   Fraction inspired oxygen  Glucose  Heart Rate  Height  Mean blood pressure  \\\n",
       "0                       NaN      NaN         NaN     NaN                  NaN   \n",
       "1                       NaN      NaN        84.0     NaN                  NaN   \n",
       "2                       NaN      NaN        84.0     NaN                 53.0   \n",
       "3                       NaN      NaN        86.0     NaN                 53.0   \n",
       "4                       NaN      NaN        86.0     NaN                 53.0   \n",
       "\n",
       "   Oxygen saturation  ...  x4_No Response  x4_No Response-ETT  x4_Oriented  \\\n",
       "0                NaN  ...             NaN                 NaN          NaN   \n",
       "1               93.0  ...             NaN                 NaN          NaN   \n",
       "2               93.0  ...             NaN                 NaN          NaN   \n",
       "3               92.0  ...             NaN                 NaN          NaN   \n",
       "4               92.0  ...             0.0                 0.0          0.0   \n",
       "\n",
       "   x4_nan  subject_id  episode_num  readmission  length_of_stay  mortality  \\\n",
       "0     1.0    11432534            1          0.0        7.935417          0   \n",
       "1     1.0    11432534            1          0.0        7.935417          0   \n",
       "2     1.0    11432534            1          0.0        7.935417          0   \n",
       "3     1.0    11432534            1          0.0        7.935417          0   \n",
       "4     0.0    11432534            1          0.0        7.935417          0   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_48_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vx7GR50X1onC",
    "outputId": "6acc984c-8335-4a2f-b716-ce2e977ae03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31489\n"
     ]
    }
   ],
   "source": [
    "# Grouping by admission\n",
    "\n",
    "data = first_48_data.groupby('subject')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  \n",
    "\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "\n",
    "for group_idx, group_rows in data:  \n",
    "    \n",
    "    subjects.append(group_idx)\n",
    "    subject_idx.append(i)\n",
    "    \n",
    "    readm_label.append(group_rows['readmission'].values[0])\n",
    "    mortality_label.append(group_rows['mortality'].values[0])\n",
    "    los_label.append(group_rows['length_of_stay'].values[0])\n",
    "    cluster.append(group_rows['cluster'].values[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # stores totals for variables\n",
    "    cur_matrix = np.empty([48, 48])\n",
    "    cur_matrix[:] = np.nan\n",
    "\n",
    "    # stores counts for variables\n",
    "    cur_counts = np.empty([48, 48])\n",
    "    cur_counts[:] = np.nan\n",
    "\n",
    "    cur_columns = group_rows.columns.values.tolist()\n",
    "    feature_columns = cur_columns[3:-6]\n",
    "\n",
    "    j = 0\n",
    "    for idx, row in group_rows.iterrows():\n",
    "        \n",
    "            \n",
    "        # Modifying cur_data to have data by the hour for 48 hours\n",
    "        if row['Hours'] < j+1 and j < 48:\n",
    "            for k in range(len(feature_columns)):\n",
    "                if not (np.isnan(group_rows.loc[idx, feature_columns[k]])):\n",
    "                    if np.isnan(cur_matrix[j, k]):\n",
    "                        cur_matrix[j, k] = group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] = 1\n",
    "                    else:\n",
    "                        cur_matrix[j, k] += group_rows.loc[idx, feature_columns[k]]\n",
    "                        cur_counts[j, k] += 1\n",
    "                        \n",
    "        else:\n",
    "            if j >= 48:\n",
    "                break\n",
    "            else:\n",
    "                j += 1\n",
    "                \n",
    "\n",
    "    # Getting time series data\n",
    "\n",
    "    X_element = np.divide(cur_matrix, cur_counts)\n",
    "\n",
    "    if i == 0:\n",
    "\n",
    "        # Holds all of the multivariate time series\n",
    "        X = np.array([X_element])\n",
    "\n",
    "    else:\n",
    "        X = np.concatenate((X, np.array([X_element])))\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7LiqNzaB5TU",
    "outputId": "e82a9180-0104-426d-841c-cdccbbd97574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>readmission</th>\n",
       "      <th>mortality</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032_episode1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980_episode1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.806944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001217_episode1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.794444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001217_episode2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.914583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001725_episode1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.994444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subject  subject_idx  readmission  mortality  length_of_stay  \\\n",
       "0  10000032_episode1            0          0.0          0        2.222222   \n",
       "1  10000980_episode1            1          0.0          0        5.806944   \n",
       "2  10001217_episode1            2          1.0          0        6.794444   \n",
       "3  10001217_episode2            3          NaN          0        5.914583   \n",
       "4  10001725_episode1            4          0.0          0        2.994444   \n",
       "\n",
       "   cluster  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame({'subject':subjects, 'subject_idx':subject_idx, 'readmission':readm_label, 'mortality':mortality_label,\n",
    "                  'length_of_stay':los_label, 'cluster':cluster})\n",
    "subjects = []\n",
    "subject_idx = []\n",
    "readm_label = []\n",
    "mortality_label = []\n",
    "los_label = []\n",
    "cluster = []\n",
    "\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "T2z9KMmI1tVF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 33\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Standardizing the data\n",
    "\n",
    "scalers = {}\n",
    "for i in range(X_train.shape[2]):\n",
    "    scalers[i] = preprocessing.StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i]) \n",
    "\n",
    "for i in range(X_test.shape[2]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i]) \n",
    "\n",
    "for i in range(X.shape[2]):\n",
    "    X[:, :, i] = scalers[i].transform(X[:, :, i]) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.20036582976204423, 0.17775456930207437, 0.12269121668293394, 0.17775456930207437, 0.019168285216680847, 0.17775456930207437, 0.17775456930207437, 0.08130735198117317, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437, 0.17775456930207437]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "all_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_2d = np.reshape(X, (X.shape[0]*X.shape[1], X.shape[2]))\n",
    "\n",
    "\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "mean_imputer.fit(X_2d)\n",
    "X_2d = mean_imputer.transform(X_2d)\n",
    "\n",
    "\n",
    "for i in range(X_2d.shape[1]):\n",
    "    all_feature_means.append(np.mean(X_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(all_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwJDX3Ai2GnQ",
    "outputId": "52f717ae-3504-4811-f20a-cc84764a72d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.09987920279910383, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, 0.3625940492800348, 0.4566171176093376, -0.026951689326147627, -0.11808901157400302, -0.07199669000259247, -5.561317025005966e-16, -5.561317025005966e-16, -0.027816122495181478, -5.561317025005966e-16, -0.03771542601618285, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.0517255267568309, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.05797858027354016, -0.037948085096949545, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -5.561317025005966e-16, -0.0373495700991753, -5.561317025005966e-16, 0.0011522622218144013, -0.1193126492824123, -0.00621006890979503, -5.561317025005966e-16, -0.1122734378452095, -5.561317025005966e-16, -0.098805219260766]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "train_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_train_2d = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "\n",
    "train_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "train_mean_imputer.fit(X_train_2d)\n",
    "X_train_2d = train_mean_imputer.transform(X_train_2d)\n",
    "\n",
    "\n",
    "for i in range(X_train_2d.shape[1]):\n",
    "    train_feature_means.append(np.mean(X_train_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q12dIA8z2hsx",
    "outputId": "a7fe45b7-0b1e-4eed-c627-2699bcb41292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31489, 48, 48)\n",
      "[0.1030028290570371, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.24883296789872858, 0.36238176622895285, -0.12539406351832436, -0.10990306785139915, -0.10842122798852537, -0.07174711163129376, 0.016609368340701185, 0.0654413884834812, 0.053703900653218097, 0.8772903210129748, -0.032617594906144014, 0.011494253958953267, 0.014764003867121742, -0.01673144230310153, 0.8772903210129748, -0.025311304149835765, -0.006946143768683178, 0.8772903210129748, 0.8772903210129748, 0.1387755349024727, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.061612438423388184, -0.07264972143415817, -0.08039203564601172, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.06493351645073649, 0.8772903210129748, -0.013698942651471474, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.07014096988932718, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, 0.8772903210129748, -0.0797538903150036, -0.05625997397447844, 0.8772903210129748]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "test_feature_means = []\n",
    "\n",
    "# Reshaping to 2-dimensional data for imputation\n",
    "X_test_2d = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "\n",
    "test_mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "test_mean_imputer.fit(X_test_2d)\n",
    "X_test_2d = test_mean_imputer.transform(X_test_2d)\n",
    "\n",
    "\n",
    "for i in range(X_test_2d.shape[1]):\n",
    "    test_feature_means.append(np.mean(X_test_2d[:][i]))\n",
    "\n",
    "\n",
    "\n",
    "print(test_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "6Q53xXLP2lnd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a random mask for evaluation of imputation \n",
    "\n",
    "def mean_imputation_eval(X, train_feature_means):\n",
    "    iter = 100\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "    \n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4SbKzJc21E7",
    "outputId": "2f997abd-7a40-41f0-f71b-97d38a04fdc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:\n",
      "0.5776177830281686\n",
      "0.015483739134975714 \n",
      "\n",
      "mae:\n",
      "0.3979626500626157\n",
      "0.0006590698783683776 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputation_eval(X_test, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8qPYEc7B3GNQ"
   },
   "outputs": [],
   "source": [
    "def create_mean_imputed_data(X_train, X_test, train_feature_means, test_feature_means):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = train_feature_means[k]\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = train_feature_means[k]\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "\n",
    "    return X_train_imputed, X_test_imputed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iComzTNR4cbF"
   },
   "outputs": [],
   "source": [
    "X_train_mean_imputed, X_test_mean_imputed = create_mean_imputed_data(X_train, X_test, train_feature_means, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "d9GnUNeC40Em"
   },
   "outputs": [],
   "source": [
    "def vae_preprocessing(X_train, X_test):\n",
    "    impute_value = 0.\n",
    "\n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "    train_mask = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    test_mask = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = impute_value\n",
    "                    train_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "                    train_mask[i,j,k] = 1\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = impute_value\n",
    "                    test_mask[i,j,k] = 0\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "                    test_mask[i,j,k] = 1\n",
    "                    \n",
    "    return X_train_imputed, X_test_imputed, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HPBch8O_5uFF"
   },
   "outputs": [],
   "source": [
    "processed_X_train, processed_X_test, train_mask, test_mask = vae_preprocessing(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Co301rq5CDqP"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class vae_model(ABC):\n",
    "\n",
    "    def __init__(self, n_filters, kernel_size, learning_rate,\n",
    "               sequence_length, n_features):\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.latent_dim = 2\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_features = n_features\n",
    "    \n",
    "\n",
    "        if self.kernel_size == 3:\n",
    "            self.nn_dim = 21\n",
    "        elif self.kernel_size == 5:\n",
    "            self.nn_dim = 18\n",
    "        else:\n",
    "            self.kernel_size = 3\n",
    "            self.nn_dim = 21\n",
    "\n",
    "    def set_seed(self, seed):\n",
    "    \n",
    "        tf.random.set_seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def sampling(self, args):\n",
    "      \n",
    "        latent_dim = 2\n",
    "        z_mean, z_log_sigma = args\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1)\n",
    "\n",
    "        return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "\n",
    "    def vae_loss(self, inp, mask, out, z_log_sigma, z_mean):\n",
    "        masked_input = tf.math.multiply(inp, mask)\n",
    "        masked_output = tf.math.multiply(out, mask)\n",
    "\n",
    "        #mse = np.sum(np.square(np.subtract(masked_output, masked_input))) / np.sum(mask)\n",
    "        mse = K.sum(K.square(masked_output - masked_input)) / K.sum(mask)\n",
    "\n",
    "        reconstruction = mse * self.sequence_length\n",
    "        kl = -0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma))\n",
    "\n",
    "        return reconstruction + kl\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ev9NJEg-58HO"
   },
   "outputs": [],
   "source": [
    "class cnn_vae(vae_model):\n",
    "\n",
    "    def get_model(self):\n",
    "  \n",
    "\n",
    "        self.set_seed(random_seed)\n",
    "\n",
    "        # encoder\n",
    "\n",
    "        inp = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "        mask = tf.keras.Input(shape=(self.sequence_length, self.n_features))\n",
    "\n",
    "\n",
    "        conv = tf.keras.layers.Conv1D(filters = self.n_filters, kernel_size = self.kernel_size, activation='relu')(inp)\n",
    "        print(conv.shape)\n",
    "\n",
    "        max_pool = tf.keras.layers.MaxPool1D(pool_size = 2)(conv) \n",
    "\n",
    "        conv = tf.keras.layers.Conv1D(filters = self.n_filters/2, kernel_size = self.kernel_size, activation='relu')(max_pool)\n",
    "        print(conv.shape)\n",
    "\n",
    "        enc = tf.keras.layers.Flatten()(conv)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*8, activation=\"relu\")(enc)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*4, activation=\"relu\")(enc)\n",
    "\n",
    "        enc = tf.keras.layers.Dense(self.nn_dim*2, activation=\"relu\")(enc)\n",
    "\n",
    "        z = tf.keras.layers.Dense(self.nn_dim, activation=\"relu\")(enc)\n",
    "\n",
    "        z_mean = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "        z_log_sigma = tf.keras.layers.Dense(self.latent_dim)(z)\n",
    "\n",
    "        encoder = tf.keras.Model([inp], [z_mean, z_log_sigma])\n",
    "\n",
    "        # decoder\n",
    "\n",
    "        inp_z = tf.keras.Input(shape=(self.latent_dim,))\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim)(inp_z)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*2)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*4)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Dense(self.nn_dim*8)(dec)\n",
    "\n",
    "        dec = tf.keras.layers.Reshape((self.nn_dim, 8))(dec)\n",
    "\n",
    "        deconv = tf.keras.layers.Conv1DTranspose(filters=self.n_filters/2, kernel_size=self.kernel_size)(dec)\n",
    "        print(deconv.shape)\n",
    "\n",
    "        upsample = tf.keras.layers.UpSampling1D(2)(deconv)\n",
    "\n",
    "        deconv = tf.keras.layers.Conv1DTranspose(filters=self.n_features, kernel_size=self.kernel_size)(upsample)\n",
    "        print(deconv.shape)\n",
    "\n",
    "\n",
    "        out = deconv\n",
    "\n",
    "\n",
    "        decoder = tf.keras.Model([inp_z], out) \n",
    "\n",
    "        # encoder and decoder \n",
    "\n",
    "        z_mean, z_log_sigma = encoder([inp])\n",
    "        z = tf.keras.layers.Lambda(self.sampling)([z_mean, z_log_sigma])\n",
    "        pred = decoder([z])\n",
    "\n",
    "        vae = tf.keras.Model([inp,  mask], pred)\n",
    "        vae.add_loss(self.vae_loss(inp, mask, pred, z_log_sigma, z_mean))\n",
    "        vae.compile(loss=None, optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "\n",
    "        return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pwKhQRmD8sWn"
   },
   "outputs": [],
   "source": [
    "def train_eval_vae_model(model, processed_X_train, processed_X_test, train_mask, test_mask, batch_size):\n",
    "  \n",
    "    es = EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "    model.fit([processed_X_train, train_mask], batch_size=batch_size, validation_split=0.2, epochs=100, shuffle=False, callbacks=[es])\n",
    "\n",
    "\n",
    "    vae = tf.keras.Model(model.input, model.output)\n",
    "\n",
    "    reconstruc_train = vae.predict([processed_X_train,  train_mask])\n",
    "    reconstruc_test = vae.predict([processed_X_test, test_mask])\n",
    "\n",
    "    mse = 0\n",
    "    mae = 0\n",
    "\n",
    "    #print(mask_X_test_imputed[1])\n",
    "    masked_reconstruction = tf.math.multiply(reconstruc_test, test_mask)\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(processed_X_test.shape[0]):\n",
    "        mse += np.sum(np.square(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "        mae += np.sum(np.absolute(np.subtract(processed_X_test[i], masked_reconstruction[i]))) / np.sum(test_mask[i])\n",
    "\n",
    "\n",
    "    print(\"test mse: \", mse / processed_X_test.shape[0])\n",
    "    print(\"test mae: \", mae / processed_X_test.shape[0], \"\\n\")\n",
    "\n",
    "    return model, reconstruc_train, reconstruc_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TxadxrVYByDt"
   },
   "outputs": [],
   "source": [
    "def vae_masked_eval(X, vae, batch_size):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        # imputing on the random mask data\n",
    "        imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "        rand_X_imputed = imputated_data\n",
    "\n",
    "        #print(rand_X_test_imputed)\n",
    "\n",
    "\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        rand_X_imputed = np.where(rand_mask==0, rand_X_imputed, 0)\n",
    "        rand_X_imputed = np.where(np.isnan(X), 0, rand_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            # mse += np.mean(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            # mae += np.mean(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i])))\n",
    "            mse += np.sum(np.square(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], rand_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        mse_list.append(mse / n_samples)\n",
    "        mae_list.append(mae / n_samples)\n",
    "\n",
    "\n",
    "    print(\"mse:\")\n",
    "    print(np.mean(mse_list))\n",
    "    print(np.std(mse_list), \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"mae:\")\n",
    "    print(np.mean(mae_list))\n",
    "    print(np.std(mae_list), \"\\n\")\n",
    "\n",
    "    return np.mean(mse_list), np.mean(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_vae_mean_imp_eval(X, vae, batch_size, train_feature_means):\n",
    "    # Creating a random mask for evaluation of imputation \n",
    "\n",
    "    iter = 30\n",
    "    vae_mse_list = []\n",
    "    vae_mae_list = []\n",
    "    \n",
    "    mean_mse_list = []\n",
    "    mean_mae_list = []\n",
    "    \n",
    "    diff_mse_list = []\n",
    "    diff_mae_list = []\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    rand_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    mask_X_imputed = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "    rand_mask = np.empty([X.shape[0], X.shape[1], X.shape[2]])\n",
    "\n",
    "    for j in range(iter):\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            rand_mask[i] = np.random.randint(2, size=(X.shape[1], X.shape[2]))\n",
    "\n",
    "        rand_mask = np.where(np.isnan(X), 0, rand_mask)\n",
    "\n",
    "        vae_mse = 0\n",
    "        vae_mae = 0\n",
    "        \n",
    "        mean_mse = 0\n",
    "        mean_mae = 0\n",
    "\n",
    "        # Actual mask of observations for comparison\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, X)\n",
    "        mask_X = np.where(np.isnan(X), 0, 1)\n",
    "        # Random mask for evaluation\n",
    "        rand_X_imputed = np.where(rand_mask==0, 0, mask_X_imputed)\n",
    "        #print(rand_X_test_imputed[i])\n",
    "\n",
    "        #print(mask_X_test_imputed[i].shape)\n",
    "\n",
    "        \n",
    "        # Performing and evaluating vae imputation\n",
    "        vae_imputated_data = vae.predict([rand_X_imputed, rand_mask], batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # Only considering observations where actual was randomly masked out\n",
    "        vae_imputated_data = np.where(rand_mask==0, vae_imputated_data, 0)\n",
    "        vae_imputated_data = np.where(np.isnan(X), 0, vae_imputated_data)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            vae_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "            vae_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], vae_imputated_data[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "        vae_mse_list.append(vae_mse / n_samples)\n",
    "        vae_mae_list.append(vae_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Performing and evaluating mean imputation\n",
    "        rand_X_imputed = np.where(rand_mask==0, np.nan, mask_X_imputed)\n",
    "        mean_X_imputed = np.where(np.isnan(rand_X_imputed), train_feature_means,  rand_X_imputed)\n",
    "        \n",
    "        \n",
    "        mean_X_imputed = np.where(rand_mask==0, mean_X_imputed, 0)\n",
    "        mean_X_imputed = np.where(np.isnan(X), 0, mean_X_imputed)\n",
    "\n",
    "        mask_X_imputed = np.where(rand_mask==0, mask_X_imputed, 0)\n",
    "        mask_X_imputed = np.where(np.isnan(X), 0, mask_X_imputed)\n",
    "\n",
    "        rand_error_mask = np.where(rand_mask==0, 1, 0)\n",
    "        rand_error_mask = np.where(np.isnan(X), 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(rand_X_imputed.shape[0]):\n",
    "            mean_mse += np.sum(np.square(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "            mean_mae += np.sum(np.absolute(np.subtract(mask_X_imputed[i], mean_X_imputed[i]))) / np.sum(rand_error_mask[i])\n",
    "\n",
    "            \n",
    "        mean_mse_list.append(mean_mse / n_samples)\n",
    "        mean_mae_list.append(mean_mae / n_samples)\n",
    "        \n",
    "        \n",
    "        # Adding the differences of the mean errors\n",
    "        diff_mse_list.append((vae_mse / n_samples) - (mean_mse / n_samples))\n",
    "        \n",
    "        diff_mae_list.append((vae_mae / n_samples) - (mean_mae / n_samples))\n",
    "        \n",
    "\n",
    "\n",
    "    print(\"vae imputation mse:\")\n",
    "    print(\"mean: \", np.mean(vae_mse_list))\n",
    "    print(\"std dev: \", np.std(vae_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"vae imputation mae:\")\n",
    "    print(\"mean: \", np.mean(vae_mae_list))\n",
    "    print(\"std dev: \", np.std(vae_mae_list), \"\\n\\n\")\n",
    "\n",
    "    \n",
    "    print(\"mean inputation mse:\")\n",
    "    print(\"mean: \", np.mean(mean_mse_list))\n",
    "    print(\"std dev: \", np.std(mean_mse_list), \"\\n\")\n",
    "    \n",
    "    print(\"mean imputation mae:\")\n",
    "    print(\"mean: \", np.mean(mean_mae_list))\n",
    "    print(\"std dev: \", np.std(mean_mae_list), \"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"mean difference in mse:\")\n",
    "    print(\"mean: \", np.mean(diff_mse_list))\n",
    "    print(\"std dev: \", np.std(diff_mse_list), \"\\n\")\n",
    "\n",
    "    print(\"mean difference in mae:\")\n",
    "    print(\"mean: \", np.mean(diff_mae_list))\n",
    "    print(\"std dev: \", np.std(diff_mae_list), \"\\n\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhSubm4Lfm4J",
    "outputId": "6ec47709-e89b-49a3-919b-0ccab91bc5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 44, 32)\n",
      "(None, 18, 16)\n",
      "(None, 22, 16)\n",
      "(None, 48, 48)\n",
      "Epoch 1/100\n",
      "20152/20152 [==============================] - 190s 9ms/step - loss: 43.0898 - val_loss: 43.4776\n",
      "Epoch 2/100\n",
      "20152/20152 [==============================] - 185s 9ms/step - loss: 42.0445 - val_loss: 42.9030\n",
      "Epoch 3/100\n",
      "20152/20152 [==============================] - 184s 9ms/step - loss: 41.5354 - val_loss: 42.2095\n",
      "Epoch 4/100\n",
      "20152/20152 [==============================] - 184s 9ms/step - loss: 41.2158 - val_loss: 42.0479\n",
      "Epoch 5/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 41.0528 - val_loss: 41.9464\n",
      "Epoch 6/100\n",
      "20152/20152 [==============================] - 184s 9ms/step - loss: 41.0066 - val_loss: 42.0873\n",
      "Epoch 7/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.9325 - val_loss: 41.9834\n",
      "Epoch 8/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.9639 - val_loss: 41.9584\n",
      "Epoch 9/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.9084 - val_loss: 42.1087\n",
      "Epoch 10/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.8869 - val_loss: 41.9838\n",
      "Epoch 11/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.8702 - val_loss: 41.9897\n",
      "Epoch 12/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.8522 - val_loss: 42.0444\n",
      "Epoch 13/100\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.8353 - val_loss: 42.0354\n",
      "Epoch 14/100\n",
      "20152/20152 [==============================] - 187s 9ms/step - loss: 40.8000 - val_loss: 42.0894\n",
      "Epoch 15/100\n",
      "20150/20152 [============================>.] - ETA: 0s - loss: 40.8232Restoring model weights from the end of the best epoch: 5.\n",
      "20152/20152 [==============================] - 183s 9ms/step - loss: 40.8233 - val_loss: 42.0055\n",
      "Epoch 15: early stopping\n",
      "test mse:  981394.7215399777\n",
      "test mae:  1.3947493973305258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_vae_instance = cnn_vae(n_filters=32, kernel_size=5, learning_rate=1e-4, \n",
    "                                    sequence_length=48, n_features=48)\n",
    "\n",
    "\n",
    "cnn_vae_model = cnn_vae_instance.get_model()\n",
    "\n",
    "trained_cnn_vae_model, cnn_reconstruc_train, cnn_reconstruc_test = train_eval_vae_model(cnn_vae_model, \n",
    "                                                processed_X_train, processed_X_test, train_mask, test_mask, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae imputation mse:\n",
      "mean:  95695.37024899418\n",
      "std dev:  76539.89213454461 \n",
      "\n",
      "vae imputation mae:\n",
      "mean:  0.2996553933472536\n",
      "std dev:  0.04136853352412432 \n",
      "\n",
      "\n",
      "mean inputation mse:\n",
      "mean:  95698.62314021408\n",
      "std dev:  76585.49441238752 \n",
      "\n",
      "mean imputation mae:\n",
      "mean:  0.3090631891654669\n",
      "std dev:  0.05412419471545464 \n",
      "\n",
      "\n",
      "mean difference in mse:\n",
      "mean:  -3.252891219889283\n",
      "std dev:  92.02925245678345 \n",
      "\n",
      "mean difference in mae:\n",
      "mean:  -0.009407795818213362\n",
      "std dev:  0.013041716208218663 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paired_vae_mean_imp_eval(X, trained_cnn_vae_model, 1, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae imputation mse:\n",
      "mean:  478497.9001073111\n",
      "std dev:  399995.8648400723 \n",
      "\n",
      "vae imputation mae:\n",
      "mean:  0.6524809868884733\n",
      "std dev:  0.2219174195258939 \n",
      "\n",
      "\n",
      "mean inputation mse:\n",
      "mean:  478474.54743532446\n",
      "std dev:  400223.37878829875 \n",
      "\n",
      "mean imputation mae:\n",
      "mean:  0.5989994963248118\n",
      "std dev:  0.28688430144299704 \n",
      "\n",
      "\n",
      "mean difference in mse:\n",
      "mean:  23.352671986756366\n",
      "std dev:  443.341229320458 \n",
      "\n",
      "mean difference in mae:\n",
      "mean:  0.053481490563661575\n",
      "std dev:  0.06607437961484512 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paired evaluation on test set\n",
    "\n",
    "paired_vae_mean_imp_eval(X_test, trained_cnn_vae_model, 1, train_feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339.0
    },
    "id": "ZZ7l1FCGkn69",
    "outputId": "0b8153bc-076a-4620-b57a-9f9a14d6e76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd9ca1d5340>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(cnn_reconstruc_test[a][:,b], label='reconstructed', c='red')\n",
    "plt.plot(processed_X_test[a][:,b], c='blue', label='original', alpha=0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-dvIbnsBCkG6"
   },
   "outputs": [],
   "source": [
    "def imputed_vae_data(X_train, X_test, reconstruc_train, reconstruc_test):\n",
    "  \n",
    "    X_train_imputed = np.empty([X_train.shape[0], X_train.shape[1], X_train.shape[2]])\n",
    "    X_test_imputed = np.empty([X_test.shape[0], X_test.shape[1], X_test.shape[2]])\n",
    "\n",
    "\n",
    "    # Impute original with reconstruction\n",
    "\n",
    "    for i in range(X_train.shape[0]):\n",
    "        for j in range(X_train.shape[1]):\n",
    "            for k in range(X_train.shape[2]):\n",
    "                if np.isnan(X_train[i,j,k]):\n",
    "                    X_train_imputed[i,j,k] = reconstruc_train[i,j,k]\n",
    "                else:\n",
    "                    X_train_imputed[i,j,k] = X_train[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(X_test.shape[1]):\n",
    "            for k in range(X_test.shape[2]):\n",
    "                if np.isnan(X_test[i,j,k]):\n",
    "                    X_test_imputed[i,j,k] = reconstruc_test[i,j,k]\n",
    "                else:\n",
    "                    X_test_imputed[i,j,k] = X_test[i,j,k]\n",
    "\n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_X_train_imputed, cnn_X_test_imputed = imputed_vae_data(X_train, X_test, cnn_reconstruc_train, cnn_reconstruc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "fE44FC8KFaL2"
   },
   "outputs": [],
   "source": [
    "def readm_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    readm_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    readm_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                readm_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                readm_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "\n",
    "\n",
    "    readm_y_train = y_train['readmission']\n",
    "    readm_y_test = y_test['readmission']\n",
    "\n",
    "\n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(readm_X_train.shape[0]):\n",
    "        if np.isnan(y_train['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(readm_X_test.shape[0]):\n",
    "        if np.isnan(y_test['readmission'].values[i]) or y_train['mortality'].values[i] == 1:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    readm_X_train = np.delete(readm_X_train, rm_idx_train, 0)\n",
    "    readm_y_train = np.delete(np.array(readm_y_train), rm_idx_train, 0)\n",
    "\n",
    "    readm_X_test = np.delete(readm_X_test, rm_idx_test, 0)\n",
    "    readm_y_test = np.delete(np.array(readm_y_test), rm_idx_test, 0)\n",
    "\n",
    "    #print(readm_X_train.shape)\n",
    "    #print(readm_y_train.shape)\n",
    "\n",
    "    #print(readm_X_test.shape)\n",
    "    #print(readm_y_test.shape)\n",
    "\n",
    "    #print(np.where(readm_y_train == 1))\n",
    "    #print(np.where(readm_y_test == 1))  \n",
    "    return readm_X_train, readm_X_test, readm_y_train, readm_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "e9Nk7yYjFk_n"
   },
   "outputs": [],
   "source": [
    "def mortality_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Mortality\n",
    "    mortality_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    mortality_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                mortality_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                mortality_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "    mortality_y_train = y_train['mortality']\n",
    "    mortality_y_test = y_test['mortality']\n",
    "\n",
    "\n",
    "    #print(np.where(mortality_y_train == 1))\n",
    "    #print(np.where(mortality_y_test == 1))\n",
    "    return mortality_X_train, mortality_X_test, mortality_y_train, mortality_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GNeU2yqMFlHo"
   },
   "outputs": [],
   "source": [
    "def los_preprocessing(X_train_imputed, X_test_imputed, y_train, y_test):\n",
    "    # Processing Data for Length of Stay\n",
    "    los_X_train = np.empty([X_train_imputed.shape[0], X_train_imputed.shape[1], X_train_imputed.shape[2]])\n",
    "    los_X_test = np.empty([X_test_imputed.shape[0], X_test_imputed.shape[1], X_test_imputed.shape[2]])\n",
    "\n",
    "    for i in range(X_train_imputed.shape[0]):\n",
    "        for j in range(X_train_imputed.shape[1]):\n",
    "            for k in range(X_train_imputed.shape[2]):\n",
    "                los_X_train[i,j,k] = X_train_imputed[i,j,k]\n",
    "\n",
    "\n",
    "    for i in range(X_test_imputed.shape[0]):\n",
    "        for j in range(X_test_imputed.shape[1]):\n",
    "            for k in range(X_test_imputed.shape[2]):\n",
    "                los_X_test[i,j,k] = X_test_imputed[i,j,k]\n",
    "\n",
    "                \n",
    "    los_y_train = y_train['length_of_stay']\n",
    "    los_y_test = y_test['length_of_stay']\n",
    "    \n",
    "    rm_idx_train = []\n",
    "    rm_idx_test = []\n",
    "\n",
    "\n",
    "    for i in range(los_X_train.shape[0]):\n",
    "        if los_y_train.values[i] < 0:\n",
    "            rm_idx_train.append(i)\n",
    "\n",
    "    for i in range(los_X_test.shape[0]):\n",
    "        if los_y_test.values[i] < 0:\n",
    "            rm_idx_test.append(i)\n",
    "\n",
    "    los_X_train = np.delete(los_X_train, rm_idx_train, 0)\n",
    "    los_y_train = np.delete(np.array(los_y_train), rm_idx_train, 0)\n",
    "\n",
    "    los_X_test = np.delete(los_X_test, rm_idx_test, 0)\n",
    "    los_y_test = np.delete(np.array(los_y_test), rm_idx_test, 0)\n",
    "    \n",
    "          \n",
    "    los_y_train = (los_y_train - np.full(len(los_y_train), np.mean(los_y_train))) / np.std(los_y_train)\n",
    "    \n",
    "    los_y_test = (los_y_test - np.full(len(los_y_test), np.mean(los_y_test))) / np.std(los_y_test)\n",
    "  \n",
    "\n",
    "    return los_X_train, los_X_test, los_y_train, los_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BmHqSFHGzPk",
    "outputId": "071a96e0-8ffb-4bd6-dbe9-dd8f96ef0342"
   },
   "outputs": [],
   "source": [
    "# Readmission data for each method\n",
    "readm_mean_X_train, readm_mean_X_test, readm_mean_y_train, readm_mean_y_test = readm_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "readm_cnn_X_train, readm_cnn_X_test, readm_cnn_y_train, readm_cnn_y_test = readm_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mortality data for each method\n",
    "mortality_mean_X_train, mortality_mean_X_test, mortality_mean_y_train, mortality_mean_y_test = mortality_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "mortality_cnn_X_train, mortality_cnn_X_test, mortality_cnn_y_train, mortality_cnn_y_test = mortality_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Length of stay data for each method\n",
    "los_mean_X_train, los_mean_X_test, los_mean_y_train, los_mean_y_test = los_preprocessing(X_train_mean_imputed, \n",
    "                                                                               X_test_mean_imputed, y_train, y_test)\n",
    "los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test = los_preprocessing(cnn_X_train_imputed, \n",
    "                                                                           cnn_X_test_imputed, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "OPgncEK1QFNV"
   },
   "outputs": [],
   "source": [
    "# LSTM Classification Model\n",
    "\n",
    "es = EarlyStopping(patience=20, verbose=1, min_delta=0.0001, monitor='val_auc', mode='auto', restore_best_weights=True)\n",
    "\n",
    "class_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "\n",
    "class_model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.AUC(curve='PR'), \n",
    "                      tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "dfNt7NW2QRXj"
   },
   "outputs": [],
   "source": [
    "# LSTM Regression Model\n",
    "\n",
    "es = EarlyStopping(patience=10, verbose=1, min_delta=0.0001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "\n",
    "reg_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh', return_sequences=True),\n",
    "  tf.keras.layers.LSTM(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='relu'),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "reg_model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_pred_model(model, batch_size, epochs, X_train, X_test, y_train, y_test):\n",
    "    hist = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=2, callbacks=[es])\n",
    "    \n",
    "    predictions = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    metrics = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "    \n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7hBaf-KwOBc9",
    "outputId": "b2773897-6b07-480a-9561-02fa4079d950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7197/7197 - 136s - loss: 0.5650 - auc: 0.4947 - auc_1: 0.1564 - precision: 0.1766 - recall: 0.0326 - val_loss: 0.4615 - val_auc: 0.4810 - val_auc_1: 0.1380 - val_precision: 0.1111 - val_recall: 0.0057 - 136s/epoch - 19ms/step\n",
      "Epoch 2/200\n",
      "7197/7197 - 126s - loss: 0.4587 - auc: 0.4739 - auc_1: 0.1455 - precision: 0.1250 - recall: 0.0018 - val_loss: 0.4296 - val_auc: 0.4820 - val_auc_1: 0.1374 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 3/200\n",
      "7197/7197 - 129s - loss: 0.4463 - auc: 0.4814 - auc_1: 0.1466 - precision: 0.2500 - recall: 4.4053e-04 - val_loss: 0.4229 - val_auc: 0.4805 - val_auc_1: 0.1370 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 129s/epoch - 18ms/step\n",
      "Epoch 4/200\n",
      "7197/7197 - 129s - loss: 0.4418 - auc: 0.4876 - auc_1: 0.1486 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4199 - val_auc: 0.4832 - val_auc_1: 0.1379 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 129s/epoch - 18ms/step\n",
      "Epoch 5/200\n",
      "7197/7197 - 125s - loss: 0.4390 - auc: 0.4975 - auc_1: 0.1516 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4178 - val_auc: 0.4813 - val_auc_1: 0.1377 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 6/200\n",
      "7197/7197 - 126s - loss: 0.4373 - auc: 0.5112 - auc_1: 0.1568 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4172 - val_auc: 0.4888 - val_auc_1: 0.1404 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 7/200\n",
      "7197/7197 - 125s - loss: 0.4362 - auc: 0.5253 - auc_1: 0.1637 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4163 - val_auc: 0.4906 - val_auc_1: 0.1417 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 8/200\n",
      "7197/7197 - 127s - loss: 0.4354 - auc: 0.5347 - auc_1: 0.1689 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4159 - val_auc: 0.4980 - val_auc_1: 0.1445 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 127s/epoch - 18ms/step\n",
      "Epoch 9/200\n",
      "7197/7197 - 127s - loss: 0.4348 - auc: 0.5428 - auc_1: 0.1748 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4154 - val_auc: 0.4995 - val_auc_1: 0.1466 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 127s/epoch - 18ms/step\n",
      "Epoch 10/200\n",
      "7197/7197 - 126s - loss: 0.4343 - auc: 0.5486 - auc_1: 0.1797 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4154 - val_auc: 0.5040 - val_auc_1: 0.1477 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 11/200\n",
      "7197/7197 - 126s - loss: 0.4339 - auc: 0.5523 - auc_1: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4152 - val_auc: 0.5067 - val_auc_1: 0.1493 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 12/200\n",
      "7197/7197 - 126s - loss: 0.4335 - auc: 0.5568 - auc_1: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4148 - val_auc: 0.5151 - val_auc_1: 0.1527 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 13/200\n",
      "7197/7197 - 126s - loss: 0.4332 - auc: 0.5615 - auc_1: 0.1884 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4147 - val_auc: 0.5173 - val_auc_1: 0.1533 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 14/200\n",
      "7197/7197 - 125s - loss: 0.4329 - auc: 0.5645 - auc_1: 0.1906 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4147 - val_auc: 0.5171 - val_auc_1: 0.1542 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 15/200\n",
      "7197/7197 - 125s - loss: 0.4325 - auc: 0.5664 - auc_1: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4145 - val_auc: 0.5188 - val_auc_1: 0.1559 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 16/200\n",
      "7197/7197 - 125s - loss: 0.4322 - auc: 0.5704 - auc_1: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4146 - val_auc: 0.5229 - val_auc_1: 0.1578 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 17/200\n",
      "7197/7197 - 126s - loss: 0.4319 - auc: 0.5732 - auc_1: 0.1962 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4146 - val_auc: 0.5260 - val_auc_1: 0.1588 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 18/200\n",
      "7197/7197 - 126s - loss: 0.4316 - auc: 0.5752 - auc_1: 0.1976 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4144 - val_auc: 0.5272 - val_auc_1: 0.1595 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 19/200\n",
      "7197/7197 - 126s - loss: 0.4313 - auc: 0.5784 - auc_1: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4141 - val_auc: 0.5296 - val_auc_1: 0.1608 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 20/200\n",
      "7197/7197 - 126s - loss: 0.4310 - auc: 0.5803 - auc_1: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4143 - val_auc: 0.5297 - val_auc_1: 0.1607 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 21/200\n",
      "7197/7197 - 126s - loss: 0.4307 - auc: 0.5827 - auc_1: 0.2004 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4141 - val_auc: 0.5338 - val_auc_1: 0.1627 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 22/200\n",
      "7197/7197 - 126s - loss: 0.4304 - auc: 0.5849 - auc_1: 0.2015 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4143 - val_auc: 0.5344 - val_auc_1: 0.1626 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 23/200\n",
      "7197/7197 - 126s - loss: 0.4302 - auc: 0.5855 - auc_1: 0.2026 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4137 - val_auc: 0.5372 - val_auc_1: 0.1639 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 24/200\n",
      "7197/7197 - 125s - loss: 0.4300 - auc: 0.5885 - auc_1: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4137 - val_auc: 0.5383 - val_auc_1: 0.1645 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 125s/epoch - 17ms/step\n",
      "Epoch 25/200\n",
      "7197/7197 - 126s - loss: 0.4298 - auc: 0.5889 - auc_1: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4139 - val_auc: 0.5391 - val_auc_1: 0.1647 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 26/200\n",
      "7197/7197 - 126s - loss: 0.4295 - auc: 0.5908 - auc_1: 0.2047 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4140 - val_auc: 0.5422 - val_auc_1: 0.1661 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 27/200\n",
      "7197/7197 - 126s - loss: 0.4293 - auc: 0.5919 - auc_1: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4136 - val_auc: 0.5412 - val_auc_1: 0.1655 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 28/200\n",
      "7197/7197 - 126s - loss: 0.4292 - auc: 0.5921 - auc_1: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4137 - val_auc: 0.5434 - val_auc_1: 0.1667 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 29/200\n",
      "7197/7197 - 126s - loss: 0.4290 - auc: 0.5935 - auc_1: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4135 - val_auc: 0.5454 - val_auc_1: 0.1676 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 30/200\n",
      "7197/7197 - 126s - loss: 0.4289 - auc: 0.5939 - auc_1: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4137 - val_auc: 0.5434 - val_auc_1: 0.1669 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 31/200\n",
      "7197/7197 - 126s - loss: 0.4287 - auc: 0.5951 - auc_1: 0.2079 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4139 - val_auc: 0.5476 - val_auc_1: 0.1687 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 32/200\n",
      "7197/7197 - 127s - loss: 0.4286 - auc: 0.5956 - auc_1: 0.2078 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4141 - val_auc: 0.5458 - val_auc_1: 0.1690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 127s/epoch - 18ms/step\n",
      "Epoch 33/200\n",
      "7197/7197 - 126s - loss: 0.4284 - auc: 0.5976 - auc_1: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4134 - val_auc: 0.5481 - val_auc_1: 0.1696 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 34/200\n",
      "7197/7197 - 126s - loss: 0.4283 - auc: 0.5972 - auc_1: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4140 - val_auc: 0.5480 - val_auc_1: 0.1694 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 35/200\n",
      "7197/7197 - 127s - loss: 0.4282 - auc: 0.5977 - auc_1: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4136 - val_auc: 0.5472 - val_auc_1: 0.1694 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 127s/epoch - 18ms/step\n",
      "Epoch 36/200\n",
      "7197/7197 - 126s - loss: 0.4281 - auc: 0.5984 - auc_1: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4134 - val_auc: 0.5494 - val_auc_1: 0.1702 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 37/200\n",
      "7197/7197 - 126s - loss: 0.4279 - auc: 0.5984 - auc_1: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4137 - val_auc: 0.5507 - val_auc_1: 0.1704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 38/200\n",
      "7197/7197 - 126s - loss: 0.4279 - auc: 0.5989 - auc_1: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4135 - val_auc: 0.5495 - val_auc_1: 0.1702 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 17ms/step\n",
      "Epoch 39/200\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "7197/7197 - 126s - loss: 0.4278 - auc: 0.5990 - auc_1: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.4138 - val_auc: 0.5501 - val_auc_1: 0.1704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - 126s/epoch - 18ms/step\n",
      "Epoch 39: early stopping\n",
      "2253/2253 [==============================] - 23s 10ms/step - loss: 0.4101 - auc: 0.5711 - auc_1: 0.1768 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# cnn-vae\n",
    "cnn_readm_model, cnn_readm_preds  = train_eval_pred_model(class_model, 2, 200, readm_cnn_X_train, readm_cnn_X_test,\n",
    "                                        readm_cnn_y_train, readm_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10076/10076 - 193s - loss: 0.2663 - auc: 0.7993 - auc_1: 0.3923 - precision: 0.8750 - recall: 0.0073 - val_loss: 0.2487 - val_auc: 0.8297 - val_auc_1: 0.4746 - val_precision: 0.9211 - val_recall: 0.0707 - 193s/epoch - 19ms/step\n",
      "Epoch 2/200\n",
      "10076/10076 - 186s - loss: 0.2380 - auc: 0.8288 - auc_1: 0.4846 - precision: 0.8705 - recall: 0.1507 - val_loss: 0.2420 - val_auc: 0.8315 - val_auc_1: 0.4858 - val_precision: 0.7951 - val_recall: 0.1960 - 186s/epoch - 19ms/step\n",
      "Epoch 3/200\n",
      "10076/10076 - 187s - loss: 0.2339 - auc: 0.8354 - auc_1: 0.4993 - precision: 0.8069 - recall: 0.2070 - val_loss: 0.2390 - val_auc: 0.8357 - val_auc_1: 0.4965 - val_precision: 0.7397 - val_recall: 0.2182 - 187s/epoch - 19ms/step\n",
      "Epoch 4/200\n",
      "10076/10076 - 186s - loss: 0.2311 - auc: 0.8390 - auc_1: 0.5090 - precision: 0.7833 - recall: 0.2299 - val_loss: 0.2364 - val_auc: 0.8392 - val_auc_1: 0.5065 - val_precision: 0.7267 - val_recall: 0.2202 - 186s/epoch - 18ms/step\n",
      "Epoch 5/200\n",
      "10076/10076 - 187s - loss: 0.2286 - auc: 0.8430 - auc_1: 0.5181 - precision: 0.7818 - recall: 0.2336 - val_loss: 0.2340 - val_auc: 0.8433 - val_auc_1: 0.5155 - val_precision: 0.7289 - val_recall: 0.2444 - 187s/epoch - 19ms/step\n",
      "Epoch 6/200\n",
      "10076/10076 - 186s - loss: 0.2263 - auc: 0.8472 - auc_1: 0.5261 - precision: 0.7611 - recall: 0.2492 - val_loss: 0.2318 - val_auc: 0.8495 - val_auc_1: 0.5235 - val_precision: 0.7314 - val_recall: 0.2586 - 186s/epoch - 18ms/step\n",
      "Epoch 7/200\n",
      "10076/10076 - 186s - loss: 0.2242 - auc: 0.8511 - auc_1: 0.5335 - precision: 0.7549 - recall: 0.2633 - val_loss: 0.2297 - val_auc: 0.8521 - val_auc_1: 0.5310 - val_precision: 0.7403 - val_recall: 0.2707 - 186s/epoch - 19ms/step\n",
      "Epoch 8/200\n",
      "10076/10076 - 186s - loss: 0.2222 - auc: 0.8545 - auc_1: 0.5402 - precision: 0.7536 - recall: 0.2696 - val_loss: 0.2280 - val_auc: 0.8537 - val_auc_1: 0.5375 - val_precision: 0.7433 - val_recall: 0.2808 - 186s/epoch - 18ms/step\n",
      "Epoch 9/200\n",
      "10076/10076 - 187s - loss: 0.2204 - auc: 0.8579 - auc_1: 0.5460 - precision: 0.7518 - recall: 0.2795 - val_loss: 0.2264 - val_auc: 0.8570 - val_auc_1: 0.5428 - val_precision: 0.7513 - val_recall: 0.2990 - 187s/epoch - 19ms/step\n",
      "Epoch 10/200\n",
      "10076/10076 - 186s - loss: 0.2188 - auc: 0.8610 - auc_1: 0.5512 - precision: 0.7459 - recall: 0.2862 - val_loss: 0.2247 - val_auc: 0.8591 - val_auc_1: 0.5479 - val_precision: 0.7308 - val_recall: 0.3071 - 186s/epoch - 18ms/step\n",
      "Epoch 11/200\n",
      "10076/10076 - 187s - loss: 0.2172 - auc: 0.8646 - auc_1: 0.5566 - precision: 0.7468 - recall: 0.3029 - val_loss: 0.2235 - val_auc: 0.8618 - val_auc_1: 0.5529 - val_precision: 0.7451 - val_recall: 0.3071 - 187s/epoch - 19ms/step\n",
      "Epoch 12/200\n",
      "10076/10076 - 184s - loss: 0.2156 - auc: 0.8670 - auc_1: 0.5621 - precision: 0.7533 - recall: 0.2977 - val_loss: 0.2220 - val_auc: 0.8637 - val_auc_1: 0.5575 - val_precision: 0.7149 - val_recall: 0.3394 - 184s/epoch - 18ms/step\n",
      "Epoch 13/200\n",
      "10076/10076 - 184s - loss: 0.2141 - auc: 0.8707 - auc_1: 0.5657 - precision: 0.7420 - recall: 0.3133 - val_loss: 0.2207 - val_auc: 0.8658 - val_auc_1: 0.5612 - val_precision: 0.7284 - val_recall: 0.3414 - 184s/epoch - 18ms/step\n",
      "Epoch 14/200\n",
      "10076/10076 - 187s - loss: 0.2127 - auc: 0.8733 - auc_1: 0.5703 - precision: 0.7443 - recall: 0.3217 - val_loss: 0.2195 - val_auc: 0.8691 - val_auc_1: 0.5655 - val_precision: 0.7331 - val_recall: 0.3495 - 187s/epoch - 19ms/step\n",
      "Epoch 15/200\n",
      "10076/10076 - 187s - loss: 0.2114 - auc: 0.8761 - auc_1: 0.5741 - precision: 0.7543 - recall: 0.3217 - val_loss: 0.2184 - val_auc: 0.8690 - val_auc_1: 0.5684 - val_precision: 0.7350 - val_recall: 0.3475 - 187s/epoch - 19ms/step\n",
      "Epoch 16/200\n",
      "10076/10076 - 188s - loss: 0.2101 - auc: 0.8778 - auc_1: 0.5775 - precision: 0.7485 - recall: 0.3306 - val_loss: 0.2173 - val_auc: 0.8708 - val_auc_1: 0.5715 - val_precision: 0.7257 - val_recall: 0.3475 - 188s/epoch - 19ms/step\n",
      "Epoch 17/200\n",
      "10076/10076 - 187s - loss: 0.2088 - auc: 0.8805 - auc_1: 0.5812 - precision: 0.7465 - recall: 0.3300 - val_loss: 0.2163 - val_auc: 0.8722 - val_auc_1: 0.5752 - val_precision: 0.7190 - val_recall: 0.3515 - 187s/epoch - 19ms/step\n",
      "Epoch 18/200\n",
      "10076/10076 - 187s - loss: 0.2076 - auc: 0.8818 - auc_1: 0.5840 - precision: 0.7393 - recall: 0.3415 - val_loss: 0.2155 - val_auc: 0.8740 - val_auc_1: 0.5786 - val_precision: 0.7412 - val_recall: 0.3414 - 187s/epoch - 19ms/step\n",
      "Epoch 19/200\n",
      "10076/10076 - 188s - loss: 0.2065 - auc: 0.8837 - auc_1: 0.5876 - precision: 0.7486 - recall: 0.3399 - val_loss: 0.2144 - val_auc: 0.8748 - val_auc_1: 0.5807 - val_precision: 0.7172 - val_recall: 0.3535 - 188s/epoch - 19ms/step\n",
      "Epoch 20/200\n",
      "10076/10076 - 187s - loss: 0.2052 - auc: 0.8855 - auc_1: 0.5901 - precision: 0.7427 - recall: 0.3446 - val_loss: 0.2135 - val_auc: 0.8762 - val_auc_1: 0.5840 - val_precision: 0.7063 - val_recall: 0.3596 - 187s/epoch - 19ms/step\n",
      "Epoch 21/200\n",
      "10076/10076 - 187s - loss: 0.2041 - auc: 0.8870 - auc_1: 0.5932 - precision: 0.7430 - recall: 0.3452 - val_loss: 0.2129 - val_auc: 0.8771 - val_auc_1: 0.5853 - val_precision: 0.7097 - val_recall: 0.3556 - 187s/epoch - 19ms/step\n",
      "Epoch 22/200\n",
      "10076/10076 - 187s - loss: 0.2032 - auc: 0.8877 - auc_1: 0.5956 - precision: 0.7442 - recall: 0.3519 - val_loss: 0.2119 - val_auc: 0.8789 - val_auc_1: 0.5875 - val_precision: 0.7126 - val_recall: 0.3556 - 187s/epoch - 19ms/step\n",
      "Epoch 23/200\n",
      "10076/10076 - 187s - loss: 0.2022 - auc: 0.8895 - auc_1: 0.5985 - precision: 0.7413 - recall: 0.3571 - val_loss: 0.2110 - val_auc: 0.8787 - val_auc_1: 0.5905 - val_precision: 0.7373 - val_recall: 0.3515 - 187s/epoch - 19ms/step\n",
      "Epoch 24/200\n",
      "10076/10076 - 188s - loss: 0.2012 - auc: 0.8905 - auc_1: 0.6012 - precision: 0.7459 - recall: 0.3519 - val_loss: 0.2106 - val_auc: 0.8792 - val_auc_1: 0.5922 - val_precision: 0.7479 - val_recall: 0.3535 - 188s/epoch - 19ms/step\n",
      "Epoch 25/200\n",
      "10076/10076 - 188s - loss: 0.2003 - auc: 0.8917 - auc_1: 0.6035 - precision: 0.7464 - recall: 0.3545 - val_loss: 0.2096 - val_auc: 0.8797 - val_auc_1: 0.5941 - val_precision: 0.7054 - val_recall: 0.3677 - 188s/epoch - 19ms/step\n",
      "Epoch 26/200\n",
      "10076/10076 - 188s - loss: 0.1994 - auc: 0.8929 - auc_1: 0.6057 - precision: 0.7389 - recall: 0.3644 - val_loss: 0.2088 - val_auc: 0.8812 - val_auc_1: 0.5955 - val_precision: 0.7328 - val_recall: 0.3657 - 188s/epoch - 19ms/step\n",
      "Epoch 27/200\n",
      "10076/10076 - 188s - loss: 0.1987 - auc: 0.8936 - auc_1: 0.6079 - precision: 0.7423 - recall: 0.3634 - val_loss: 0.2082 - val_auc: 0.8815 - val_auc_1: 0.5982 - val_precision: 0.7366 - val_recall: 0.3616 - 188s/epoch - 19ms/step\n",
      "Epoch 28/200\n",
      "10076/10076 - 187s - loss: 0.1978 - auc: 0.8945 - auc_1: 0.6097 - precision: 0.7390 - recall: 0.3691 - val_loss: 0.2079 - val_auc: 0.8830 - val_auc_1: 0.6005 - val_precision: 0.7588 - val_recall: 0.3495 - 187s/epoch - 19ms/step\n",
      "Epoch 29/200\n",
      "10076/10076 - 189s - loss: 0.1970 - auc: 0.8952 - auc_1: 0.6121 - precision: 0.7461 - recall: 0.3707 - val_loss: 0.2076 - val_auc: 0.8849 - val_auc_1: 0.6015 - val_precision: 0.7621 - val_recall: 0.3495 - 189s/epoch - 19ms/step\n",
      "Epoch 30/200\n",
      "10076/10076 - 188s - loss: 0.1963 - auc: 0.8960 - auc_1: 0.6144 - precision: 0.7607 - recall: 0.3629 - val_loss: 0.2068 - val_auc: 0.8855 - val_auc_1: 0.6023 - val_precision: 0.7336 - val_recall: 0.3616 - 188s/epoch - 19ms/step\n",
      "Epoch 31/200\n",
      "10076/10076 - 188s - loss: 0.1957 - auc: 0.8968 - auc_1: 0.6156 - precision: 0.7516 - recall: 0.3707 - val_loss: 0.2062 - val_auc: 0.8861 - val_auc_1: 0.6044 - val_precision: 0.7377 - val_recall: 0.3636 - 188s/epoch - 19ms/step\n",
      "Epoch 32/200\n",
      "10076/10076 - 187s - loss: 0.1950 - auc: 0.8981 - auc_1: 0.6180 - precision: 0.7521 - recall: 0.3670 - val_loss: 0.2059 - val_auc: 0.8847 - val_auc_1: 0.6046 - val_precision: 0.7377 - val_recall: 0.3636 - 187s/epoch - 19ms/step\n",
      "Epoch 33/200\n",
      "10076/10076 - 188s - loss: 0.1944 - auc: 0.8983 - auc_1: 0.6192 - precision: 0.7503 - recall: 0.3743 - val_loss: 0.2050 - val_auc: 0.8859 - val_auc_1: 0.6067 - val_precision: 0.7390 - val_recall: 0.3717 - 188s/epoch - 19ms/step\n",
      "Epoch 34/200\n",
      "10076/10076 - 189s - loss: 0.1938 - auc: 0.8990 - auc_1: 0.6211 - precision: 0.7508 - recall: 0.3785 - val_loss: 0.2045 - val_auc: 0.8868 - val_auc_1: 0.6084 - val_precision: 0.7379 - val_recall: 0.3697 - 189s/epoch - 19ms/step\n",
      "Epoch 35/200\n",
      "10076/10076 - 189s - loss: 0.1932 - auc: 0.9000 - auc_1: 0.6228 - precision: 0.7505 - recall: 0.3780 - val_loss: 0.2043 - val_auc: 0.8869 - val_auc_1: 0.6092 - val_precision: 0.7593 - val_recall: 0.3697 - 189s/epoch - 19ms/step\n",
      "Epoch 36/200\n",
      "10076/10076 - 190s - loss: 0.1927 - auc: 0.9005 - auc_1: 0.6245 - precision: 0.7558 - recall: 0.3759 - val_loss: 0.2042 - val_auc: 0.8878 - val_auc_1: 0.6111 - val_precision: 0.7521 - val_recall: 0.3677 - 190s/epoch - 19ms/step\n",
      "Epoch 37/200\n",
      "10076/10076 - 190s - loss: 0.1921 - auc: 0.9008 - auc_1: 0.6261 - precision: 0.7571 - recall: 0.3754 - val_loss: 0.2035 - val_auc: 0.8884 - val_auc_1: 0.6111 - val_precision: 0.7305 - val_recall: 0.3778 - 190s/epoch - 19ms/step\n",
      "Epoch 38/200\n",
      "10076/10076 - 189s - loss: 0.1916 - auc: 0.9013 - auc_1: 0.6273 - precision: 0.7505 - recall: 0.3843 - val_loss: 0.2029 - val_auc: 0.8881 - val_auc_1: 0.6135 - val_precision: 0.7430 - val_recall: 0.3737 - 189s/epoch - 19ms/step\n",
      "Epoch 39/200\n",
      "10076/10076 - 189s - loss: 0.1911 - auc: 0.9023 - auc_1: 0.6295 - precision: 0.7629 - recall: 0.3775 - val_loss: 0.2028 - val_auc: 0.8893 - val_auc_1: 0.6128 - val_precision: 0.7373 - val_recall: 0.3798 - 189s/epoch - 19ms/step\n",
      "Epoch 40/200\n",
      "10076/10076 - 189s - loss: 0.1906 - auc: 0.9027 - auc_1: 0.6303 - precision: 0.7520 - recall: 0.3905 - val_loss: 0.2023 - val_auc: 0.8900 - val_auc_1: 0.6153 - val_precision: 0.7390 - val_recall: 0.3717 - 189s/epoch - 19ms/step\n",
      "Epoch 41/200\n",
      "10076/10076 - 190s - loss: 0.1901 - auc: 0.9036 - auc_1: 0.6313 - precision: 0.7497 - recall: 0.3843 - val_loss: 0.2019 - val_auc: 0.8898 - val_auc_1: 0.6164 - val_precision: 0.7412 - val_recall: 0.3818 - 190s/epoch - 19ms/step\n",
      "Epoch 42/200\n",
      "10076/10076 - 188s - loss: 0.1897 - auc: 0.9041 - auc_1: 0.6332 - precision: 0.7579 - recall: 0.3869 - val_loss: 0.2015 - val_auc: 0.8908 - val_auc_1: 0.6166 - val_precision: 0.7364 - val_recall: 0.3838 - 188s/epoch - 19ms/step\n",
      "Epoch 43/200\n",
      "10076/10076 - 190s - loss: 0.1892 - auc: 0.9044 - auc_1: 0.6344 - precision: 0.7612 - recall: 0.3905 - val_loss: 0.2012 - val_auc: 0.8917 - val_auc_1: 0.6179 - val_precision: 0.7321 - val_recall: 0.3919 - 190s/epoch - 19ms/step\n",
      "Epoch 44/200\n",
      "10076/10076 - 190s - loss: 0.1886 - auc: 0.9059 - auc_1: 0.6362 - precision: 0.7542 - recall: 0.3999 - val_loss: 0.2013 - val_auc: 0.8916 - val_auc_1: 0.6201 - val_precision: 0.7521 - val_recall: 0.3677 - 190s/epoch - 19ms/step\n",
      "Epoch 45/200\n",
      "10076/10076 - 189s - loss: 0.1883 - auc: 0.9059 - auc_1: 0.6375 - precision: 0.7686 - recall: 0.3879 - val_loss: 0.2007 - val_auc: 0.8918 - val_auc_1: 0.6192 - val_precision: 0.7328 - val_recall: 0.3879 - 189s/epoch - 19ms/step\n",
      "Epoch 46/200\n",
      "10076/10076 - 189s - loss: 0.1879 - auc: 0.9062 - auc_1: 0.6384 - precision: 0.7610 - recall: 0.3952 - val_loss: 0.2003 - val_auc: 0.8927 - val_auc_1: 0.6206 - val_precision: 0.7328 - val_recall: 0.3879 - 189s/epoch - 19ms/step\n",
      "Epoch 47/200\n",
      "10076/10076 - 190s - loss: 0.1876 - auc: 0.9063 - auc_1: 0.6397 - precision: 0.7637 - recall: 0.4009 - val_loss: 0.2000 - val_auc: 0.8929 - val_auc_1: 0.6222 - val_precision: 0.7356 - val_recall: 0.3879 - 190s/epoch - 19ms/step\n",
      "Epoch 48/200\n",
      "10076/10076 - 189s - loss: 0.1872 - auc: 0.9071 - auc_1: 0.6408 - precision: 0.7632 - recall: 0.3983 - val_loss: 0.1997 - val_auc: 0.8933 - val_auc_1: 0.6218 - val_precision: 0.7346 - val_recall: 0.3859 - 189s/epoch - 19ms/step\n",
      "Epoch 49/200\n",
      "10076/10076 - 196s - loss: 0.1867 - auc: 0.9071 - auc_1: 0.6420 - precision: 0.7666 - recall: 0.3973 - val_loss: 0.1996 - val_auc: 0.8926 - val_auc_1: 0.6226 - val_precision: 0.7393 - val_recall: 0.3838 - 196s/epoch - 19ms/step\n",
      "Epoch 50/200\n",
      "10076/10076 - 189s - loss: 0.1864 - auc: 0.9079 - auc_1: 0.6428 - precision: 0.7643 - recall: 0.4041 - val_loss: 0.1994 - val_auc: 0.8936 - val_auc_1: 0.6237 - val_precision: 0.7318 - val_recall: 0.3859 - 189s/epoch - 19ms/step\n",
      "Epoch 51/200\n",
      "10076/10076 - 189s - loss: 0.1860 - auc: 0.9083 - auc_1: 0.6440 - precision: 0.7653 - recall: 0.4030 - val_loss: 0.1991 - val_auc: 0.8939 - val_auc_1: 0.6249 - val_precision: 0.7346 - val_recall: 0.3859 - 189s/epoch - 19ms/step\n",
      "Epoch 52/200\n",
      "10076/10076 - 190s - loss: 0.1856 - auc: 0.9092 - auc_1: 0.6456 - precision: 0.7687 - recall: 0.4020 - val_loss: 0.1988 - val_auc: 0.8942 - val_auc_1: 0.6245 - val_precision: 0.7363 - val_recall: 0.4061 - 190s/epoch - 19ms/step\n",
      "Epoch 53/200\n",
      "10076/10076 - 190s - loss: 0.1853 - auc: 0.9090 - auc_1: 0.6460 - precision: 0.7643 - recall: 0.4041 - val_loss: 0.1986 - val_auc: 0.8944 - val_auc_1: 0.6252 - val_precision: 0.7303 - val_recall: 0.3939 - 190s/epoch - 19ms/step\n",
      "Epoch 54/200\n",
      "10076/10076 - 191s - loss: 0.1848 - auc: 0.9097 - auc_1: 0.6471 - precision: 0.7637 - recall: 0.4129 - val_loss: 0.1986 - val_auc: 0.8941 - val_auc_1: 0.6257 - val_precision: 0.7490 - val_recall: 0.3919 - 191s/epoch - 19ms/step\n",
      "Epoch 55/200\n",
      "10076/10076 - 193s - loss: 0.1846 - auc: 0.9099 - auc_1: 0.6483 - precision: 0.7702 - recall: 0.4020 - val_loss: 0.1981 - val_auc: 0.8953 - val_auc_1: 0.6272 - val_precision: 0.7395 - val_recall: 0.3899 - 193s/epoch - 19ms/step\n",
      "Epoch 56/200\n",
      "10076/10076 - 192s - loss: 0.1843 - auc: 0.9106 - auc_1: 0.6494 - precision: 0.7682 - recall: 0.4062 - val_loss: 0.1978 - val_auc: 0.8959 - val_auc_1: 0.6271 - val_precision: 0.7399 - val_recall: 0.4081 - 192s/epoch - 19ms/step\n",
      "Epoch 57/200\n",
      "10076/10076 - 190s - loss: 0.1839 - auc: 0.9108 - auc_1: 0.6504 - precision: 0.7701 - recall: 0.4103 - val_loss: 0.1978 - val_auc: 0.8952 - val_auc_1: 0.6276 - val_precision: 0.7414 - val_recall: 0.3939 - 190s/epoch - 19ms/step\n",
      "Epoch 58/200\n",
      "10076/10076 - 190s - loss: 0.1836 - auc: 0.9113 - auc_1: 0.6513 - precision: 0.7724 - recall: 0.4088 - val_loss: 0.1977 - val_auc: 0.8961 - val_auc_1: 0.6289 - val_precision: 0.7445 - val_recall: 0.4121 - 190s/epoch - 19ms/step\n",
      "Epoch 59/200\n",
      "10076/10076 - 191s - loss: 0.1832 - auc: 0.9118 - auc_1: 0.6520 - precision: 0.7703 - recall: 0.4161 - val_loss: 0.1974 - val_auc: 0.8955 - val_auc_1: 0.6293 - val_precision: 0.7443 - val_recall: 0.3939 - 191s/epoch - 19ms/step\n",
      "Epoch 60/200\n",
      "10076/10076 - 190s - loss: 0.1830 - auc: 0.9120 - auc_1: 0.6533 - precision: 0.7706 - recall: 0.4150 - val_loss: 0.1973 - val_auc: 0.8962 - val_auc_1: 0.6291 - val_precision: 0.7481 - val_recall: 0.3960 - 190s/epoch - 19ms/step\n",
      "Epoch 61/200\n",
      "10076/10076 - 192s - loss: 0.1826 - auc: 0.9125 - auc_1: 0.6546 - precision: 0.7750 - recall: 0.4129 - val_loss: 0.1973 - val_auc: 0.8968 - val_auc_1: 0.6293 - val_precision: 0.7463 - val_recall: 0.4101 - 192s/epoch - 19ms/step\n",
      "Epoch 62/200\n",
      "10076/10076 - 191s - loss: 0.1821 - auc: 0.9131 - auc_1: 0.6545 - precision: 0.7717 - recall: 0.4213 - val_loss: 0.1967 - val_auc: 0.8967 - val_auc_1: 0.6301 - val_precision: 0.7394 - val_recall: 0.4242 - 191s/epoch - 19ms/step\n",
      "Epoch 63/200\n",
      "10076/10076 - 190s - loss: 0.1820 - auc: 0.9132 - auc_1: 0.6560 - precision: 0.7739 - recall: 0.4228 - val_loss: 0.1966 - val_auc: 0.8976 - val_auc_1: 0.6315 - val_precision: 0.7473 - val_recall: 0.4182 - 190s/epoch - 19ms/step\n",
      "Epoch 64/200\n",
      "10076/10076 - 191s - loss: 0.1817 - auc: 0.9136 - auc_1: 0.6569 - precision: 0.7735 - recall: 0.4202 - val_loss: 0.1965 - val_auc: 0.8974 - val_auc_1: 0.6321 - val_precision: 0.7361 - val_recall: 0.4283 - 191s/epoch - 19ms/step\n",
      "Epoch 65/200\n",
      "10076/10076 - 192s - loss: 0.1813 - auc: 0.9141 - auc_1: 0.6583 - precision: 0.7719 - recall: 0.4181 - val_loss: 0.1966 - val_auc: 0.8971 - val_auc_1: 0.6303 - val_precision: 0.7300 - val_recall: 0.4424 - 192s/epoch - 19ms/step\n",
      "Epoch 66/200\n",
      "10076/10076 - 194s - loss: 0.1812 - auc: 0.9140 - auc_1: 0.6582 - precision: 0.7683 - recall: 0.4270 - val_loss: 0.1964 - val_auc: 0.8973 - val_auc_1: 0.6317 - val_precision: 0.7594 - val_recall: 0.4081 - 194s/epoch - 19ms/step\n",
      "Epoch 67/200\n",
      "10076/10076 - 197s - loss: 0.1810 - auc: 0.9148 - auc_1: 0.6587 - precision: 0.7725 - recall: 0.4249 - val_loss: 0.1961 - val_auc: 0.8980 - val_auc_1: 0.6326 - val_precision: 0.7546 - val_recall: 0.4101 - 197s/epoch - 20ms/step\n",
      "Epoch 68/200\n",
      "10076/10076 - 201s - loss: 0.1806 - auc: 0.9148 - auc_1: 0.6599 - precision: 0.7740 - recall: 0.4249 - val_loss: 0.1957 - val_auc: 0.8981 - val_auc_1: 0.6333 - val_precision: 0.7385 - val_recall: 0.4222 - 201s/epoch - 20ms/step\n",
      "Epoch 69/200\n",
      "10076/10076 - 194s - loss: 0.1803 - auc: 0.9153 - auc_1: 0.6608 - precision: 0.7738 - recall: 0.4281 - val_loss: 0.1959 - val_auc: 0.8987 - val_auc_1: 0.6343 - val_precision: 0.7546 - val_recall: 0.4101 - 194s/epoch - 19ms/step\n",
      "Epoch 70/200\n",
      "10076/10076 - 193s - loss: 0.1802 - auc: 0.9152 - auc_1: 0.6616 - precision: 0.7807 - recall: 0.4249 - val_loss: 0.1958 - val_auc: 0.8981 - val_auc_1: 0.6337 - val_precision: 0.7324 - val_recall: 0.4424 - 193s/epoch - 19ms/step\n",
      "Epoch 71/200\n",
      "10076/10076 - 193s - loss: 0.1797 - auc: 0.9152 - auc_1: 0.6625 - precision: 0.7732 - recall: 0.4338 - val_loss: 0.1956 - val_auc: 0.8985 - val_auc_1: 0.6351 - val_precision: 0.7391 - val_recall: 0.4121 - 193s/epoch - 19ms/step\n",
      "Epoch 72/200\n",
      "10076/10076 - 193s - loss: 0.1795 - auc: 0.9162 - auc_1: 0.6635 - precision: 0.7802 - recall: 0.4275 - val_loss: 0.1957 - val_auc: 0.8986 - val_auc_1: 0.6336 - val_precision: 0.7291 - val_recall: 0.4404 - 193s/epoch - 19ms/step\n",
      "Epoch 73/200\n",
      "10076/10076 - 192s - loss: 0.1793 - auc: 0.9157 - auc_1: 0.6637 - precision: 0.7756 - recall: 0.4343 - val_loss: 0.1955 - val_auc: 0.8982 - val_auc_1: 0.6344 - val_precision: 0.7429 - val_recall: 0.4202 - 192s/epoch - 19ms/step\n",
      "Epoch 74/200\n",
      "10076/10076 - 192s - loss: 0.1791 - auc: 0.9162 - auc_1: 0.6650 - precision: 0.7777 - recall: 0.4322 - val_loss: 0.1955 - val_auc: 0.8997 - val_auc_1: 0.6353 - val_precision: 0.7474 - val_recall: 0.4364 - 192s/epoch - 19ms/step\n",
      "Epoch 75/200\n",
      "10076/10076 - 193s - loss: 0.1789 - auc: 0.9165 - auc_1: 0.6652 - precision: 0.7784 - recall: 0.4322 - val_loss: 0.1955 - val_auc: 0.8997 - val_auc_1: 0.6357 - val_precision: 0.7448 - val_recall: 0.4364 - 193s/epoch - 19ms/step\n",
      "Epoch 76/200\n",
      "10076/10076 - 193s - loss: 0.1786 - auc: 0.9166 - auc_1: 0.6659 - precision: 0.7771 - recall: 0.4343 - val_loss: 0.1953 - val_auc: 0.8997 - val_auc_1: 0.6367 - val_precision: 0.7474 - val_recall: 0.4364 - 193s/epoch - 19ms/step\n",
      "Epoch 77/200\n",
      "10076/10076 - 192s - loss: 0.1784 - auc: 0.9168 - auc_1: 0.6669 - precision: 0.7761 - recall: 0.4338 - val_loss: 0.1951 - val_auc: 0.8998 - val_auc_1: 0.6364 - val_precision: 0.7255 - val_recall: 0.4485 - 192s/epoch - 19ms/step\n",
      "Epoch 78/200\n",
      "10076/10076 - 193s - loss: 0.1782 - auc: 0.9174 - auc_1: 0.6672 - precision: 0.7732 - recall: 0.4390 - val_loss: 0.1952 - val_auc: 0.9003 - val_auc_1: 0.6365 - val_precision: 0.7535 - val_recall: 0.4323 - 193s/epoch - 19ms/step\n",
      "Epoch 79/200\n",
      "10076/10076 - 193s - loss: 0.1779 - auc: 0.9176 - auc_1: 0.6680 - precision: 0.7814 - recall: 0.4380 - val_loss: 0.1950 - val_auc: 0.8991 - val_auc_1: 0.6352 - val_precision: 0.7365 - val_recall: 0.4404 - 193s/epoch - 19ms/step\n",
      "Epoch 80/200\n",
      "10076/10076 - 194s - loss: 0.1777 - auc: 0.9177 - auc_1: 0.6689 - precision: 0.7778 - recall: 0.4380 - val_loss: 0.1947 - val_auc: 0.9001 - val_auc_1: 0.6373 - val_precision: 0.7491 - val_recall: 0.4404 - 194s/epoch - 19ms/step\n",
      "Epoch 81/200\n",
      "10076/10076 - 192s - loss: 0.1774 - auc: 0.9184 - auc_1: 0.6699 - precision: 0.7782 - recall: 0.4426 - val_loss: 0.1947 - val_auc: 0.8995 - val_auc_1: 0.6367 - val_precision: 0.7465 - val_recall: 0.4283 - 192s/epoch - 19ms/step\n",
      "Epoch 82/200\n",
      "10076/10076 - 192s - loss: 0.1773 - auc: 0.9183 - auc_1: 0.6702 - precision: 0.7771 - recall: 0.4380 - val_loss: 0.1948 - val_auc: 0.9000 - val_auc_1: 0.6370 - val_precision: 0.7414 - val_recall: 0.4343 - 192s/epoch - 19ms/step\n",
      "Epoch 83/200\n",
      "10076/10076 - 193s - loss: 0.1771 - auc: 0.9182 - auc_1: 0.6710 - precision: 0.7771 - recall: 0.4416 - val_loss: 0.1950 - val_auc: 0.8990 - val_auc_1: 0.6365 - val_precision: 0.7381 - val_recall: 0.4384 - 193s/epoch - 19ms/step\n",
      "Epoch 84/200\n",
      "10076/10076 - 192s - loss: 0.1768 - auc: 0.9189 - auc_1: 0.6714 - precision: 0.7769 - recall: 0.4447 - val_loss: 0.1943 - val_auc: 0.9002 - val_auc_1: 0.6386 - val_precision: 0.7491 - val_recall: 0.4343 - 192s/epoch - 19ms/step\n",
      "Epoch 85/200\n",
      "10076/10076 - 251s - loss: 0.1767 - auc: 0.9186 - auc_1: 0.6724 - precision: 0.7777 - recall: 0.4432 - val_loss: 0.1947 - val_auc: 0.9005 - val_auc_1: 0.6392 - val_precision: 0.7535 - val_recall: 0.4323 - 251s/epoch - 25ms/step\n",
      "Epoch 86/200\n",
      "10076/10076 - 194s - loss: 0.1763 - auc: 0.9194 - auc_1: 0.6727 - precision: 0.7729 - recall: 0.4437 - val_loss: 0.1947 - val_auc: 0.8992 - val_auc_1: 0.6379 - val_precision: 0.7374 - val_recall: 0.4424 - 194s/epoch - 19ms/step\n",
      "Epoch 87/200\n",
      "10076/10076 - 194s - loss: 0.1762 - auc: 0.9191 - auc_1: 0.6729 - precision: 0.7764 - recall: 0.4453 - val_loss: 0.1942 - val_auc: 0.9013 - val_auc_1: 0.6381 - val_precision: 0.7331 - val_recall: 0.4384 - 194s/epoch - 19ms/step\n",
      "Epoch 88/200\n",
      "10076/10076 - 193s - loss: 0.1760 - auc: 0.9197 - auc_1: 0.6743 - precision: 0.7824 - recall: 0.4463 - val_loss: 0.1945 - val_auc: 0.9003 - val_auc_1: 0.6385 - val_precision: 0.7318 - val_recall: 0.4465 - 193s/epoch - 19ms/step\n",
      "Epoch 89/200\n",
      "10076/10076 - 195s - loss: 0.1759 - auc: 0.9193 - auc_1: 0.6747 - precision: 0.7785 - recall: 0.4453 - val_loss: 0.1942 - val_auc: 0.9006 - val_auc_1: 0.6389 - val_precision: 0.7290 - val_recall: 0.4566 - 195s/epoch - 19ms/step\n",
      "Epoch 90/200\n",
      "10076/10076 - 188s - loss: 0.1756 - auc: 0.9198 - auc_1: 0.6754 - precision: 0.7714 - recall: 0.4557 - val_loss: 0.1943 - val_auc: 0.9004 - val_auc_1: 0.6392 - val_precision: 0.7572 - val_recall: 0.4222 - 188s/epoch - 19ms/step\n",
      "Epoch 91/200\n",
      "10076/10076 - 188s - loss: 0.1754 - auc: 0.9202 - auc_1: 0.6761 - precision: 0.7830 - recall: 0.4479 - val_loss: 0.1944 - val_auc: 0.9006 - val_auc_1: 0.6393 - val_precision: 0.7518 - val_recall: 0.4283 - 188s/epoch - 19ms/step\n",
      "Epoch 92/200\n",
      "10076/10076 - 187s - loss: 0.1752 - auc: 0.9203 - auc_1: 0.6773 - precision: 0.7867 - recall: 0.4442 - val_loss: 0.1940 - val_auc: 0.9012 - val_auc_1: 0.6397 - val_precision: 0.7258 - val_recall: 0.4545 - 187s/epoch - 19ms/step\n",
      "Epoch 93/200\n",
      "10076/10076 - 188s - loss: 0.1750 - auc: 0.9203 - auc_1: 0.6776 - precision: 0.7717 - recall: 0.4546 - val_loss: 0.1938 - val_auc: 0.9010 - val_auc_1: 0.6402 - val_precision: 0.7448 - val_recall: 0.4364 - 188s/epoch - 19ms/step\n",
      "Epoch 94/200\n",
      "10076/10076 - 187s - loss: 0.1747 - auc: 0.9207 - auc_1: 0.6785 - precision: 0.7777 - recall: 0.4468 - val_loss: 0.1935 - val_auc: 0.9016 - val_auc_1: 0.6414 - val_precision: 0.7303 - val_recall: 0.4485 - 187s/epoch - 19ms/step\n",
      "Epoch 95/200\n",
      "10076/10076 - 186s - loss: 0.1746 - auc: 0.9213 - auc_1: 0.6782 - precision: 0.7803 - recall: 0.4499 - val_loss: 0.1939 - val_auc: 0.9014 - val_auc_1: 0.6417 - val_precision: 0.7320 - val_recall: 0.4525 - 186s/epoch - 18ms/step\n",
      "Epoch 96/200\n",
      "10076/10076 - 187s - loss: 0.1744 - auc: 0.9208 - auc_1: 0.6790 - precision: 0.7709 - recall: 0.4562 - val_loss: 0.1940 - val_auc: 0.9009 - val_auc_1: 0.6397 - val_precision: 0.7535 - val_recall: 0.4384 - 187s/epoch - 19ms/step\n",
      "Epoch 97/200\n",
      "10076/10076 - 188s - loss: 0.1741 - auc: 0.9213 - auc_1: 0.6799 - precision: 0.7752 - recall: 0.4567 - val_loss: 0.1936 - val_auc: 0.9009 - val_auc_1: 0.6419 - val_precision: 0.7544 - val_recall: 0.4343 - 188s/epoch - 19ms/step\n",
      "Epoch 98/200\n",
      "10076/10076 - 188s - loss: 0.1739 - auc: 0.9215 - auc_1: 0.6811 - precision: 0.7834 - recall: 0.4526 - val_loss: 0.1942 - val_auc: 0.9008 - val_auc_1: 0.6410 - val_precision: 0.7597 - val_recall: 0.4343 - 188s/epoch - 19ms/step\n",
      "Epoch 99/200\n",
      "10076/10076 - 189s - loss: 0.1738 - auc: 0.9217 - auc_1: 0.6809 - precision: 0.7797 - recall: 0.4557 - val_loss: 0.1937 - val_auc: 0.9013 - val_auc_1: 0.6420 - val_precision: 0.7526 - val_recall: 0.4364 - 189s/epoch - 19ms/step\n",
      "Epoch 100/200\n",
      "10076/10076 - 188s - loss: 0.1737 - auc: 0.9216 - auc_1: 0.6814 - precision: 0.7835 - recall: 0.4567 - val_loss: 0.1936 - val_auc: 0.9014 - val_auc_1: 0.6415 - val_precision: 0.7374 - val_recall: 0.4424 - 188s/epoch - 19ms/step\n",
      "Epoch 101/200\n",
      "10076/10076 - 187s - loss: 0.1734 - auc: 0.9222 - auc_1: 0.6824 - precision: 0.7786 - recall: 0.4546 - val_loss: 0.1934 - val_auc: 0.9019 - val_auc_1: 0.6425 - val_precision: 0.7391 - val_recall: 0.4465 - 187s/epoch - 19ms/step\n",
      "Epoch 102/200\n",
      "10076/10076 - 186s - loss: 0.1731 - auc: 0.9227 - auc_1: 0.6832 - precision: 0.7787 - recall: 0.4567 - val_loss: 0.1934 - val_auc: 0.9015 - val_auc_1: 0.6422 - val_precision: 0.7390 - val_recall: 0.4404 - 186s/epoch - 19ms/step\n",
      "Epoch 103/200\n",
      "10076/10076 - 188s - loss: 0.1728 - auc: 0.9227 - auc_1: 0.6839 - precision: 0.7834 - recall: 0.4583 - val_loss: 0.1936 - val_auc: 0.9010 - val_auc_1: 0.6414 - val_precision: 0.7288 - val_recall: 0.4505 - 188s/epoch - 19ms/step\n",
      "Epoch 104/200\n",
      "10076/10076 - 188s - loss: 0.1728 - auc: 0.9229 - auc_1: 0.6837 - precision: 0.7824 - recall: 0.4630 - val_loss: 0.1932 - val_auc: 0.9019 - val_auc_1: 0.6433 - val_precision: 0.7383 - val_recall: 0.4444 - 188s/epoch - 19ms/step\n",
      "Epoch 105/200\n",
      "10076/10076 - 188s - loss: 0.1726 - auc: 0.9229 - auc_1: 0.6844 - precision: 0.7812 - recall: 0.4599 - val_loss: 0.1933 - val_auc: 0.9027 - val_auc_1: 0.6438 - val_precision: 0.7450 - val_recall: 0.4485 - 188s/epoch - 19ms/step\n",
      "Epoch 106/200\n",
      "10076/10076 - 188s - loss: 0.1725 - auc: 0.9229 - auc_1: 0.6849 - precision: 0.7785 - recall: 0.4599 - val_loss: 0.1935 - val_auc: 0.9020 - val_auc_1: 0.6439 - val_precision: 0.7474 - val_recall: 0.4424 - 188s/epoch - 19ms/step\n",
      "Epoch 107/200\n",
      "10076/10076 - 189s - loss: 0.1723 - auc: 0.9236 - auc_1: 0.6858 - precision: 0.7852 - recall: 0.4593 - val_loss: 0.1930 - val_auc: 0.9024 - val_auc_1: 0.6444 - val_precision: 0.7311 - val_recall: 0.4505 - 189s/epoch - 19ms/step\n",
      "Epoch 108/200\n",
      "10076/10076 - 189s - loss: 0.1721 - auc: 0.9236 - auc_1: 0.6867 - precision: 0.7790 - recall: 0.4614 - val_loss: 0.1940 - val_auc: 0.9012 - val_auc_1: 0.6433 - val_precision: 0.7474 - val_recall: 0.4424 - 189s/epoch - 19ms/step\n",
      "Epoch 109/200\n",
      "10076/10076 - 189s - loss: 0.1718 - auc: 0.9239 - auc_1: 0.6871 - precision: 0.7874 - recall: 0.4578 - val_loss: 0.1934 - val_auc: 0.9019 - val_auc_1: 0.6424 - val_precision: 0.7205 - val_recall: 0.4687 - 189s/epoch - 19ms/step\n",
      "Epoch 110/200\n",
      "10076/10076 - 189s - loss: 0.1717 - auc: 0.9239 - auc_1: 0.6871 - precision: 0.7791 - recall: 0.4672 - val_loss: 0.1933 - val_auc: 0.9009 - val_auc_1: 0.6436 - val_precision: 0.7400 - val_recall: 0.4485 - 189s/epoch - 19ms/step\n",
      "Epoch 111/200\n",
      "10076/10076 - 187s - loss: 0.1715 - auc: 0.9237 - auc_1: 0.6880 - precision: 0.7805 - recall: 0.4635 - val_loss: 0.1937 - val_auc: 0.9007 - val_auc_1: 0.6434 - val_precision: 0.7424 - val_recall: 0.4424 - 187s/epoch - 19ms/step\n",
      "Epoch 112/200\n",
      "10076/10076 - 189s - loss: 0.1713 - auc: 0.9240 - auc_1: 0.6883 - precision: 0.7773 - recall: 0.4677 - val_loss: 0.1927 - val_auc: 0.9024 - val_auc_1: 0.6448 - val_precision: 0.7416 - val_recall: 0.4465 - 189s/epoch - 19ms/step\n",
      "Epoch 113/200\n",
      "10076/10076 - 189s - loss: 0.1712 - auc: 0.9245 - auc_1: 0.6896 - precision: 0.7893 - recall: 0.4630 - val_loss: 0.1932 - val_auc: 0.9027 - val_auc_1: 0.6443 - val_precision: 0.7302 - val_recall: 0.4646 - 189s/epoch - 19ms/step\n",
      "Epoch 114/200\n",
      "10076/10076 - 188s - loss: 0.1709 - auc: 0.9248 - auc_1: 0.6898 - precision: 0.7762 - recall: 0.4703 - val_loss: 0.1933 - val_auc: 0.9004 - val_auc_1: 0.6437 - val_precision: 0.7474 - val_recall: 0.4424 - 188s/epoch - 19ms/step\n",
      "Epoch 115/200\n",
      "10076/10076 - 188s - loss: 0.1708 - auc: 0.9248 - auc_1: 0.6902 - precision: 0.7841 - recall: 0.4640 - val_loss: 0.1933 - val_auc: 0.9016 - val_auc_1: 0.6442 - val_precision: 0.7384 - val_recall: 0.4505 - 188s/epoch - 19ms/step\n",
      "Epoch 116/200\n",
      "10076/10076 - 187s - loss: 0.1706 - auc: 0.9251 - auc_1: 0.6909 - precision: 0.7810 - recall: 0.4703 - val_loss: 0.1930 - val_auc: 0.9010 - val_auc_1: 0.6439 - val_precision: 0.7377 - val_recall: 0.4545 - 187s/epoch - 19ms/step\n",
      "Epoch 117/200\n",
      "10076/10076 - 186s - loss: 0.1704 - auc: 0.9251 - auc_1: 0.6914 - precision: 0.7818 - recall: 0.4708 - val_loss: 0.1931 - val_auc: 0.9017 - val_auc_1: 0.6451 - val_precision: 0.7517 - val_recall: 0.4465 - 186s/epoch - 18ms/step\n",
      "Epoch 118/200\n",
      "10076/10076 - 187s - loss: 0.1703 - auc: 0.9253 - auc_1: 0.6924 - precision: 0.7858 - recall: 0.4687 - val_loss: 0.1926 - val_auc: 0.9024 - val_auc_1: 0.6457 - val_precision: 0.7305 - val_recall: 0.4545 - 187s/epoch - 19ms/step\n",
      "Epoch 119/200\n",
      "10076/10076 - 187s - loss: 0.1701 - auc: 0.9252 - auc_1: 0.6926 - precision: 0.7811 - recall: 0.4708 - val_loss: 0.1928 - val_auc: 0.9025 - val_auc_1: 0.6462 - val_precision: 0.7362 - val_recall: 0.4566 - 187s/epoch - 19ms/step\n",
      "Epoch 120/200\n",
      "10076/10076 - 186s - loss: 0.1699 - auc: 0.9256 - auc_1: 0.6932 - precision: 0.7834 - recall: 0.4734 - val_loss: 0.1932 - val_auc: 0.9014 - val_auc_1: 0.6463 - val_precision: 0.7367 - val_recall: 0.4465 - 186s/epoch - 19ms/step\n",
      "Epoch 121/200\n",
      "10076/10076 - 186s - loss: 0.1697 - auc: 0.9256 - auc_1: 0.6939 - precision: 0.7853 - recall: 0.4750 - val_loss: 0.1929 - val_auc: 0.9016 - val_auc_1: 0.6458 - val_precision: 0.7407 - val_recall: 0.4444 - 186s/epoch - 18ms/step\n",
      "Epoch 122/200\n",
      "Restoring model weights from the end of the best epoch: 112.\n",
      "10076/10076 - 187s - loss: 0.1695 - auc: 0.9258 - auc_1: 0.6946 - precision: 0.7861 - recall: 0.4713 - val_loss: 0.1927 - val_auc: 0.9026 - val_auc_1: 0.6452 - val_precision: 0.7340 - val_recall: 0.4626 - 187s/epoch - 19ms/step\n",
      "Epoch 122: early stopping\n",
      "3149/3149 [==============================] - 35s 11ms/step - loss: 0.1869 - auc: 0.9105 - auc_1: 0.6354 - precision: 0.7214 - recall: 0.4066\n"
     ]
    }
   ],
   "source": [
    "cnn_mort_model, cnn_mort_preds  = train_eval_pred_model(class_model, 2, 200, mortality_cnn_X_train, mortality_cnn_X_test,\n",
    "                                       mortality_cnn_y_train, mortality_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "3_art6AQSVBY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20129/20129 - 287s - loss: 0.8838 - mean_absolute_error: 0.5605 - val_loss: 1.0942 - val_mean_absolute_error: 0.5960 - 287s/epoch - 14ms/step\n",
      "Epoch 2/200\n",
      "20129/20129 - 281s - loss: 0.8663 - mean_absolute_error: 0.5584 - val_loss: 1.0965 - val_mean_absolute_error: 0.5699 - 281s/epoch - 14ms/step\n",
      "Epoch 3/200\n",
      "20129/20129 - 282s - loss: 0.8589 - mean_absolute_error: 0.5558 - val_loss: 1.1179 - val_mean_absolute_error: 0.5941 - 282s/epoch - 14ms/step\n",
      "Epoch 4/200\n",
      "20129/20129 - 282s - loss: 0.8553 - mean_absolute_error: 0.5551 - val_loss: 1.0851 - val_mean_absolute_error: 0.5830 - 282s/epoch - 14ms/step\n",
      "Epoch 5/200\n",
      "20129/20129 - 282s - loss: 0.8466 - mean_absolute_error: 0.5531 - val_loss: 1.0869 - val_mean_absolute_error: 0.5862 - 282s/epoch - 14ms/step\n",
      "Epoch 6/200\n",
      "20129/20129 - 266s - loss: 0.8466 - mean_absolute_error: 0.5532 - val_loss: 1.0945 - val_mean_absolute_error: 0.5913 - 266s/epoch - 13ms/step\n",
      "Epoch 7/200\n",
      "20129/20129 - 268s - loss: 0.8404 - mean_absolute_error: 0.5488 - val_loss: 1.0941 - val_mean_absolute_error: 0.5811 - 268s/epoch - 13ms/step\n",
      "Epoch 8/200\n",
      "20129/20129 - 284s - loss: 0.8315 - mean_absolute_error: 0.5494 - val_loss: 1.1329 - val_mean_absolute_error: 0.5967 - 284s/epoch - 14ms/step\n",
      "Epoch 9/200\n",
      "20129/20129 - 279s - loss: 0.8207 - mean_absolute_error: 0.5476 - val_loss: 1.1278 - val_mean_absolute_error: 0.6157 - 279s/epoch - 14ms/step\n",
      "Epoch 10/200\n",
      "20129/20129 - 275s - loss: 0.8123 - mean_absolute_error: 0.5442 - val_loss: 1.1109 - val_mean_absolute_error: 0.5868 - 275s/epoch - 14ms/step\n",
      "Epoch 11/200\n",
      "20129/20129 - 284s - loss: 0.7882 - mean_absolute_error: 0.5413 - val_loss: 1.1186 - val_mean_absolute_error: 0.5866 - 284s/epoch - 14ms/step\n",
      "Epoch 12/200\n",
      "20129/20129 - 276s - loss: 0.7869 - mean_absolute_error: 0.5400 - val_loss: 1.1082 - val_mean_absolute_error: 0.5718 - 276s/epoch - 14ms/step\n",
      "Epoch 13/200\n",
      "20129/20129 - 284s - loss: 0.7734 - mean_absolute_error: 0.5357 - val_loss: 1.1483 - val_mean_absolute_error: 0.5961 - 284s/epoch - 14ms/step\n",
      "Epoch 14/200\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "20129/20129 - 284s - loss: 0.7431 - mean_absolute_error: 0.5330 - val_loss: 1.1173 - val_mean_absolute_error: 0.5757 - 284s/epoch - 14ms/step\n",
      "Epoch 14: early stopping\n",
      "6285/6285 [==============================] - 44s 7ms/step - loss: 0.8911 - mean_absolute_error: 0.6527\n"
     ]
    }
   ],
   "source": [
    "cnn_los_model, cnn_los_preds = train_eval_pred_model(reg_model, 1, 200, los_cnn_X_train, los_cnn_X_test, los_cnn_y_train, los_cnn_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "los_cnn_y_test_std = np.subtract(los_cnn_y_test, np.repeat(np.mean(los_cnn_y_test), len(los_cnn_y_test))) / np.std(los_cnn_y_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(los_cnn_y_test_std, cnn_los_preds, s=25, zorder=10)\n",
    "\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "\n",
    "# Implementing Logistic Regression Model\n",
    "def train_test_lr_model(X_train, X_test, y_train, y_test): \n",
    "    \n",
    "    lr_model = LogisticRegression(random_state=random_seed, max_iter=10e6)\n",
    "    \n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lr_model.predict_proba(X_test)\n",
    "    \n",
    "    auroc = metrics.roc_auc_score(y_test, preds[:,1])\n",
    "    print(\"auroc: \", auroc, \"\\n\")\n",
    "    \n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, preds[:,1])\n",
    "    \n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    print(\"auprc: \", auprc, \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "\n",
    "# Implementing Linear Regression Model\n",
    "def train_test_linear_model(X_train, X_test, y_train, y_test): \n",
    "    \n",
    "    lr_model = Lasso(random_state=random_seed, max_iter=10e6)\n",
    "    \n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = lr_model.predict(X_test)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_test, preds)\n",
    "    print(\"mse: \", mse, \"\\n\")\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, preds)\n",
    "\n",
    "    print(\"mae: \", mae, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.5643236327680288 \n",
      "\n",
      "auprc:  0.164959075846385 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR cnn readmission\n",
    "\n",
    "\n",
    "readm_cnn_X_train_2d = readm_cnn_X_train.reshape((readm_cnn_X_train.shape[0], readm_cnn_X_train.shape[1]*readm_cnn_X_train.shape[2]))\n",
    "\n",
    "readm_cnn_X_test_2d = readm_cnn_X_test.reshape((readm_cnn_X_test.shape[0], readm_cnn_X_test.shape[1]*readm_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_lr_model(readm_cnn_X_train_2d, readm_cnn_X_test_2d, readm_cnn_y_train, readm_cnn_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.8023228468192779 \n",
      "\n",
      "auprc:  0.39849904246861323 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LR cnn ihm\n",
    "\n",
    "\n",
    "\n",
    "mortality_cnn_X_train_2d = mortality_cnn_X_train.reshape((mortality_cnn_X_train.shape[0],\n",
    "                                                          mortality_cnn_X_train.shape[1]*mortality_cnn_X_train.shape[2]))\n",
    "\n",
    "mortality_cnn_X_test_2d = mortality_cnn_X_test.reshape((mortality_cnn_X_test.shape[0],\n",
    "                                                     mortality_cnn_X_test.shape[1]*mortality_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_lr_model(mortality_cnn_X_train_2d, mortality_cnn_X_test_2d, mortality_cnn_y_train, mortality_cnn_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  1.0 \n",
      "\n",
      "mae:  0.6456541924088668 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear regression cnn los\n",
    "\n",
    "\n",
    "los_cnn_X_train_2d = los_cnn_X_train.reshape((los_cnn_X_train.shape[0], los_cnn_X_train.shape[1]*los_cnn_X_train.shape[2]))\n",
    "\n",
    "los_cnn_X_test_2d = los_cnn_X_test.reshape((los_cnn_X_test.shape[0], los_cnn_X_test.shape[1]*los_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_linear_model(los_cnn_X_train_2d, los_cnn_X_test_2d, los_cnn_y_train, los_cnn_y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ugrads/j/jeroda7105/miniconda3/envs/jeroda7105/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Implementing XGBoost model\n",
    "def train_test_XGBoost_class(X_train, X_test, y_train, y_test):\n",
    "    xg_class = xgb.XGBClassifier(objective ='binary:logistic', nthread=1, learning_rate = 0.2,\n",
    "                    max_depth = 12, alpha = 12, n_estimators = 35, use_label_encoder = False, eval_metric='logloss')\n",
    "    \n",
    "    xg_class.fit(X_train,y_train)\n",
    "\n",
    "    preds = xg_class.predict_proba(X_test)\n",
    "    \n",
    "    auroc = metrics.roc_auc_score(y_test, preds[:,1])\n",
    "    print(\"auroc: \", auroc, \"\\n\")\n",
    "    \n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, preds[:,1])\n",
    "    \n",
    "    auprc = metrics.auc(recall, precision)\n",
    "    print(\"auprc: \", auprc, \"\\n\")\n",
    "    \n",
    "\n",
    "     \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_XGBoost_reg(X_train, X_test, y_train, y_test):\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', nthread=1, learning_rate = 0.2,\n",
    "                    max_depth = 12, alpha = 12, n_estimators = 30)\n",
    "    \n",
    "    xg_reg.fit(X_train,y_train)\n",
    "\n",
    "    preds = xg_reg.predict(X_test)\n",
    "    \n",
    "    mse = metrics.mean_squared_error(y_test, preds)\n",
    "    print(\"mse: \", mse, \"\\n\")\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, preds)\n",
    "    print(\"mae: \", mae, \"\\n\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.5641393289270252 \n",
      "\n",
      "auprc:  0.1710776117683132 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB cnn readmission\n",
    "\n",
    "\n",
    "readm_cnn_X_train_2d = readm_cnn_X_train.reshape((readm_cnn_X_train.shape[0], readm_cnn_X_train.shape[1]*readm_cnn_X_train.shape[2]))\n",
    "\n",
    "readm_cnn_X_test_2d = readm_cnn_X_test.reshape((readm_cnn_X_test.shape[0], readm_cnn_X_test.shape[1]*readm_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_class(readm_cnn_X_train_2d, readm_cnn_X_test_2d, readm_cnn_y_train, readm_cnn_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc:  0.8841090914897662 \n",
      "\n",
      "auprc:  0.5699799244508265 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB cnn ihm\n",
    "\n",
    "\n",
    "\n",
    "mortality_cnn_X_train_2d = mortality_cnn_X_train.reshape((mortality_cnn_X_train.shape[0],\n",
    "                                                          mortality_cnn_X_train.shape[1]*mortality_cnn_X_train.shape[2]))\n",
    "\n",
    "mortality_cnn_X_test_2d = mortality_cnn_X_test.reshape((mortality_cnn_X_test.shape[0],\n",
    "                                                     mortality_cnn_X_test.shape[1]*mortality_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_class(mortality_cnn_X_train_2d, mortality_cnn_X_test_2d, mortality_cnn_y_train, mortality_cnn_y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  0.8673820744719607 \n",
      "\n",
      "mae:  0.5723229489533959 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB cnn los\n",
    "\n",
    "\n",
    "los_cnn_X_train_2d = los_cnn_X_train.reshape((los_cnn_X_train.shape[0], los_cnn_X_train.shape[1]*los_cnn_X_train.shape[2]))\n",
    "\n",
    "los_cnn_X_test_2d = los_cnn_X_test.reshape((los_cnn_X_test.shape[0], los_cnn_X_test.shape[1]*los_cnn_X_test.shape[2]))\n",
    "\n",
    "train_test_XGBoost_reg(los_cnn_X_train_2d, los_cnn_X_test_2d, los_cnn_y_train, los_cnn_y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mortality_mean_X_train_2d' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     27\u001b[0m skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(\u001b[43mmortality_mean_X_train_2d\u001b[49m, mortality_mean_y_train):\n\u001b[1;32m     30\u001b[0m     X_train_kf, X_test_kf \u001b[38;5;241m=\u001b[39m mortality_mean_X_train_2d[train_index], mortality_mean_X_train_2d[test_index]\n\u001b[1;32m     31\u001b[0m     y_train_kf, y_test_kf \u001b[38;5;241m=\u001b[39m mortality_mean_y_train\u001b[38;5;241m.\u001b[39miloc[train_index], mortality_mean_y_train\u001b[38;5;241m.\u001b[39miloc[test_index]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mortality_mean_X_train_2d' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# cross-validation xgb regression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Grid search for XGB\n",
    "depths = [12, 15]\n",
    "n_ests = [30, 35]\n",
    "lrs = [0.1, 0.2]\n",
    "alphas = [12, 14]\n",
    "\n",
    "\n",
    "auroc_dict = {}\n",
    "auprc_dict = {}\n",
    "\n",
    "for depth in depths:\n",
    "    for n_est in n_ests:\n",
    "        for lr in lrs:\n",
    "            for alpha in alphas:\n",
    "\n",
    "                auroc_dict[(depth, n_est, lr, alpha)] = 0\n",
    "                auprc_dict[(depth, n_est, lr, alpha)] = 0\n",
    "\n",
    "k = 4\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "for train_index, test_index in skf.split(mortality_mean_X_train_2d, mortality_mean_y_train):\n",
    "    X_train_kf, X_test_kf = mortality_mean_X_train_2d[train_index], mortality_mean_X_train_2d[test_index]\n",
    "    y_train_kf, y_test_kf = mortality_mean_y_train.iloc[train_index], mortality_mean_y_train.iloc[test_index]\n",
    "  \n",
    "\n",
    "    for depth in depths:\n",
    "        for n_est in n_ests:\n",
    "            for lr in lrs:\n",
    "                for alpha in alphas:\n",
    "                    \n",
    "                    \n",
    "                    xg_class = xgb.XGBClassifier(objective ='binary:logistic', nthread=1, learning_rate = lr,\n",
    "                    max_depth = depth, alpha = alpha, n_estimators = n_est, use_label_encoder = False, eval_metric='logloss')\n",
    "    \n",
    "                    xg_class.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "                    preds = xg_class.predict_proba(X_test_kf)\n",
    "\n",
    "                    cur_auroc = metrics.roc_auc_score(y_test_kf, preds[:,1])\n",
    "\n",
    "                    precision, recall, thresholds = metrics.precision_recall_curve(y_test_kf, preds[:,1])\n",
    "\n",
    "                    cur_auprc = metrics.auc(recall, precision)\n",
    "\n",
    "                    auroc_dict[(depth, n_est, lr, alpha)] += cur_auroc / k \n",
    "                    auprc_dict[(depth, n_est, lr, alpha)] += cur_auprc / k\n",
    "\n",
    "\n",
    "best_auroc = -1\n",
    "best_auprc = -1\n",
    "\n",
    "for key, model_auroc in auroc_dict.items():\n",
    "    if model_auroc > best_auroc:\n",
    "        best_auroc = model_auroc\n",
    "        best_depth = key[0]\n",
    "        best_n_est = key[1]\n",
    "        best_learning_rate = key[2]\n",
    "        best_alpha = key[3]\n",
    "\n",
    "\n",
    "# Finding the best parameters n for mse\n",
    "print('Best auroc:', best_auroc, '\\n')\n",
    "print('depth:', best_depth, '\\n')\n",
    "print('n_est:', best_n_est, '\\n')\n",
    "print('learning rate: ', best_learning_rate, '\\n')\n",
    "print('alpha: ', best_alpha, '\\n')\n",
    "\n",
    "for key, model_auprc in auprc_dict.items():\n",
    "    if model_auprc > best_auprc:\n",
    "        best_auprc = model_auprc\n",
    "        best_depth = key[0]\n",
    "        best_n_est = key[1]\n",
    "        best_learning_rate = key[2]\n",
    "        best_alpha = key[3]\n",
    "  \n",
    " # Finding the best parameters n for mae\n",
    "print('Best auprc:', best_auprc, '\\n')\n",
    "print('depth:', best_depth, '\\n')\n",
    "print('n_est:', best_n_est, '\\n')\n",
    "print('learning rate: ', best_learning_rate, '\\n')\n",
    "print('alpha: ', best_alpha, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mimic_iv_omop_modeling_unified_cnn_vae_testing_diff_error_calc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
